diff --git a/node_modules/@vladmandic/face-api/dist/face-api.node.js b/node_modules/@vladmandic/face-api/dist/face-api.node.js
index a606d4b..e518227 100644
--- a/node_modules/@vladmandic/face-api/dist/face-api.node.js
+++ b/node_modules/@vladmandic/face-api/dist/face-api.node.js
@@ -1,9 +1,3837 @@
-
-  /*
+/*
   Face-API
   homepage: <https://github.com/vladmandic/face-api>
   author: <https://github.com/vladmandic>'
   */
 
-var ln=Object.create,Ye=Object.defineProperty,fn=Object.getPrototypeOf,hn=Object.prototype.hasOwnProperty,xn=Object.getOwnPropertyNames,bn=Object.getOwnPropertyDescriptor;var fo=o=>Ye(o,"__esModule",{value:!0});var ho=(o,t)=>()=>(t||(t={exports:{}},o(t.exports,t)),t.exports),Ge=(o,t)=>{fo(o);for(var e in t)Ye(o,e,{get:t[e],enumerable:!0})},gn=(o,t,e)=>{if(fo(o),t&&typeof t=="object"||typeof t=="function")for(let r of xn(t))!hn.call(o,r)&&r!=="default"&&Ye(o,r,{get:()=>t[r],enumerable:!(e=bn(t,r))||e.enumerable});return o},b=o=>o&&o.__esModule?o:gn(Ye(o!=null?ln(fn(o)):{},"default",{value:o,enumerable:!0}),o);var g=ho(xo=>{var vn=Object.create,Er=Object.defineProperty,yn=Object.getPrototypeOf,Fn=Object.prototype.hasOwnProperty,Tn=Object.getOwnPropertyNames,Pn=Object.getOwnPropertyDescriptor,_n=o=>Er(o,"__esModule",{value:!0}),bo=(o,t,e)=>{if(_n(o),t&&typeof t=="object"||typeof t=="function")for(let r of Tn(t))!Fn.call(o,r)&&r!=="default"&&Er(o,r,{get:()=>t[r],enumerable:!(e=Pn(t,r))||e.enumerable});return o},wn=o=>o&&o.__esModule?o:bo(Er(o!=null?vn(yn(o)):{},"default",{value:o,enumerable:!0}),o);bo(xo,wn(require("@tensorflow/tfjs-node")))});var To=ho((Ln,Fo)=>{Ge(Ln,{isNodejs:()=>kn});function kn(){return typeof global=="object"&&!0&&typeof Fo!="undefined"&&typeof process!="undefined"&&!!process.version}});Ge(exports,{AgeGenderNet:()=>pr,BoundingBox:()=>ee,Box:()=>D,ComposableTask:()=>tt,ComputeAllFaceDescriptorsTask:()=>At,ComputeFaceDescriptorsTaskBase:()=>vr,ComputeSingleFaceDescriptorTask:()=>Wt,DetectAllFaceLandmarksTask:()=>Fr,DetectAllFacesTask:()=>He,DetectFaceLandmarksTaskBase:()=>yr,DetectFacesTaskBase:()=>Pr,DetectSingleFaceLandmarksTask:()=>Tr,DetectSingleFaceTask:()=>_r,Dimensions:()=>A,FACE_EXPRESSION_LABELS:()=>Jr,FaceDetection:()=>M,FaceDetectionNet:()=>Jo,FaceExpressionNet:()=>cr,FaceExpressions:()=>It,FaceLandmark68Net:()=>fe,FaceLandmark68TinyNet:()=>dr,FaceLandmarkNet:()=>Bo,FaceLandmarks:()=>V,FaceLandmarks5:()=>vo,FaceLandmarks68:()=>oe,FaceMatch:()=>Ee,FaceMatcher:()=>Dr,FaceRecognitionNet:()=>xe,Gender:()=>vt,LabeledBox:()=>Me,LabeledFaceDescriptors:()=>xt,NetInput:()=>bt,NeuralNetwork:()=>S,ObjectDetection:()=>Dt,Point:()=>x,PredictedBox:()=>yo,Rect:()=>re,SsdMobilenetv1:()=>Ut,SsdMobilenetv1Options:()=>Z,TinyFaceDetector:()=>Fe,TinyFaceDetectorOptions:()=>gr,TinyYolov2:()=>ve,TinyYolov2Options:()=>lt,allFaces:()=>Da,allFacesSsdMobilenetv1:()=>dn,allFacesTinyYolov2:()=>wa,awaitMediaLoaded:()=>Yr,bufferToImage:()=>Gr,computeFaceDescriptor:()=>da,createCanvas:()=>ne,createCanvasFromMedia:()=>Ie,createFaceDetectionNet:()=>na,createFaceRecognitionNet:()=>Un,createSsdMobilenetv1:()=>Xo,createTinyFaceDetector:()=>Ea,createTinyYolov2:()=>ia,detectAllFaces:()=>wr,detectFaceLandmarks:()=>mn,detectFaceLandmarksTiny:()=>pa,detectLandmarks:()=>Pa,detectSingleFace:()=>_a,draw:()=>Qr,env:()=>w,euclideanDistance:()=>uo,extendWithAge:()=>hr,extendWithFaceDescriptor:()=>fr,extendWithFaceDetection:()=>$t,extendWithFaceExpressions:()=>mr,extendWithFaceLandmarks:()=>le,extendWithGender:()=>xr,extractFaceTensors:()=>se,extractFaces:()=>ae,fetchImage:()=>Bn,fetchJson:()=>Ur,fetchNetWeights:()=>Rn,fetchOrThrow:()=>Yt,getContext2dOrThrow:()=>O,getMediaDimensions:()=>Ht,imageTensorToCanvas:()=>zr,imageToSquare:()=>Vr,inverseSigmoid:()=>Mn,iou:()=>Lr,isMediaElement:()=>qe,isMediaLoaded:()=>Ne,isWithAge:()=>Xn,isWithFaceDetection:()=>pt,isWithFaceExpressions:()=>qr,isWithFaceLandmarks:()=>zt,isWithGender:()=>Jn,loadAgeGenderModel:()=>ya,loadFaceDetectionModel:()=>Fa,loadFaceExpressionModel:()=>va,loadFaceLandmarkModel:()=>xa,loadFaceLandmarkTinyModel:()=>ba,loadFaceRecognitionModel:()=>ga,loadSsdMobilenetv1Model:()=>pn,loadTinyFaceDetectorModel:()=>fa,loadTinyYolov2Model:()=>ha,loadWeightMap:()=>Xr,locateFaces:()=>Ta,matchDimensions:()=>On,minBbox:()=>kr,nets:()=>P,nonMaxSuppression:()=>Sr,normalize:()=>ot,padToSquare:()=>Ar,predictAgeAndGender:()=>la,recognizeFaceExpressions:()=>ua,resizeResults:()=>un,resolveInput:()=>jt,shuffleArray:()=>En,sigmoid:()=>De,ssdMobilenetv1:()=>cn,tf:()=>Ma,tinyFaceDetector:()=>ca,tinyYolov2:()=>ma,toNetInput:()=>E,utils:()=>Mr,validateConfig:()=>ao,version:()=>Ia});var Ma=b(g());var Qr={};Ge(Qr,{AnchorPosition:()=>dt,DrawBox:()=>Xe,DrawBoxOptions:()=>Hr,DrawFaceLandmarks:()=>Kr,DrawFaceLandmarksOptions:()=>Zr,DrawTextField:()=>Mt,DrawTextFieldOptions:()=>Ce,drawContour:()=>ft,drawDetections:()=>Wn,drawFaceExpressions:()=>$n,drawFaceLandmarks:()=>jn});function ft(o,t,e=!1){if(o.beginPath(),t.slice(1).forEach(({x:r,y:n},a)=>{let s=t[a];o.moveTo(s.x,s.y),o.lineTo(r,n)}),e){let r=t[t.length-1],n=t[0];if(!r||!n)return;o.moveTo(r.x,r.y),o.lineTo(n.x,n.y)}o.stroke()}var Mr={};Ge(Mr,{computeReshapedDimensions:()=>Ir,getCenterPoint:()=>Ot,isDimensions:()=>Ve,isEven:()=>ze,isFloat:()=>Nr,isTensor:()=>Bt,isTensor1D:()=>Dn,isTensor2D:()=>Cr,isTensor3D:()=>ht,isTensor4D:()=>z,isValidNumber:()=>rt,isValidProbablitiy:()=>te,range:()=>ct,round:()=>Rt});var go=b(g());var A=class{constructor(t,e){if(!rt(t)||!rt(e))throw new Error(`Dimensions.constructor - expected width and height to be valid numbers, instead have ${JSON.stringify({width:t,height:e})}`);this._width=t,this._height=e}get width(){return this._width}get height(){return this._height}reverse(){return new A(1/this.width,1/this.height)}};function Bt(o,t){return o instanceof go.Tensor&&o.shape.length===t}function Dn(o){return Bt(o,1)}function Cr(o){return Bt(o,2)}function ht(o){return Bt(o,3)}function z(o){return Bt(o,4)}function Nr(o){return o%1!=0}function ze(o){return o%2==0}function Rt(o,t=2){let e=10**t;return Math.floor(o*e)/e}function Ve(o){return o&&o.width&&o.height}function Ir({width:o,height:t},e){let r=e/Math.max(t,o);return new A(Math.round(o*r),Math.round(t*r))}function Ot(o){return o.reduce((t,e)=>t.add(e),new x(0,0)).div(new x(o.length,o.length))}function ct(o,t,e){return Array(o).fill(0).map((r,n)=>t+n*e)}function rt(o){return!!o&&o!==Infinity&&o!==-Infinity&&!Number.isNaN(o)||o===0}function te(o){return rt(o)&&o>=0&&o<=1}var x=class{constructor(t,e){this._x=t,this._y=e}get x(){return this._x}get y(){return this._y}add(t){return new x(this.x+t.x,this.y+t.y)}sub(t){return new x(this.x-t.x,this.y-t.y)}mul(t){return new x(this.x*t.x,this.y*t.y)}div(t){return new x(this.x/t.x,this.y/t.y)}abs(){return new x(Math.abs(this.x),Math.abs(this.y))}magnitude(){return Math.sqrt(this.x**2+this.y**2)}floor(){return new x(Math.floor(this.x),Math.floor(this.y))}};var D=class{static isRect(t){return!!t&&[t.x,t.y,t.width,t.height].every(rt)}static assertIsValidBox(t,e,r=!1){if(!D.isRect(t))throw new Error(`${e} - invalid box: ${JSON.stringify(t)}, expected object with properties x, y, width, height`);if(!r&&(t.width<0||t.height<0))throw new Error(`${e} - width (${t.width}) and height (${t.height}) must be positive numbers`)}constructor(t,e=!0){let r=t||{},n=[r.left,r.top,r.right,r.bottom].every(rt),a=[r.x,r.y,r.width,r.height].every(rt);if(!a&&!n)throw new Error(`Box.constructor - expected box to be IBoundingBox | IRect, instead have ${JSON.stringify(r)}`);let[s,i,c,m]=a?[r.x,r.y,r.width,r.height]:[r.left,r.top,r.right-r.left,r.bottom-r.top];D.assertIsValidBox({x:s,y:i,width:c,height:m},"Box.constructor",e),this._x=s,this._y=i,this._width=c,this._height=m}get x(){return this._x}get y(){return this._y}get width(){return this._width}get height(){return this._height}get left(){return this.x}get top(){return this.y}get right(){return this.x+this.width}get bottom(){return this.y+this.height}get area(){return this.width*this.height}get topLeft(){return new x(this.left,this.top)}get topRight(){return new x(this.right,this.top)}get bottomLeft(){return new x(this.left,this.bottom)}get bottomRight(){return new x(this.right,this.bottom)}round(){let[t,e,r,n]=[this.x,this.y,this.width,this.height].map(a=>Math.round(a));return new D({x:t,y:e,width:r,height:n})}floor(){let[t,e,r,n]=[this.x,this.y,this.width,this.height].map(a=>Math.floor(a));return new D({x:t,y:e,width:r,height:n})}toSquare(){let{x:t,y:e,width:r,height:n}=this,a=Math.abs(r-n);return r<n&&(t-=a/2,r+=a),n<r&&(e-=a/2,n+=a),new D({x:t,y:e,width:r,height:n})}rescale(t){let e=Ve(t)?t.width:t,r=Ve(t)?t.height:t;return new D({x:this.x*e,y:this.y*r,width:this.width*e,height:this.height*r})}pad(t,e){let[r,n,a,s]=[this.x-t/2,this.y-e/2,this.width+t,this.height+e];return new D({x:r,y:n,width:a,height:s})}clipAtImageBorders(t,e){let{x:r,y:n,right:a,bottom:s}=this,i=Math.max(r,0),c=Math.max(n,0),m=a-i,p=s-c,d=Math.min(m,t-i),u=Math.min(p,e-c);return new D({x:i,y:c,width:d,height:u}).floor()}shift(t,e){let{width:r,height:n}=this,a=this.x+t,s=this.y+e;return new D({x:a,y:s,width:r,height:n})}padAtBorders(t,e){let r=this.width+1,n=this.height+1,a=1,s=1,i=r,c=n,m=this.left,p=this.top,d=this.right,u=this.bottom;return d>e&&(i=-d+e+r,d=e),u>t&&(c=-u+t+n,u=t),m<1&&(c=2-m,m=1),p<1&&(c=2-p,p=1),{dy:s,edy:c,dx:a,edx:i,y:p,ey:u,x:m,ex:d,w:r,h:n}}calibrate(t){return new D({left:this.left+t.left*this.width,top:this.top+t.top*this.height,right:this.right+t.right*this.width,bottom:this.bottom+t.bottom*this.height}).toSquare().round()}};var ee=class extends D{constructor(t,e,r,n,a=!1){super({left:t,top:e,right:r,bottom:n},a)}};var Dt=class{constructor(t,e,r,n,a){this._imageDims=new A(a.width,a.height),this._score=t,this._classScore=e,this._className=r,this._box=new D(n).rescale(this._imageDims)}get score(){return this._score}get classScore(){return this._classScore}get className(){return this._className}get box(){return this._box}get imageDims(){return this._imageDims}get imageWidth(){return this.imageDims.width}get imageHeight(){return this.imageDims.height}get relativeBox(){return new D(this._box).rescale(this.imageDims.reverse())}forSize(t,e){return new Dt(this.score,this.classScore,this.className,this.relativeBox,{width:t,height:e})}};var M=class extends Dt{constructor(t,e,r){super(t,t,"",e,r)}forSize(t,e){let{score:r,relativeBox:n,imageDims:a}=super.forSize(t,e);return new M(r,n,a)}};function Lr(o,t,e=!0){let r=Math.max(0,Math.min(o.right,t.right)-Math.max(o.left,t.left)),n=Math.max(0,Math.min(o.bottom,t.bottom)-Math.max(o.top,t.top)),a=r*n;return e?a/(o.area+t.area-a):a/Math.min(o.area,t.area)}function kr(o){let t=o.map(i=>i.x),e=o.map(i=>i.y),r=t.reduce((i,c)=>c<i?c:i,Infinity),n=e.reduce((i,c)=>c<i?c:i,Infinity),a=t.reduce((i,c)=>i<c?c:i,0),s=e.reduce((i,c)=>i<c?c:i,0);return new ee(r,n,a,s)}function Sr(o,t,e,r=!0){let n=t.map((s,i)=>({score:s,boxIndex:i})).sort((s,i)=>s.score-i.score).map(s=>s.boxIndex),a=[];for(;n.length>0;){let s=n.pop();a.push(s);let i=n,c=[];for(let m=0;m<i.length;m++){let p=i[m],d=o[s],u=o[p];c.push(Lr(d,u,r))}n=n.filter((m,p)=>c[p]<=e)}return a}var mt=b(g());function ot(o,t){return mt.tidy(()=>{let[e,r,n]=t,a=mt.fill([...o.shape.slice(0,3),1],e,"float32"),s=mt.fill([...o.shape.slice(0,3),1],r,"float32"),i=mt.fill([...o.shape.slice(0,3),1],n,"float32"),c=mt.concat([a,s,i],3);return mt.sub(o,c)})}var Et=b(g());function Ar(o,t=!1){return Et.tidy(()=>{let[e,r]=o.shape.slice(1);if(e===r)return o;let n=Math.abs(e-r),a=Math.round(n*(t?.5:1)),s=e>r?2:1,i=u=>{let l=o.shape.slice();return l[s]=u,Et.fill(l,0,"float32")},c=i(a),m=n-c.shape[s],d=[t&&m?i(m):null,o,c].filter(u=>!!u).map(u=>Et.cast(u,"float32"));return Et.concat(d,s)})}function En(o){let t=o.slice();for(let e=t.length-1;e>0;e--){let r=Math.floor(Math.random()*(e+1)),n=t[e];t[e]=t[r],t[r]=n}return t}function De(o){return 1/(1+Math.exp(-o))}function Mn(o){return Math.log(o/(1-o))}var re=class extends D{constructor(t,e,r,n,a=!1){super({x:t,y:e,width:r,height:n},a)}};var Cn=.5,Nn=.43,In=.45,V=class{constructor(t,e,r=new x(0,0)){let{width:n,height:a}=e;this._imgDims=new A(n,a),this._shift=r,this._positions=t.map(s=>s.mul(new x(n,a)).add(r))}get shift(){return new x(this._shift.x,this._shift.y)}get imageWidth(){return this._imgDims.width}get imageHeight(){return this._imgDims.height}get positions(){return this._positions}get relativePositions(){return this._positions.map(t=>t.sub(this._shift).div(new x(this.imageWidth,this.imageHeight)))}forSize(t,e){return new this.constructor(this.relativePositions,{width:t,height:e})}shiftBy(t,e){return new this.constructor(this.relativePositions,this._imgDims,new x(t,e))}shiftByPoint(t){return this.shiftBy(t.x,t.y)}align(t,e={}){if(t){let a=t instanceof M?t.box.floor():new D(t);return this.shiftBy(a.x,a.y).align(null,e)}let{useDlibAlignment:r,minBoxPadding:n}={useDlibAlignment:!1,minBoxPadding:.2,...e};return r?this.alignDlib():this.alignMinBbox(n)}alignDlib(){let t=this.getRefPointsForAlignment(),[e,r,n]=t,a=d=>n.sub(d).magnitude(),s=(a(e)+a(r))/2,i=Math.floor(s/In),c=Ot(t),m=Math.floor(Math.max(0,c.x-Cn*i)),p=Math.floor(Math.max(0,c.y-Nn*i));return new re(m,p,Math.min(i,this.imageWidth+m),Math.min(i,this.imageHeight+p))}alignMinBbox(t){let e=kr(this.positions);return e.pad(e.width*t,e.height*t)}getRefPointsForAlignment(){throw new Error("getRefPointsForAlignment not implemented by base class")}};var vo=class extends V{getRefPointsForAlignment(){let t=this.positions;return[t[0],t[1],Ot([t[3],t[4]])]}};var oe=class extends V{getJawOutline(){return this.positions.slice(0,17)}getLeftEyeBrow(){return this.positions.slice(17,22)}getRightEyeBrow(){return this.positions.slice(22,27)}getNose(){return this.positions.slice(27,36)}getLeftEye(){return this.positions.slice(36,42)}getRightEye(){return this.positions.slice(42,48)}getMouth(){return this.positions.slice(48,68)}getRefPointsForAlignment(){return[this.getLeftEye(),this.getRightEye(),this.getMouth()].map(Ot)}};var Ee=class{constructor(t,e){this._label=t,this._distance=e}get label(){return this._label}get distance(){return this._distance}toString(t=!0){return`${this.label}${t?` (${Rt(this.distance)})`:""}`}};var Me=class extends D{static assertIsValidLabeledBox(t,e){if(D.assertIsValidBox(t,e),!rt(t.label))throw new Error(`${e} - expected property label (${t.label}) to be a number`)}constructor(t,e){super(t);this._label=e}get label(){return this._label}};var xt=class{constructor(t,e){if(typeof t!="string")throw new Error("LabeledFaceDescriptors - constructor expected label to be a string");if(!Array.isArray(e)||e.some(r=>!(r instanceof Float32Array)))throw new Error("LabeledFaceDescriptors - constructor expected descriptors to be an array of Float32Array");this._label=t,this._descriptors=e}get label(){return this._label}get descriptors(){return this._descriptors}toJSON(){return{label:this.label,descriptors:this.descriptors.map(t=>Array.from(t))}}static fromJSON(t){let e=t.descriptors.map(r=>new Float32Array(r));return new xt(t.label,e)}};var yo=class extends Me{static assertIsValidPredictedBox(t,e){if(Me.assertIsValidLabeledBox(t,e),!te(t.score)||!te(t.classScore))throw new Error(`${e} - expected properties score (${t.score}) and (${t.classScore}) to be a number between [0, 1]`)}constructor(t,e,r,n){super(t,e);this._score=r,this._classScore=n}get score(){return this._score}get classScore(){return this._classScore}};function pt(o){return o.detection instanceof M}function $t(o,t){return{...o,...{detection:t}}}function Wr(){let o=window.fetch;if(!o)throw new Error("fetch - missing fetch implementation for browser environment");let t=()=>{throw new Error("readFile - filesystem not available for browser environment")};return{Canvas:HTMLCanvasElement,CanvasRenderingContext2D,Image:HTMLImageElement,ImageData,Video:HTMLVideoElement,createCanvasElement:()=>document.createElement("canvas"),createImageElement:()=>document.createElement("img"),fetch:o,readFile:t}}function Ue(o){let t="";if(!o)try{o=require("fs")}catch(r){t=r.toString()}return{readFile:o?r=>new Promise((n,a)=>{o.readFile(r,(s,i)=>s?a(s):n(i))}):()=>{throw new Error(`readFile - failed to require fs in nodejs environment with error: ${t}`)}}}function Br(){let o=global.Canvas||global.HTMLCanvasElement,t=global.Image||global.HTMLImageElement,e=()=>{if(o)return new o;throw new Error("createCanvasElement - missing Canvas implementation for nodejs environment")},r=()=>{if(t)return new t;throw new Error("createImageElement - missing Image implementation for nodejs environment")},n=global.fetch,a=Ue();return{Canvas:o||class{},CanvasRenderingContext2D:global.CanvasRenderingContext2D||class{},Image:t||class{},ImageData:global.ImageData||class{},Video:global.HTMLVideoElement||class{},createCanvasElement:e,createImageElement:r,fetch:n,...a}}function Rr(){return typeof window=="object"&&typeof document!="undefined"&&typeof HTMLImageElement!="undefined"&&typeof HTMLCanvasElement!="undefined"&&typeof HTMLVideoElement!="undefined"&&typeof ImageData!="undefined"&&typeof CanvasRenderingContext2D!="undefined"}var Or=b(To()),k;function Sn(){if(!k)throw new Error("getEnv - environment is not defined, check isNodejs() and isBrowser()");return k}function $r(o){k=o}function jr(){return Rr()?$r(Wr()):Or.isNodejs()?$r(Br()):null}function An(o){if(k||jr(),!k)throw new Error("monkeyPatch - environment is not defined, check isNodejs() and isBrowser()");let{Canvas:t=k.Canvas,Image:e=k.Image}=o;k.Canvas=t,k.Image=e,k.createCanvasElement=o.createCanvasElement||(()=>new t),k.createImageElement=o.createImageElement||(()=>new e),k.ImageData=o.ImageData||k.ImageData,k.Video=o.Video||k.Video,k.fetch=o.fetch||k.fetch,k.readFile=o.readFile||k.readFile}var w={getEnv:Sn,setEnv:$r,initialize:jr,createBrowserEnv:Wr,createFileSystem:Ue,createNodejsEnv:Br,monkeyPatch:An,isBrowser:Rr,isNodejs:Or.isNodejs};jr();function jt(o){return!w.isNodejs()&&typeof o=="string"?document.getElementById(o):o}function O(o){let{Canvas:t,CanvasRenderingContext2D:e}=w.getEnv();if(o instanceof e)return o;let r=jt(o);if(!(r instanceof t))throw new Error("resolveContext2d - expected canvas to be of instance of Canvas");let n=r.getContext("2d");if(!n)throw new Error("resolveContext2d - canvas 2d context is null");return n}var dt;(function(o){o.TOP_LEFT="TOP_LEFT",o.TOP_RIGHT="TOP_RIGHT",o.BOTTOM_LEFT="BOTTOM_LEFT",o.BOTTOM_RIGHT="BOTTOM_RIGHT"})(dt||(dt={}));var Ce=class{constructor(t={}){let{anchorPosition:e,backgroundColor:r,fontColor:n,fontSize:a,fontStyle:s,padding:i}=t;this.anchorPosition=e||dt.TOP_LEFT,this.backgroundColor=r||"rgba(0, 0, 0, 0.5)",this.fontColor=n||"rgba(255, 255, 255, 1)",this.fontSize=a||14,this.fontStyle=s||"Georgia",this.padding=i||4}},Mt=class{constructor(t,e,r={}){this.text=typeof t=="string"?[t]:t instanceof Mt?t.text:t,this.anchor=e,this.options=new Ce(r)}measureWidth(t){let{padding:e}=this.options;return this.text.map(r=>t.measureText(r).width).reduce((r,n)=>r<n?n:r,0)+2*e}measureHeight(){let{fontSize:t,padding:e}=this.options;return this.text.length*t+2*e}getUpperLeft(t,e){let{anchorPosition:r}=this.options,n=r===dt.BOTTOM_RIGHT||r===dt.TOP_RIGHT,a=r===dt.BOTTOM_LEFT||r===dt.BOTTOM_RIGHT,s=this.measureWidth(t),i=this.measureHeight(),c=n?this.anchor.x-s:this.anchor.x,m=a?this.anchor.y-i:this.anchor.y;if(e){let{width:p,height:d}=e,u=Math.max(Math.min(c,p-s),0),l=Math.max(Math.min(m,d-i),0);return{x:u,y:l}}return{x:c,y:m}}draw(t){let e=jt(t),r=O(e),{backgroundColor:n,fontColor:a,fontSize:s,fontStyle:i,padding:c}=this.options;r.font=`${s}px ${i}`;let m=this.measureWidth(r),p=this.measureHeight();r.fillStyle=n;let d=this.getUpperLeft(r,e);r.fillRect(d.x,d.y,m,p),r.fillStyle=a,this.text.forEach((u,l)=>{let v=c+d.x,_=c+d.y+(l+1)*s;r.fillText(u,v,_)})}};var Hr=class{constructor(t={}){let{boxColor:e,lineWidth:r,label:n,drawLabelOptions:a}=t;this.boxColor=e||"rgba(0, 0, 255, 1)",this.lineWidth=r||2,this.label=n;let s={anchorPosition:dt.BOTTOM_LEFT,backgroundColor:this.boxColor};this.drawLabelOptions=new Ce({...s,...a})}},Xe=class{constructor(t,e={}){this.box=new D(t),this.options=new Hr(e)}draw(t){let e=O(t),{boxColor:r,lineWidth:n}=this.options,{x:a,y:s,width:i,height:c}=this.box;e.strokeStyle=r,e.lineWidth=n,e.strokeRect(a,s,i,c);let{label:m}=this.options;m&&new Mt([m],{x:a-n/2,y:s},this.options.drawLabelOptions).draw(t)}};function Wn(o,t){(Array.isArray(t)?t:[t]).forEach(r=>{let n=r instanceof M?r.score:pt(r)?r.detection.score:void 0,a=r instanceof M?r.box:pt(r)?r.detection.box:new D(r),s=n?`${Rt(n)}`:void 0;new Xe(a,{label:s}).draw(o)})}var ue=b(g());function Ne(o){let{Image:t,Video:e}=w.getEnv();return o instanceof t&&o.complete||o instanceof e&&o.readyState>=3}function Yr(o){return new Promise((t,e)=>{if(o instanceof w.getEnv().Canvas||Ne(o))return t(null);function r(a){!a.currentTarget||(a.currentTarget.removeEventListener("load",n),a.currentTarget.removeEventListener("error",r),e(a))}function n(a){!a.currentTarget||(a.currentTarget.removeEventListener("load",n),a.currentTarget.removeEventListener("error",r),t(a))}o.addEventListener("load",n),o.addEventListener("error",r)})}function Gr(o){return new Promise((t,e)=>{o instanceof Blob||e(new Error("bufferToImage - expected buf to be of type: Blob"));let r=new FileReader;r.onload=()=>{typeof r.result!="string"&&e(new Error("bufferToImage - expected reader.result to be a string, in onload"));let n=w.getEnv().createImageElement();n.onload=()=>t(n),n.onerror=e,n.src=r.result},r.onerror=e,r.readAsDataURL(o)})}function Ht(o){let{Image:t,Video:e}=w.getEnv();return o instanceof t?new A(o.naturalWidth,o.naturalHeight):o instanceof e?new A(o.videoWidth,o.videoHeight):new A(o.width,o.height)}function ne({width:o,height:t}){let{createCanvasElement:e}=w.getEnv(),r=e();return r.width=o,r.height=t,r}function Ie(o,t){let{ImageData:e}=w.getEnv();if(!(o instanceof e)&&!Ne(o))throw new Error("createCanvasFromMedia - media has not finished loading yet");let{width:r,height:n}=t||Ht(o),a=ne({width:r,height:n});return o instanceof e?O(a).putImageData(o,0,0):O(a).drawImage(o,0,0,r,n),a}var Je=b(g());async function zr(o,t){let e=t||w.getEnv().createCanvasElement(),[r,n,a]=o.shape.slice(z(o)?1:0),s=Je.tidy(()=>o.as3D(r,n,a).toInt());return await Je.browser.toPixels(s,e),s.dispose(),e}function qe(o){let{Image:t,Canvas:e,Video:r}=w.getEnv();return o instanceof t||o instanceof e||o instanceof r}var J=b(g());function Vr(o,t,e=!1){let{Image:r,Canvas:n}=w.getEnv();if(!(o instanceof r||o instanceof n))throw new Error("imageToSquare - expected arg0 to be HTMLImageElement | HTMLCanvasElement");let a=Ht(o),s=t/Math.max(a.height,a.width),i=s*a.width,c=s*a.height,m=ne({width:t,height:t}),p=o instanceof n?o:Ie(o),d=Math.abs(i-c)/2,u=e&&i<c?d:0,l=e&&c<i?d:0;return O(m).drawImage(p,u,l,i,c),m}var bt=class{constructor(t,e=!1){this._imageTensors=[];this._canvases=[];this._treatAsBatchInput=!1;this._inputDimensions=[];if(!Array.isArray(t))throw new Error(`NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have ${t}`);this._treatAsBatchInput=e,this._batchSize=t.length,t.forEach((r,n)=>{if(ht(r)){this._imageTensors[n]=r,this._inputDimensions[n]=r.shape;return}if(z(r)){let s=r.shape[0];if(s!==1)throw new Error(`NetInput - tf.Tensor4D with batchSize ${s} passed, but not supported in input array`);this._imageTensors[n]=r,this._inputDimensions[n]=r.shape.slice(1);return}let a=r instanceof w.getEnv().Canvas?r:Ie(r);this._canvases[n]=a,this._inputDimensions[n]=[a.height,a.width,3]})}get imageTensors(){return this._imageTensors}get canvases(){return this._canvases}get isBatchInput(){return this.batchSize>1||this._treatAsBatchInput}get batchSize(){return this._batchSize}get inputDimensions(){return this._inputDimensions}get inputSize(){return this._inputSize}get reshapedInputDimensions(){return ct(this.batchSize,0,1).map((t,e)=>this.getReshapedInputDimensions(e))}getInput(t){return this.canvases[t]||this.imageTensors[t]}getInputDimensions(t){return this._inputDimensions[t]}getInputHeight(t){return this._inputDimensions[t][0]}getInputWidth(t){return this._inputDimensions[t][1]}getReshapedInputDimensions(t){if(typeof this.inputSize!="number")throw new Error("getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet");let e=this.getInputWidth(t),r=this.getInputHeight(t);return Ir({width:e,height:r},this.inputSize)}toBatchTensor(t,e=!0){return this._inputSize=t,J.tidy(()=>{let r=ct(this.batchSize,0,1).map(a=>{let s=this.getInput(a);if(s instanceof J.Tensor){let i=z(s)?s:s.expandDims();return i=Ar(i,e),(i.shape[1]!==t||i.shape[2]!==t)&&(i=J.image.resizeBilinear(i,[t,t])),i.as3D(t,t,3)}if(s instanceof w.getEnv().Canvas)return J.browser.fromPixels(Vr(s,t,e));throw new Error(`toBatchTensor - at batchIdx ${a}, expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have ${s}`)});return J.stack(r.map(a=>J.cast(a,"float32"))).as4D(this.batchSize,t,t,3)})}};async function E(o){if(o instanceof bt)return o;let t=Array.isArray(o)?o:[o];if(!t.length)throw new Error("toNetInput - empty array passed as input");let e=n=>Array.isArray(o)?` at input index ${n}:`:"",r=t.map(jt);return r.forEach((n,a)=>{if(!qe(n)&&!ht(n)&&!z(n))throw typeof t[a]=="string"?new Error(`toNetInput -${e(a)} string passed, but could not resolve HTMLElement for element id ${t[a]}`):new Error(`toNetInput -${e(a)} expected media to be of type HTMLImageElement | HTMLVideoElement | HTMLCanvasElement | tf.Tensor3D, or to be an element id`);if(z(n)){let s=n.shape[0];if(s!==1)throw new Error(`toNetInput -${e(a)} tf.Tensor4D with batchSize ${s} passed, but not supported in input array`)}}),await Promise.all(r.map(n=>qe(n)&&Yr(n))),new bt(r,Array.isArray(o))}async function ae(o,t){let{Canvas:e}=w.getEnv(),r=o;if(!(o instanceof e)){let s=await E(o);if(s.batchSize>1)throw new Error("extractFaces - batchSize > 1 not supported");let i=s.getInput(0);r=i instanceof e?i:await zr(i)}let n=O(r);return t.map(s=>s instanceof M?s.forSize(r.width,r.height).box.floor():s).map(s=>s.clipAtImageBorders(r.width,r.height)).map(({x:s,y:i,width:c,height:m})=>{let p=ne({width:c,height:m});return O(p).putImageData(n.getImageData(s,i,c,m),0,0),p})}var Ze=b(g());async function se(o,t){if(!ht(o)&&!z(o))throw new Error("extractFaceTensors - expected image tensor to be 3D or 4D");if(z(o)&&o.shape[0]>1)throw new Error("extractFaceTensors - batchSize > 1 not supported");return Ze.tidy(()=>{let[e,r,n]=o.shape.slice(z(o)?1:0);return t.map(i=>i instanceof M?i.forSize(r,e).box:i).map(i=>i.clipAtImageBorders(r,e)).map(({x:i,y:c,width:m,height:p})=>Ze.slice3d(o.as3D(e,r,n),[c,i,0],[p,m,n]))})}async function Yt(o,t){let{fetch:e}=w.getEnv(),r=await e(o,t);if(!(r.status<400))throw new Error(`failed to fetch: (${r.status}) ${r.statusText}, from url: ${r.url}`);return r}async function Bn(o){let t=await Yt(o),e=await t.blob();if(!e.type.startsWith("image/"))throw new Error(`fetchImage - expected blob type to be of type image/*, instead have: ${e.type}, for url: ${t.url}`);return Gr(e)}async function Ur(o){return(await Yt(o)).json()}async function Rn(o){return new Float32Array(await(await Yt(o)).arrayBuffer())}var Po=b(g());function Ke(o,t){let e=`${t}-weights_manifest.json`;if(!o)return{modelBaseUri:"",manifestUri:e};if(o==="/")return{modelBaseUri:"/",manifestUri:`/${e}`};let r=o.startsWith("http://")?"http://":o.startsWith("https://")?"https://":"";o=o.replace(r,"");let n=o.split("/").filter(i=>i),a=o.endsWith(".json")?n[n.length-1]:e,s=r+(o.endsWith(".json")?n.slice(0,n.length-1):n).join("/");return s=o.startsWith("/")?`/${s}`:s,{modelBaseUri:s,manifestUri:s==="/"?`/${a}`:`${s}/${a}`}}async function Xr(o,t){let{manifestUri:e,modelBaseUri:r}=Ke(o,t),n=await Ur(e);return Po.io.loadWeights(n,r)}function On(o,t,e=!1){let{width:r,height:n}=e?Ht(t):t;return o.width=r,o.height=n,{width:r,height:n}}var Nt=b(g());var gt=b(g());var S=class{constructor(){this._params=void 0;this._paramMappings=[]}get params(){return this._params}get paramMappings(){return this._paramMappings}get isLoaded(){return!!this.params}getParamFromPath(t){let{obj:e,objProp:r}=this.traversePropertyPath(t);return e[r]}reassignParamFromPath(t,e){let{obj:r,objProp:n}=this.traversePropertyPath(t);r[n].dispose(),r[n]=e}getParamList(){return this._paramMappings.map(({paramPath:t})=>({path:t,tensor:this.getParamFromPath(t)}))}getTrainableParams(){return this.getParamList().filter(t=>t.tensor instanceof gt.Variable)}getFrozenParams(){return this.getParamList().filter(t=>!(t.tensor instanceof gt.Variable))}variable(){this.getFrozenParams().forEach(({path:t,tensor:e})=>{this.reassignParamFromPath(t,e.variable())})}freeze(){this.getTrainableParams().forEach(({path:t,tensor:e})=>{let r=gt.tensor(e.dataSync());e.dispose(),this.reassignParamFromPath(t,r)})}dispose(t=!0){this.getParamList().forEach(e=>{if(t&&e.tensor.isDisposed)throw new Error(`param tensor has already been disposed for path ${e.path}`);e.tensor.dispose()}),this._params=void 0}serializeParams(){return new Float32Array(this.getParamList().map(({tensor:t})=>Array.from(t.dataSync())).reduce((t,e)=>t.concat(e)))}async load(t){if(t instanceof Float32Array){this.extractWeights(t);return}await this.loadFromUri(t)}async loadFromUri(t){if(t&&typeof t!="string")throw new Error(`${this._name}.loadFromUri - expected model uri`);let e=await Xr(t,this.getDefaultModelName());this.loadFromWeightMap(e)}async loadFromDisk(t){if(t&&typeof t!="string")throw new Error(`${this._name}.loadFromDisk - expected model file path`);let{readFile:e}=w.getEnv(),{manifestUri:r,modelBaseUri:n}=Ke(t,this.getDefaultModelName()),a=m=>Promise.all(m.map(p=>e(p).then(d=>d.buffer))),s=gt.io.weightsLoaderFactory(a),i=JSON.parse((await e(r)).toString()),c=await s(i,n);this.loadFromWeightMap(c)}loadFromWeightMap(t){let{paramMappings:e,params:r}=this.extractParamsFromWeightMap(t);this._paramMappings=e,this._params=r}extractWeights(t){let{paramMappings:e,params:r}=this.extractParams(t);this._paramMappings=e,this._params=r}traversePropertyPath(t){if(!this.params)throw new Error("traversePropertyPath - model has no loaded params");let e=t.split("/").reduce((a,s)=>{if(!a.nextObj.hasOwnProperty(s))throw new Error(`traversePropertyPath - object does not have property ${s}, for path ${t}`);return{obj:a.nextObj,objProp:s,nextObj:a.nextObj[s]}},{nextObj:this.params}),{obj:r,objProp:n}=e;if(!r||!n||!(r[n]instanceof gt.Tensor))throw new Error(`traversePropertyPath - parameter is not a tensor, for path ${t}`);return{obj:r,objProp:n}}};var C=b(g());var ie=b(g());function $(o,t,e){return ie.tidy(()=>{let r=ie.separableConv2d(o,t.depthwise_filter,t.pointwise_filter,e,"same");return r=ie.add(r,t.bias),r})}function Qe(o,t,e=!1){return C.tidy(()=>{let r=C.relu(e?C.add(C.conv2d(o,t.conv0.filters,[2,2],"same"),t.conv0.bias):$(o,t.conv0,[2,2])),n=$(r,t.conv1,[1,1]),a=C.relu(C.add(r,n)),s=$(a,t.conv2,[1,1]);return C.relu(C.add(r,C.add(n,s)))})}function Le(o,t,e=!1,r=!0){return C.tidy(()=>{let n=C.relu(e?C.add(C.conv2d(o,t.conv0.filters,r?[2,2]:[1,1],"same"),t.conv0.bias):$(o,t.conv0,r?[2,2]:[1,1])),a=$(n,t.conv1,[1,1]),s=C.relu(C.add(n,a)),i=$(s,t.conv2,[1,1]),c=C.relu(C.add(n,C.add(a,i))),m=$(c,t.conv3,[1,1]);return C.relu(C.add(n,C.add(a,C.add(i,m))))})}var Ct=b(g());function Gt(o,t,e="same",r=!1){return Ct.tidy(()=>{let n=Ct.add(Ct.conv2d(o,t.filters,[1,1],e),t.bias);return r?Ct.relu(n):n})}function W(o,t){Object.keys(o).forEach(e=>{t.some(r=>r.originalPath===e)||o[e].dispose()})}var tr=b(g());function ce(o,t){return(e,r,n,a)=>{let s=tr.tensor4d(o(e*r*n*n),[n,n,e,r]),i=tr.tensor1d(o(r));return t.push({paramPath:`${a}/filters`},{paramPath:`${a}/bias`}),{filters:s,bias:i}}}var er=b(g());function rr(o,t){return(e,r,n)=>{let a=er.tensor2d(o(e*r),[e,r]),s=er.tensor1d(o(r));return t.push({paramPath:`${n}/weights`},{paramPath:`${n}/bias`}),{weights:a,bias:s}}}var ke=b(g());var or=class{constructor(t,e,r){this.depthwise_filter=t;this.pointwise_filter=e;this.bias=r}};function me(o,t){return(e,r,n)=>{let a=ke.tensor4d(o(3*3*e),[3,3,e,1]),s=ke.tensor4d(o(e*r),[1,1,e,r]),i=ke.tensor1d(o(r));return t.push({paramPath:`${n}/depthwise_filter`},{paramPath:`${n}/pointwise_filter`},{paramPath:`${n}/bias`}),new or(a,s,i)}}function pe(o){return t=>{let e=o(`${t}/depthwise_filter`,4),r=o(`${t}/pointwise_filter`,4),n=o(`${t}/bias`,1);return new or(e,r,n)}}function j(o,t){return(e,r,n)=>{let a=o[e];if(!Bt(a,r))throw new Error(`expected weightMap[${e}] to be a Tensor${r}D, instead have ${a}`);return t.push({originalPath:e,paramPath:n||e}),a}}function B(o){let t=o;function e(n){let a=t.slice(0,n);return t=t.slice(n),a}function r(){return t}return{extractWeights:e,getRemainingWeights:r}}function nr(o,t){let e=ce(o,t),r=me(o,t);function n(s,i,c,m=!1){let p=m?e(s,i,3,`${c}/conv0`):r(s,i,`${c}/conv0`),d=r(i,i,`${c}/conv1`),u=r(i,i,`${c}/conv2`);return{conv0:p,conv1:d,conv2:u}}function a(s,i,c,m=!1){let{conv0:p,conv1:d,conv2:u}=n(s,i,c,m),l=r(i,i,`${c}/conv3`);return{conv0:p,conv1:d,conv2:u,conv3:l}}return{extractDenseBlock3Params:n,extractDenseBlock4Params:a}}function _o(o){let t=[],{extractWeights:e,getRemainingWeights:r}=B(o),{extractDenseBlock4Params:n}=nr(e,t),a=n(3,32,"dense0",!0),s=n(32,64,"dense1"),i=n(64,128,"dense2"),c=n(128,256,"dense3");if(r().length!==0)throw new Error(`weights remaing after extract: ${r().length}`);return{paramMappings:t,params:{dense0:a,dense1:s,dense2:i,dense3:c}}}function ar(o){return t=>{let e=o(`${t}/filters`,4),r=o(`${t}/bias`,1);return{filters:e,bias:r}}}function sr(o,t){let e=j(o,t),r=ar(e),n=pe(e);function a(i,c=!1){let m=c?r(`${i}/conv0`):n(`${i}/conv0`),p=n(`${i}/conv1`),d=n(`${i}/conv2`);return{conv0:m,conv1:p,conv2:d}}function s(i,c=!1){let m=c?r(`${i}/conv0`):n(`${i}/conv0`),p=n(`${i}/conv1`),d=n(`${i}/conv2`),u=n(`${i}/conv3`);return{conv0:m,conv1:p,conv2:d,conv3:u}}return{extractDenseBlock3Params:a,extractDenseBlock4Params:s}}function wo(o){let t=[],{extractDenseBlock4Params:e}=sr(o,t),r={dense0:e("dense0",!0),dense1:e("dense1"),dense2:e("dense2"),dense3:e("dense3")};return W(o,t),{params:r,paramMappings:t}}var Se=class extends S{constructor(){super("FaceFeatureExtractor")}forwardInput(t){let{params:e}=this;if(!e)throw new Error("FaceFeatureExtractor - load model before inference");return Nt.tidy(()=>{let r=Nt.cast(t.toBatchTensor(112,!0),"float32"),a=ot(r,[122.782,117.001,104.298]).div(Nt.scalar(255)),s=Le(a,e.dense0,!0);return s=Le(s,e.dense1),s=Le(s,e.dense2),s=Le(s,e.dense3),s=Nt.avgPool(s,[7,7],[2,2],"valid"),s})}async forward(t){return this.forwardInput(await E(t))}getDefaultModelName(){return"face_feature_extractor_model"}extractParamsFromWeightMap(t){return wo(t)}extractParams(t){return _o(t)}};var Mo=b(g());var de=b(g());function Ae(o,t){return de.tidy(()=>de.add(de.matMul(o,t.weights),t.bias))}function Do(o,t,e){let r=[],{extractWeights:n,getRemainingWeights:a}=B(o),i=rr(n,r)(t,e,"fc");if(a().length!==0)throw new Error(`weights remaing after extract: ${a().length}`);return{paramMappings:r,params:{fc:i}}}function Eo(o){let t=[],e=j(o,t);function r(a){let s=e(`${a}/weights`,2),i=e(`${a}/bias`,1);return{weights:s,bias:i}}let n={fc:r("fc")};return W(o,t),{params:n,paramMappings:t}}function ir(o){let t={},e={};return Object.keys(o).forEach(r=>{let n=r.startsWith("fc")?e:t;n[r]=o[r]}),{featureExtractorMap:t,classifierMap:e}}var We=class extends S{constructor(t,e){super(t);this._faceFeatureExtractor=e}get faceFeatureExtractor(){return this._faceFeatureExtractor}runNet(t){let{params:e}=this;if(!e)throw new Error(`${this._name} - load model before inference`);return Mo.tidy(()=>{let r=t instanceof bt?this.faceFeatureExtractor.forwardInput(t):t;return Ae(r.as2D(r.shape[0],-1),e.fc)})}dispose(t=!0){this.faceFeatureExtractor.dispose(t),super.dispose(t)}loadClassifierParams(t){let{params:e,paramMappings:r}=this.extractClassifierParams(t);this._params=e,this._paramMappings=r}extractClassifierParams(t){return Do(t,this.getClassifierChannelsIn(),this.getClassifierChannelsOut())}extractParamsFromWeightMap(t){let{featureExtractorMap:e,classifierMap:r}=ir(t);return this.faceFeatureExtractor.loadFromWeightMap(e),Eo(r)}extractParams(t){let e=this.getClassifierChannelsIn(),r=this.getClassifierChannelsOut(),n=r*e+r,a=t.slice(0,t.length-n),s=t.slice(t.length-n);return this.faceFeatureExtractor.extractWeights(a),this.extractClassifierParams(s)}};var Jr=["neutral","happy","sad","angry","fearful","disgusted","surprised"],It=class{constructor(t){if(t.length!==7)throw new Error(`FaceExpressions.constructor - expected probabilities.length to be 7, have: ${t.length}`);Jr.forEach((e,r)=>{this[e]=t[r]})}asSortedArray(){return Jr.map(t=>({expression:t,probability:this[t]})).sort((t,e)=>e.probability-t.probability)}};var cr=class extends We{constructor(t=new Se){super("FaceExpressionNet",t)}forwardInput(t){return ue.tidy(()=>ue.softmax(this.runNet(t)))}async forward(t){return this.forwardInput(await E(t))}async predictExpressions(t){let e=await E(t),r=await this.forwardInput(e),n=await Promise.all(ue.unstack(r).map(async s=>{let i=await s.data();return s.dispose(),i}));r.dispose();let a=n.map(s=>new It(s));return e.isBatchInput?a:a[0]}getDefaultModelName(){return"face_expression_model"}getClassifierChannelsIn(){return 256}getClassifierChannelsOut(){return 7}};function qr(o){return o.expressions instanceof It}function mr(o,t){return{...o,...{expressions:t}}}function $n(o,t,e=.1,r){(Array.isArray(t)?t:[t]).forEach(a=>{let s=a instanceof It?a:qr(a)?a.expressions:void 0;if(!s)throw new Error("drawFaceExpressions - expected faceExpressions to be FaceExpressions | WithFaceExpressions<{}> or array thereof");let c=s.asSortedArray().filter(d=>d.probability>e),m=pt(a)?a.detection.box.bottomLeft:r||new x(0,0);new Mt(c.map(d=>`${d.expression} (${Rt(d.probability)})`),m).draw(o)})}function zt(o){return pt(o)&&o.landmarks instanceof V&&o.unshiftedLandmarks instanceof V&&o.alignedRect instanceof M}function le(o,t){let{box:e}=o.detection,r=t.shiftBy(e.x,e.y),n=r.align(),{imageDims:a}=o.detection,s=new M(o.detection.score,n.rescale(a.reverse()),a);return{...o,...{landmarks:r,unshiftedLandmarks:t,alignedRect:s}}}var Zr=class{constructor(t={}){let{drawLines:e=!0,drawPoints:r=!0,lineWidth:n,lineColor:a,pointSize:s,pointColor:i}=t;this.drawLines=e,this.drawPoints=r,this.lineWidth=n||1,this.pointSize=s||2,this.lineColor=a||"rgba(0, 255, 255, 1)",this.pointColor=i||"rgba(255, 0, 255, 1)"}},Kr=class{constructor(t,e={}){this.faceLandmarks=t,this.options=new Zr(e)}draw(t){let e=O(t),{drawLines:r,drawPoints:n,lineWidth:a,lineColor:s,pointSize:i,pointColor:c}=this.options;if(r&&this.faceLandmarks instanceof oe&&(e.strokeStyle=s,e.lineWidth=a,ft(e,this.faceLandmarks.getJawOutline()),ft(e,this.faceLandmarks.getLeftEyeBrow()),ft(e,this.faceLandmarks.getRightEyeBrow()),ft(e,this.faceLandmarks.getNose()),ft(e,this.faceLandmarks.getLeftEye(),!0),ft(e,this.faceLandmarks.getRightEye(),!0),ft(e,this.faceLandmarks.getMouth(),!0)),n){e.strokeStyle=c,e.fillStyle=c;let m=p=>{e.beginPath(),e.arc(p.x,p.y,i,0,2*Math.PI),e.fill()};this.faceLandmarks.positions.forEach(m)}}};function jn(o,t){(Array.isArray(t)?t:[t]).forEach(r=>{let n=r instanceof V?r:zt(r)?r.landmarks:void 0;if(!n)throw new Error("drawFaceLandmarks - expected faceExpressions to be FaceLandmarks | WithFaceLandmarks<WithFaceDetection<{}>> or array thereof");new Kr(n).draw(o)})}var Co="0.11.4";var ut=b(g());var I=b(g());function Hn(o,t){let e=ce(o,t),r=me(o,t);function n(s,i,c){let m=r(s,i,`${c}/separable_conv0`),p=r(i,i,`${c}/separable_conv1`),d=e(s,i,1,`${c}/expansion_conv`);return{separable_conv0:m,separable_conv1:p,expansion_conv:d}}function a(s,i){let c=r(s,s,`${i}/separable_conv0`),m=r(s,s,`${i}/separable_conv1`),p=r(s,s,`${i}/separable_conv2`);return{separable_conv0:c,separable_conv1:m,separable_conv2:p}}return{extractConvParams:e,extractSeparableConvParams:r,extractReductionBlockParams:n,extractMainBlockParams:a}}function No(o,t){let e=[],{extractWeights:r,getRemainingWeights:n}=B(o),{extractConvParams:a,extractSeparableConvParams:s,extractReductionBlockParams:i,extractMainBlockParams:c}=Hn(r,e),m=a(3,32,3,"entry_flow/conv_in"),p=i(32,64,"entry_flow/reduction_block_0"),d=i(64,128,"entry_flow/reduction_block_1"),u={conv_in:m,reduction_block_0:p,reduction_block_1:d},l={};ct(t,0,1).forEach(y=>{l[`main_block_${y}`]=c(128,`middle_flow/main_block_${y}`)});let v=i(128,256,"exit_flow/reduction_block"),_=s(256,512,"exit_flow/separable_conv"),h={reduction_block:v,separable_conv:_};if(n().length!==0)throw new Error(`weights remaing after extract: ${n().length}`);return{paramMappings:e,params:{entry_flow:u,middle_flow:l,exit_flow:h}}}function Yn(o,t){let e=j(o,t),r=ar(e),n=pe(e);function a(i){let c=n(`${i}/separable_conv0`),m=n(`${i}/separable_conv1`),p=r(`${i}/expansion_conv`);return{separable_conv0:c,separable_conv1:m,expansion_conv:p}}function s(i){let c=n(`${i}/separable_conv0`),m=n(`${i}/separable_conv1`),p=n(`${i}/separable_conv2`);return{separable_conv0:c,separable_conv1:m,separable_conv2:p}}return{extractConvParams:r,extractSeparableConvParams:n,extractReductionBlockParams:a,extractMainBlockParams:s}}function Io(o,t){let e=[],{extractConvParams:r,extractSeparableConvParams:n,extractReductionBlockParams:a,extractMainBlockParams:s}=Yn(o,e),i=r("entry_flow/conv_in"),c=a("entry_flow/reduction_block_0"),m=a("entry_flow/reduction_block_1"),p={conv_in:i,reduction_block_0:c,reduction_block_1:m},d={};ct(t,0,1).forEach(_=>{d[`main_block_${_}`]=s(`middle_flow/main_block_${_}`)});let u=a("exit_flow/reduction_block"),l=n("exit_flow/separable_conv"),v={reduction_block:u,separable_conv:l};return W(o,e),{params:{entry_flow:p,middle_flow:d,exit_flow:v},paramMappings:e}}function Lo(o,t,e){return I.add(I.conv2d(o,t.filters,e,"same"),t.bias)}function to(o,t,e=!0){let r=e?I.relu(o):o;return r=$(r,t.separable_conv0,[1,1]),r=$(I.relu(r),t.separable_conv1,[1,1]),r=I.maxPool(r,[3,3],[2,2],"same"),r=I.add(r,Lo(o,t.expansion_conv,[2,2])),r}function Gn(o,t){let e=$(I.relu(o),t.separable_conv0,[1,1]);return e=$(I.relu(e),t.separable_conv1,[1,1]),e=$(I.relu(e),t.separable_conv2,[1,1]),e=I.add(e,o),e}var eo=class extends S{constructor(t){super("TinyXception");this._numMainBlocks=t}forwardInput(t){let{params:e}=this;if(!e)throw new Error("TinyXception - load model before inference");return I.tidy(()=>{let r=I.cast(t.toBatchTensor(112,!0),"float32"),a=ot(r,[122.782,117.001,104.298]).div(I.scalar(256)),s=I.relu(Lo(a,e.entry_flow.conv_in,[2,2]));return s=to(s,e.entry_flow.reduction_block_0,!1),s=to(s,e.entry_flow.reduction_block_1),ct(this._numMainBlocks,0,1).forEach(i=>{s=Gn(s,e.middle_flow[`main_block_${i}`])}),s=to(s,e.exit_flow.reduction_block),s=I.relu($(s,e.exit_flow.separable_conv,[1,1])),s})}async forward(t){return this.forwardInput(await E(t))}getDefaultModelName(){return"tiny_xception_model"}extractParamsFromWeightMap(t){return Io(t,this._numMainBlocks)}extractParams(t){return No(t,this._numMainBlocks)}};function ko(o){let t=[],{extractWeights:e,getRemainingWeights:r}=B(o),n=rr(e,t),a=n(512,1,"fc/age"),s=n(512,2,"fc/gender");if(r().length!==0)throw new Error(`weights remaing after extract: ${r().length}`);return{paramMappings:t,params:{fc:{age:a,gender:s}}}}function So(o){let t=[],e=j(o,t);function r(a){let s=e(`${a}/weights`,2),i=e(`${a}/bias`,1);return{weights:s,bias:i}}let n={fc:{age:r("fc/age"),gender:r("fc/gender")}};return W(o,t),{params:n,paramMappings:t}}var vt;(function(o){o.FEMALE="female",o.MALE="male"})(vt||(vt={}));var pr=class extends S{constructor(t=new eo(2)){super("AgeGenderNet");this._faceFeatureExtractor=t}get faceFeatureExtractor(){return this._faceFeatureExtractor}runNet(t){let{params:e}=this;if(!e)throw new Error(`${this._name} - load model before inference`);return ut.tidy(()=>{let r=t instanceof bt?this.faceFeatureExtractor.forwardInput(t):t,n=ut.avgPool(r,[7,7],[2,2],"valid").as2D(r.shape[0],-1),a=Ae(n,e.fc.age).as1D(),s=Ae(n,e.fc.gender);return{age:a,gender:s}})}forwardInput(t){return ut.tidy(()=>{let{age:e,gender:r}=this.runNet(t);return{age:e,gender:ut.softmax(r)}})}async forward(t){return this.forwardInput(await E(t))}async predictAgeAndGender(t){let e=await E(t),r=await this.forwardInput(e),n=ut.unstack(r.age),a=ut.unstack(r.gender),s=n.map((c,m)=>({ageTensor:c,genderTensor:a[m]})),i=await Promise.all(s.map(async({ageTensor:c,genderTensor:m})=>{let p=(await c.data())[0],d=(await m.data())[0],u=d>.5,l=u?vt.MALE:vt.FEMALE,v=u?d:1-d;return c.dispose(),m.dispose(),{age:p,gender:l,genderProbability:v}}));return r.age.dispose(),r.gender.dispose(),e.isBatchInput?i:i[0]}getDefaultModelName(){return"age_gender_model"}dispose(t=!0){this.faceFeatureExtractor.dispose(t),super.dispose(t)}loadClassifierParams(t){let{params:e,paramMappings:r}=this.extractClassifierParams(t);this._params=e,this._paramMappings=r}extractClassifierParams(t){return ko(t)}extractParamsFromWeightMap(t){let{featureExtractorMap:e,classifierMap:r}=ir(t);return this.faceFeatureExtractor.loadFromWeightMap(e),So(r)}extractParams(t){let e=512*1+1+(512*2+2),r=t.slice(0,t.length-e),n=t.slice(t.length-e);return this.faceFeatureExtractor.extractWeights(r),this.extractClassifierParams(n)}};var H=b(g());var Be=class extends We{postProcess(t,e,r){let n=r.map(({width:s,height:i})=>{let c=e/Math.max(i,s);return{width:s*c,height:i*c}}),a=n.length;return H.tidy(()=>{let s=(d,u)=>H.stack([H.fill([68],d,"float32"),H.fill([68],u,"float32")],1).as2D(1,136).as1D(),i=(d,u)=>{let{width:l,height:v}=n[d];return u(l,v)?Math.abs(l-v)/2:0},c=d=>i(d,(u,l)=>u<l),m=d=>i(d,(u,l)=>l<u);return t.mul(H.fill([a,136],e,"float32")).sub(H.stack(Array.from(Array(a),(d,u)=>s(c(u),m(u))))).div(H.stack(Array.from(Array(a),(d,u)=>s(n[u].width,n[u].height))))})}forwardInput(t){return H.tidy(()=>{let e=this.runNet(t);return this.postProcess(e,t.inputSize,t.inputDimensions.map(([r,n])=>({height:r,width:n})))})}async forward(t){return this.forwardInput(await E(t))}async detectLandmarks(t){let e=await E(t),r=H.tidy(()=>H.unstack(this.forwardInput(e))),n=await Promise.all(r.map(async(a,s)=>{let i=Array.from(await a.data()),c=i.filter((p,d)=>ze(d)),m=i.filter((p,d)=>!ze(d));return new oe(Array(68).fill(0).map((p,d)=>new x(c[d],m[d])),{height:e.getInputHeight(s),width:e.getInputWidth(s)})}));return r.forEach(a=>a.dispose()),e.isBatchInput?n:n[0]}getClassifierChannelsOut(){return 136}};var fe=class extends Be{constructor(t=new Se){super("FaceLandmark68Net",t)}getDefaultModelName(){return"face_landmark_68_model"}getClassifierChannelsIn(){return 256}};var Lt=b(g());function Ao(o){let t=[],{extractDenseBlock3Params:e}=sr(o,t),r={dense0:e("dense0",!0),dense1:e("dense1"),dense2:e("dense2")};return W(o,t),{params:r,paramMappings:t}}function Wo(o){let t=[],{extractWeights:e,getRemainingWeights:r}=B(o),{extractDenseBlock3Params:n}=nr(e,t),a=n(3,32,"dense0",!0),s=n(32,64,"dense1"),i=n(64,128,"dense2");if(r().length!==0)throw new Error(`weights remaing after extract: ${r().length}`);return{paramMappings:t,params:{dense0:a,dense1:s,dense2:i}}}var ro=class extends S{constructor(){super("TinyFaceFeatureExtractor")}forwardInput(t){let{params:e}=this;if(!e)throw new Error("TinyFaceFeatureExtractor - load model before inference");return Lt.tidy(()=>{let r=Lt.cast(t.toBatchTensor(112,!0),"float32"),a=ot(r,[122.782,117.001,104.298]).div(Lt.scalar(255)),s=Qe(a,e.dense0,!0);return s=Qe(s,e.dense1),s=Qe(s,e.dense2),s=Lt.avgPool(s,[14,14],[2,2],"valid"),s})}async forward(t){return this.forwardInput(await E(t))}getDefaultModelName(){return"face_feature_extractor_tiny_model"}extractParamsFromWeightMap(t){return Ao(t)}extractParams(t){return Wo(t)}};var dr=class extends Be{constructor(t=new ro){super("FaceLandmark68TinyNet",t)}getDefaultModelName(){return"face_landmark_68_tiny_model"}getClassifierChannelsIn(){return 128}};var Bo=class extends fe{};var U=b(g());var he=b(g());var ur=b(g());function Ro(o,t){return ur.add(ur.mul(o,t.weights),t.biases)}function oo(o,t,e,r,n="same"){let{filters:a,bias:s}=t.conv,i=he.conv2d(o,a,e,n);return i=he.add(i,s),i=Ro(i,t.scale),r?he.relu(i):i}function Oo(o,t){return oo(o,t,[1,1],!0)}function no(o,t){return oo(o,t,[1,1],!1)}function lr(o,t){return oo(o,t,[2,2],!0,"valid")}var Y=b(g());function zn(o,t){function e(i,c,m){let p=o(i),d=p.length/(c*m*m);if(Nr(d))throw new Error(`depth has to be an integer: ${d}, weights.length: ${p.length}, numFilters: ${c}, filterSize: ${m}`);return Y.tidy(()=>Y.transpose(Y.tensor4d(p,[c,d,m,m]),[2,3,1,0]))}function r(i,c,m,p){let d=e(i,c,m),u=Y.tensor1d(o(c));return t.push({paramPath:`${p}/filters`},{paramPath:`${p}/bias`}),{filters:d,bias:u}}function n(i,c){let m=Y.tensor1d(o(i)),p=Y.tensor1d(o(i));return t.push({paramPath:`${c}/weights`},{paramPath:`${c}/biases`}),{weights:m,biases:p}}function a(i,c,m,p){let d=r(i,c,m,`${p}/conv`),u=n(c,`${p}/scale`);return{conv:d,scale:u}}function s(i,c,m,p,d=!1){let u=a((d?.5:1)*i,c,m,`${p}/conv1`),l=a(i,c,m,`${p}/conv2`);return{conv1:u,conv2:l}}return{extractConvLayerParams:a,extractResidualLayerParams:s}}function $o(o){let{extractWeights:t,getRemainingWeights:e}=B(o),r=[],{extractConvLayerParams:n,extractResidualLayerParams:a}=zn(t,r),s=n(4704,32,7,"conv32_down"),i=a(9216,32,3,"conv32_1"),c=a(9216,32,3,"conv32_2"),m=a(9216,32,3,"conv32_3"),p=a(36864,64,3,"conv64_down",!0),d=a(36864,64,3,"conv64_1"),u=a(36864,64,3,"conv64_2"),l=a(36864,64,3,"conv64_3"),v=a(147456,128,3,"conv128_down",!0),_=a(147456,128,3,"conv128_1"),h=a(147456,128,3,"conv128_2"),y=a(589824,256,3,"conv256_down",!0),T=a(589824,256,3,"conv256_1"),F=a(589824,256,3,"conv256_2"),L=a(589824,256,3,"conv256_down_out"),G=Y.tidy(()=>Y.transpose(Y.tensor2d(t(256*128),[128,256]),[1,0]));if(r.push({paramPath:"fc"}),e().length!==0)throw new Error(`weights remaing after extract: ${e().length}`);return{params:{conv32_down:s,conv32_1:i,conv32_2:c,conv32_3:m,conv64_down:p,conv64_1:d,conv64_2:u,conv64_3:l,conv128_down:v,conv128_1:_,conv128_2:h,conv256_down:y,conv256_1:T,conv256_2:F,conv256_down_out:L,fc:G},paramMappings:r}}function Vn(o,t){let e=j(o,t);function r(s){let i=e(`${s}/scale/weights`,1),c=e(`${s}/scale/biases`,1);return{weights:i,biases:c}}function n(s){let i=e(`${s}/conv/filters`,4),c=e(`${s}/conv/bias`,1),m=r(s);return{conv:{filters:i,bias:c},scale:m}}function a(s){return{conv1:n(`${s}/conv1`),conv2:n(`${s}/conv2`)}}return{extractConvLayerParams:n,extractResidualLayerParams:a}}function jo(o){let t=[],{extractConvLayerParams:e,extractResidualLayerParams:r}=Vn(o,t),n=e("conv32_down"),a=r("conv32_1"),s=r("conv32_2"),i=r("conv32_3"),c=r("conv64_down"),m=r("conv64_1"),p=r("conv64_2"),d=r("conv64_3"),u=r("conv128_down"),l=r("conv128_1"),v=r("conv128_2"),_=r("conv256_down"),h=r("conv256_1"),y=r("conv256_2"),T=r("conv256_down_out"),{fc:F}=o;if(t.push({originalPath:"fc",paramPath:"fc"}),!Cr(F))throw new Error(`expected weightMap[fc] to be a Tensor2D, instead have ${F}`);let L={conv32_down:n,conv32_1:a,conv32_2:s,conv32_3:i,conv64_down:c,conv64_1:m,conv64_2:p,conv64_3:d,conv128_down:u,conv128_1:l,conv128_2:v,conv256_down:_,conv256_1:h,conv256_2:y,conv256_down_out:T,fc:F};return W(o,t),{params:L,paramMappings:t}}var R=b(g());function nt(o,t){let e=Oo(o,t.conv1);return e=no(e,t.conv2),e=R.add(e,o),e=R.relu(e),e}function Re(o,t){let e=lr(o,t.conv1);e=no(e,t.conv2);let r=R.avgPool(o,2,2,"valid"),n=R.zeros(r.shape),a=r.shape[3]!==e.shape[3];if(r.shape[1]!==e.shape[1]||r.shape[2]!==e.shape[2]){let i=[...e.shape];i[1]=1;let c=R.zeros(i);e=R.concat([e,c],1);let m=[...e.shape];m[2]=1;let p=R.zeros(m);e=R.concat([e,p],2)}return r=a?R.concat([r,n],3):r,e=R.add(r,e),e=R.relu(e),e}var xe=class extends S{constructor(){super("FaceRecognitionNet")}forwardInput(t){let{params:e}=this;if(!e)throw new Error("FaceRecognitionNet - load model before inference");return U.tidy(()=>{let r=U.cast(t.toBatchTensor(150,!0),"float32"),a=ot(r,[122.782,117.001,104.298]).div(U.scalar(256)),s=lr(a,e.conv32_down);s=U.maxPool(s,3,2,"valid"),s=nt(s,e.conv32_1),s=nt(s,e.conv32_2),s=nt(s,e.conv32_3),s=Re(s,e.conv64_down),s=nt(s,e.conv64_1),s=nt(s,e.conv64_2),s=nt(s,e.conv64_3),s=Re(s,e.conv128_down),s=nt(s,e.conv128_1),s=nt(s,e.conv128_2),s=Re(s,e.conv256_down),s=nt(s,e.conv256_1),s=nt(s,e.conv256_2),s=Re(s,e.conv256_down_out);let i=s.mean([1,2]);return U.matMul(i,e.fc)})}async forward(t){return this.forwardInput(await E(t))}async computeFaceDescriptor(t){let e=await E(t),r=U.tidy(()=>U.unstack(this.forwardInput(e))),n=await Promise.all(r.map(a=>a.data()));return r.forEach(a=>a.dispose()),e.isBatchInput?n:n[0]}getDefaultModelName(){return"face_recognition_model"}extractParamsFromWeightMap(t){return jo(t)}extractParams(t){return $o(t)}};function Un(o){let t=new xe;return t.extractWeights(o),t}function fr(o,t){return{...o,...{descriptor:t}}}function Xn(o){return typeof o.age=="number"}function hr(o,t){return{...o,...{age:t}}}function Jn(o){return(o.gender===vt.MALE||o.gender===vt.FEMALE)&&te(o.genderProbability)}function xr(o,t,e){return{...o,...{gender:t,genderProbability:e}}}var st=b(g());var at=b(g());function qn(o,t){function e(c,m){let p=at.tensor4d(o(3*3*c),[3,3,c,1]),d=at.tensor1d(o(c)),u=at.tensor1d(o(c)),l=at.tensor1d(o(c)),v=at.tensor1d(o(c));return t.push({paramPath:`${m}/filters`},{paramPath:`${m}/batch_norm_scale`},{paramPath:`${m}/batch_norm_offset`},{paramPath:`${m}/batch_norm_mean`},{paramPath:`${m}/batch_norm_variance`}),{filters:p,batch_norm_scale:d,batch_norm_offset:u,batch_norm_mean:l,batch_norm_variance:v}}function r(c,m,p,d,u){let l=at.tensor4d(o(c*m*p*p),[p,p,c,m]),v=at.tensor1d(o(m));return t.push({paramPath:`${d}/filters`},{paramPath:`${d}/${u?"batch_norm_offset":"bias"}`}),{filters:l,bias:v}}function n(c,m,p,d){let{filters:u,bias:l}=r(c,m,p,d,!0);return{filters:u,batch_norm_offset:l}}function a(c,m,p){let d=e(c,`${p}/depthwise_conv`),u=n(c,m,1,`${p}/pointwise_conv`);return{depthwise_conv:d,pointwise_conv:u}}function s(){let c=n(3,32,3,"mobilenetv1/conv_0"),m=a(32,64,"mobilenetv1/conv_1"),p=a(64,128,"mobilenetv1/conv_2"),d=a(128,128,"mobilenetv1/conv_3"),u=a(128,256,"mobilenetv1/conv_4"),l=a(256,256,"mobilenetv1/conv_5"),v=a(256,512,"mobilenetv1/conv_6"),_=a(512,512,"mobilenetv1/conv_7"),h=a(512,512,"mobilenetv1/conv_8"),y=a(512,512,"mobilenetv1/conv_9"),T=a(512,512,"mobilenetv1/conv_10"),F=a(512,512,"mobilenetv1/conv_11"),L=a(512,1024,"mobilenetv1/conv_12"),G=a(1024,1024,"mobilenetv1/conv_13");return{conv_0:c,conv_1:m,conv_2:p,conv_3:d,conv_4:u,conv_5:l,conv_6:v,conv_7:_,conv_8:h,conv_9:y,conv_10:T,conv_11:F,conv_12:L,conv_13:G}}function i(){let c=n(1024,256,1,"prediction_layer/conv_0"),m=n(256,512,3,"prediction_layer/conv_1"),p=n(512,128,1,"prediction_layer/conv_2"),d=n(128,256,3,"prediction_layer/conv_3"),u=n(256,128,1,"prediction_layer/conv_4"),l=n(128,256,3,"prediction_layer/conv_5"),v=n(256,64,1,"prediction_layer/conv_6"),_=n(64,128,3,"prediction_layer/conv_7"),h=r(512,12,1,"prediction_layer/box_predictor_0/box_encoding_predictor"),y=r(512,9,1,"prediction_layer/box_predictor_0/class_predictor"),T=r(1024,24,1,"prediction_layer/box_predictor_1/box_encoding_predictor"),F=r(1024,18,1,"prediction_layer/box_predictor_1/class_predictor"),L=r(512,24,1,"prediction_layer/box_predictor_2/box_encoding_predictor"),G=r(512,18,1,"prediction_layer/box_predictor_2/class_predictor"),et=r(256,24,1,"prediction_layer/box_predictor_3/box_encoding_predictor"),it=r(256,18,1,"prediction_layer/box_predictor_3/class_predictor"),X=r(256,24,1,"prediction_layer/box_predictor_4/box_encoding_predictor"),Pt=r(256,18,1,"prediction_layer/box_predictor_4/class_predictor"),_t=r(128,24,1,"prediction_layer/box_predictor_5/box_encoding_predictor"),wt=r(128,18,1,"prediction_layer/box_predictor_5/class_predictor");return{conv_0:c,conv_1:m,conv_2:p,conv_3:d,conv_4:u,conv_5:l,conv_6:v,conv_7:_,box_predictor_0:{box_encoding_predictor:h,class_predictor:y},box_predictor_1:{box_encoding_predictor:T,class_predictor:F},box_predictor_2:{box_encoding_predictor:L,class_predictor:G},box_predictor_3:{box_encoding_predictor:et,class_predictor:it},box_predictor_4:{box_encoding_predictor:X,class_predictor:Pt},box_predictor_5:{box_encoding_predictor:_t,class_predictor:wt}}}return{extractMobilenetV1Params:s,extractPredictionLayerParams:i}}function Ho(o){let t=[],{extractWeights:e,getRemainingWeights:r}=B(o),{extractMobilenetV1Params:n,extractPredictionLayerParams:a}=qn(e,t),s=n(),i=a(),m={extra_dim:at.tensor3d(e(5118*4),[1,5118,4])};if(t.push({paramPath:"output_layer/extra_dim"}),r().length!==0)throw new Error(`weights remaing after extract: ${r().length}`);return{params:{mobilenetv1:s,prediction_layer:i,output_layer:m},paramMappings:t}}function Zn(o,t){let e=j(o,t);function r(m,p,d){let u=e(`${m}/Conv2d_${p}_pointwise/weights`,4,`${d}/filters`),l=e(`${m}/Conv2d_${p}_pointwise/convolution_bn_offset`,1,`${d}/batch_norm_offset`);return{filters:u,batch_norm_offset:l}}function n(m){let p=`mobilenetv1/conv_${m}`,d=`MobilenetV1/Conv2d_${m}_depthwise`,u=`${p}/depthwise_conv`,l=`${p}/pointwise_conv`,v=e(`${d}/depthwise_weights`,4,`${u}/filters`),_=e(`${d}/BatchNorm/gamma`,1,`${u}/batch_norm_scale`),h=e(`${d}/BatchNorm/beta`,1,`${u}/batch_norm_offset`),y=e(`${d}/BatchNorm/moving_mean`,1,`${u}/batch_norm_mean`),T=e(`${d}/BatchNorm/moving_variance`,1,`${u}/batch_norm_variance`);return{depthwise_conv:{filters:v,batch_norm_scale:_,batch_norm_offset:h,batch_norm_mean:y,batch_norm_variance:T},pointwise_conv:r("MobilenetV1",m,l)}}function a(){return{conv_0:r("MobilenetV1",0,"mobilenetv1/conv_0"),conv_1:n(1),conv_2:n(2),conv_3:n(3),conv_4:n(4),conv_5:n(5),conv_6:n(6),conv_7:n(7),conv_8:n(8),conv_9:n(9),conv_10:n(10),conv_11:n(11),conv_12:n(12),conv_13:n(13)}}function s(m,p){let d=e(`${m}/weights`,4,`${p}/filters`),u=e(`${m}/biases`,1,`${p}/bias`);return{filters:d,bias:u}}function i(m){let p=s(`Prediction/BoxPredictor_${m}/BoxEncodingPredictor`,`prediction_layer/box_predictor_${m}/box_encoding_predictor`),d=s(`Prediction/BoxPredictor_${m}/ClassPredictor`,`prediction_layer/box_predictor_${m}/class_predictor`);return{box_encoding_predictor:p,class_predictor:d}}function c(){return{conv_0:r("Prediction",0,"prediction_layer/conv_0"),conv_1:r("Prediction",1,"prediction_layer/conv_1"),conv_2:r("Prediction",2,"prediction_layer/conv_2"),conv_3:r("Prediction",3,"prediction_layer/conv_3"),conv_4:r("Prediction",4,"prediction_layer/conv_4"),conv_5:r("Prediction",5,"prediction_layer/conv_5"),conv_6:r("Prediction",6,"prediction_layer/conv_6"),conv_7:r("Prediction",7,"prediction_layer/conv_7"),box_predictor_0:i(0),box_predictor_1:i(1),box_predictor_2:i(2),box_predictor_3:i(3),box_predictor_4:i(4),box_predictor_5:i(5)}}return{extractMobilenetV1Params:a,extractPredictionLayerParams:c}}function Yo(o){let t=[],{extractMobilenetV1Params:e,extractPredictionLayerParams:r}=Zn(o,t),n=o["Output/extra_dim"];if(t.push({originalPath:"Output/extra_dim",paramPath:"output_layer/extra_dim"}),!ht(n))throw new Error(`expected weightMap['Output/extra_dim'] to be a Tensor3D, instead have ${n}`);let a={mobilenetv1:e(),prediction_layer:r(),output_layer:{extra_dim:n}};return W(o,t),{params:a,paramMappings:t}}var yt=b(g());var kt=b(g());function q(o,t,e){return kt.tidy(()=>{let r=kt.conv2d(o,t.filters,e,"same");return r=kt.add(r,t.batch_norm_offset),kt.clipByValue(r,0,6)})}var Kn=.0010000000474974513;function Qn(o,t,e){return yt.tidy(()=>{let r=yt.depthwiseConv2d(o,t.filters,e,"same");return r=yt.batchNorm(r,t.batch_norm_mean,t.batch_norm_variance,t.batch_norm_offset,t.batch_norm_scale,Kn),yt.clipByValue(r,0,6)})}function ta(o){return[2,4,6,12].some(t=>t===o)?[2,2]:[1,1]}function Go(o,t){return yt.tidy(()=>{let e,r=q(o,t.conv_0,[2,2]);if([t.conv_1,t.conv_2,t.conv_3,t.conv_4,t.conv_5,t.conv_6,t.conv_7,t.conv_8,t.conv_9,t.conv_10,t.conv_11,t.conv_12,t.conv_13].forEach((a,s)=>{let i=s+1,c=ta(i);r=Qn(r,a.depthwise_conv,c),r=q(r,a.pointwise_conv,[1,1]),i===11&&(e=r)}),e===null)throw new Error("mobileNetV1 - output of conv layer 11 is null");return{out:r,conv11:e}})}function ea(o,t,e){let r=o.arraySync(),n=Math.min(r[t][0],r[t][2]),a=Math.min(r[t][1],r[t][3]),s=Math.max(r[t][0],r[t][2]),i=Math.max(r[t][1],r[t][3]),c=Math.min(r[e][0],r[e][2]),m=Math.min(r[e][1],r[e][3]),p=Math.max(r[e][0],r[e][2]),d=Math.max(r[e][1],r[e][3]),u=(s-n)*(i-a),l=(p-c)*(d-m);if(u<=0||l<=0)return 0;let v=Math.max(n,c),_=Math.max(a,m),h=Math.min(s,p),y=Math.min(i,d),T=Math.max(h-v,0)*Math.max(y-_,0);return T/(u+l-T)}function zo(o,t,e,r,n){let a=o.shape[0],s=Math.min(e,a),i=t.map((p,d)=>({score:p,boxIndex:d})).filter(p=>p.score>n).sort((p,d)=>d.score-p.score),c=p=>p<=r?1:0,m=[];return i.forEach(p=>{if(m.length>=s)return;let d=p.score;for(let u=m.length-1;u>=0;--u){let l=ea(o,p.boxIndex,m[u]);if(l!==0&&(p.score*=c(l),p.score<=n))break}d===p.score&&m.push(p.boxIndex)}),m}var f=b(g());function ra(o){let t=f.unstack(f.transpose(o,[1,0])),e=[f.sub(t[2],t[0]),f.sub(t[3],t[1])],r=[f.add(t[0],f.div(e[0],f.scalar(2))),f.add(t[1],f.div(e[1],f.scalar(2)))];return{sizes:e,centers:r}}function oa(o,t){let{sizes:e,centers:r}=ra(o),n=f.unstack(f.transpose(t,[1,0])),a=f.div(f.mul(f.exp(f.div(n[2],f.scalar(5))),e[0]),f.scalar(2)),s=f.add(f.mul(f.div(n[0],f.scalar(10)),e[0]),r[0]),i=f.div(f.mul(f.exp(f.div(n[3],f.scalar(5))),e[1]),f.scalar(2)),c=f.add(f.mul(f.div(n[1],f.scalar(10)),e[1]),r[1]);return f.transpose(f.stack([f.sub(s,a),f.sub(c,i),f.add(s,a),f.add(c,i)]),[1,0])}function Vo(o,t,e){return f.tidy(()=>{let r=o.shape[0],n=oa(f.reshape(f.tile(e.extra_dim,[r,1,1]),[-1,4]),f.reshape(o,[-1,4]));n=f.reshape(n,[r,n.shape[0]/r,4]);let a=f.sigmoid(f.slice(t,[0,0,1],[-1,-1,-1])),s=f.slice(a,[0,0,0],[-1,-1,1]);s=f.reshape(s,[r,s.shape[1]]);let i=f.unstack(n),c=f.unstack(s);return{boxes:i,scores:c}})}var $e=b(g());var Oe=b(g());function Vt(o,t){return Oe.tidy(()=>{let e=o.shape[0],r=Oe.reshape(Gt(o,t.box_encoding_predictor),[e,-1,1,4]),n=Oe.reshape(Gt(o,t.class_predictor),[e,-1,3]);return{boxPredictionEncoding:r,classPrediction:n}})}function Uo(o,t,e){return $e.tidy(()=>{let r=q(o,e.conv_0,[1,1]),n=q(r,e.conv_1,[2,2]),a=q(n,e.conv_2,[1,1]),s=q(a,e.conv_3,[2,2]),i=q(s,e.conv_4,[1,1]),c=q(i,e.conv_5,[2,2]),m=q(c,e.conv_6,[1,1]),p=q(m,e.conv_7,[2,2]),d=Vt(t,e.box_predictor_0),u=Vt(o,e.box_predictor_1),l=Vt(n,e.box_predictor_2),v=Vt(s,e.box_predictor_3),_=Vt(c,e.box_predictor_4),h=Vt(p,e.box_predictor_5),y=$e.concat([d.boxPredictionEncoding,u.boxPredictionEncoding,l.boxPredictionEncoding,v.boxPredictionEncoding,_.boxPredictionEncoding,h.boxPredictionEncoding],1),T=$e.concat([d.classPrediction,u.classPrediction,l.classPrediction,v.classPrediction,_.classPrediction,h.classPrediction],1);return{boxPredictions:y,classPredictions:T}})}var Z=class{constructor({minConfidence:t,maxResults:e}={}){this._name="SsdMobilenetv1Options";if(this._minConfidence=t||.5,this._maxResults=e||100,typeof this._minConfidence!="number"||this._minConfidence<=0||this._minConfidence>=1)throw new Error(`${this._name} - expected minConfidence to be a number between 0 and 1`);if(typeof this._maxResults!="number")throw new Error(`${this._name} - expected maxResults to be a number`)}get minConfidence(){return this._minConfidence}get maxResults(){return this._maxResults}};var Ut=class extends S{constructor(){super("SsdMobilenetv1")}forwardInput(t){let{params:e}=this;if(!e)throw new Error("SsdMobilenetv1 - load model before inference");return st.tidy(()=>{let r=st.cast(t.toBatchTensor(512,!1),"float32"),n=st.sub(st.mul(r,st.scalar(.007843137718737125)),st.scalar(1)),a=Go(n,e.mobilenetv1),{boxPredictions:s,classPredictions:i}=Uo(a.out,a.conv11,e.prediction_layer);return Vo(s,i,e.output_layer)})}async forward(t){return this.forwardInput(await E(t))}async locateFaces(t,e={}){let{maxResults:r,minConfidence:n}=new Z(e),a=await E(t),{boxes:s,scores:i}=this.forwardInput(a),c=s[0],m=i[0];for(let F=1;F<s.length;F++)s[F].dispose(),i[F].dispose();let p=Array.from(await m.data()),u=zo(c,p,r,.5,n),l=a.getReshapedInputDimensions(0),v=a.inputSize,_=v/l.width,h=v/l.height,y=c.arraySync(),T=u.map(F=>{let[L,G]=[Math.max(0,y[F][0]),Math.min(1,y[F][2])].map(X=>X*h),[et,it]=[Math.max(0,y[F][1]),Math.min(1,y[F][3])].map(X=>X*_);return new M(p[F],new re(et,L,it-et,G-L),{height:a.getInputHeight(0),width:a.getInputWidth(0)})});return c.dispose(),m.dispose(),T}getDefaultModelName(){return"ssd_mobilenetv1_model"}extractParamsFromWeightMap(t){return Yo(t)}extractParams(t){return Ho(t)}};function Xo(o){let t=new Ut;return t.extractWeights(o),t}function na(o){return Xo(o)}var Jo=class extends Ut{};var qo=.4,Zo=[new x(.738768,.874946),new x(2.42204,2.65704),new x(4.30971,7.04493),new x(10.246,4.59428),new x(12.6868,11.8741)],Ko=[new x(1.603231,2.094468),new x(6.041143,7.080126),new x(2.882459,3.518061),new x(4.266906,5.178857),new x(9.041765,10.66308)],Qo=[117.001,114.697,97.404],tn="tiny_yolov2_model",en="tiny_yolov2_separable_conv_model";var N=b(g());var br=o=>typeof o=="number";function ao(o){if(!o)throw new Error(`invalid config: ${o}`);if(typeof o.withSeparableConvs!="boolean")throw new Error(`config.withSeparableConvs has to be a boolean, have: ${o.withSeparableConvs}`);if(!br(o.iouThreshold)||o.iouThreshold<0||o.iouThreshold>1)throw new Error(`config.iouThreshold has to be a number between [0, 1], have: ${o.iouThreshold}`);if(!Array.isArray(o.classes)||!o.classes.length||!o.classes.every(t=>typeof t=="string"))throw new Error(`config.classes has to be an array class names: string[], have: ${JSON.stringify(o.classes)}`);if(!Array.isArray(o.anchors)||!o.anchors.length||!o.anchors.map(t=>t||{}).every(t=>br(t.x)&&br(t.y)))throw new Error(`config.anchors has to be an array of { x: number, y: number }, have: ${JSON.stringify(o.anchors)}`);if(o.meanRgb&&(!Array.isArray(o.meanRgb)||o.meanRgb.length!==3||!o.meanRgb.every(br)))throw new Error(`config.meanRgb has to be an array of shape [number, number, number], have: ${JSON.stringify(o.meanRgb)}`)}var Q=b(g());var K=b(g());function be(o){return K.tidy(()=>{let t=K.mul(o,K.scalar(.10000000149011612));return K.add(K.relu(K.sub(o,t)),t)})}function Ft(o,t){return Q.tidy(()=>{let e=Q.pad(o,[[0,0],[1,1],[1,1],[0,0]]);return e=Q.conv2d(e,t.conv.filters,[1,1],"valid"),e=Q.sub(e,t.bn.sub),e=Q.mul(e,t.bn.truediv),e=Q.add(e,t.conv.bias),be(e)})}var St=b(g());function Tt(o,t){return St.tidy(()=>{let e=St.pad(o,[[0,0],[1,1],[1,1],[0,0]]);return e=St.separableConv2d(e,t.depthwise_filter,t.pointwise_filter,[1,1],"valid"),e=St.add(e,t.bias),be(e)})}var so=b(g());function aa(o,t){let e=ce(o,t);function r(s,i){let c=so.tensor1d(o(s)),m=so.tensor1d(o(s));return t.push({paramPath:`${i}/sub`},{paramPath:`${i}/truediv`}),{sub:c,truediv:m}}function n(s,i,c){let m=e(s,i,3,`${c}/conv`),p=r(i,`${c}/bn`);return{conv:m,bn:p}}let a=me(o,t);return{extractConvParams:e,extractConvWithBatchNormParams:n,extractSeparableConvParams:a}}function rn(o,t,e,r){let{extractWeights:n,getRemainingWeights:a}=B(o),s=[],{extractConvParams:i,extractConvWithBatchNormParams:c,extractSeparableConvParams:m}=aa(n,s),p;if(t.withSeparableConvs){let[d,u,l,v,_,h,y,T,F]=r,L=t.isFirstLayerConv2d?i(d,u,3,"conv0"):m(d,u,"conv0"),G=m(u,l,"conv1"),et=m(l,v,"conv2"),it=m(v,_,"conv3"),X=m(_,h,"conv4"),Pt=m(h,y,"conv5"),_t=T?m(y,T,"conv6"):void 0,wt=F?m(T,F,"conv7"):void 0,Qt=i(F||T||y,5*e,1,"conv8");p={conv0:L,conv1:G,conv2:et,conv3:it,conv4:X,conv5:Pt,conv6:_t,conv7:wt,conv8:Qt}}else{let[d,u,l,v,_,h,y,T,F]=r,L=c(d,u,"conv0"),G=c(u,l,"conv1"),et=c(l,v,"conv2"),it=c(v,_,"conv3"),X=c(_,h,"conv4"),Pt=c(h,y,"conv5"),_t=c(y,T,"conv6"),wt=c(T,F,"conv7"),Qt=i(F,5*e,1,"conv8");p={conv0:L,conv1:G,conv2:et,conv3:it,conv4:X,conv5:Pt,conv6:_t,conv7:wt,conv8:Qt}}if(a().length!==0)throw new Error(`weights remaing after extract: ${a().length}`);return{params:p,paramMappings:s}}function sa(o,t){let e=j(o,t);function r(i){let c=e(`${i}/sub`,1),m=e(`${i}/truediv`,1);return{sub:c,truediv:m}}function n(i){let c=e(`${i}/filters`,4),m=e(`${i}/bias`,1);return{filters:c,bias:m}}function a(i){let c=n(`${i}/conv`),m=r(`${i}/bn`);return{conv:c,bn:m}}let s=pe(e);return{extractConvParams:n,extractConvWithBatchNormParams:a,extractSeparableConvParams:s}}function on(o,t){let e=[],{extractConvParams:r,extractConvWithBatchNormParams:n,extractSeparableConvParams:a}=sa(o,e),s;if(t.withSeparableConvs){let i=t.filterSizes&&t.filterSizes.length||9;s={conv0:t.isFirstLayerConv2d?r("conv0"):a("conv0"),conv1:a("conv1"),conv2:a("conv2"),conv3:a("conv3"),conv4:a("conv4"),conv5:a("conv5"),conv6:i>7?a("conv6"):void 0,conv7:i>8?a("conv7"):void 0,conv8:r("conv8")}}else s={conv0:n("conv0"),conv1:n("conv1"),conv2:n("conv2"),conv3:n("conv3"),conv4:n("conv4"),conv5:n("conv5"),conv6:n("conv6"),conv7:n("conv7"),conv8:r("conv8")};return W(o,e),{params:s,paramMappings:e}}var lt=class{constructor({inputSize:t,scoreThreshold:e}={}){this._name="TinyYolov2Options";if(this._inputSize=t||416,this._scoreThreshold=e||.5,typeof this._inputSize!="number"||this._inputSize%32!=0)throw new Error(`${this._name} - expected inputSize to be a number divisible by 32`);if(typeof this._scoreThreshold!="number"||this._scoreThreshold<=0||this._scoreThreshold>=1)throw new Error(`${this._name} - expected scoreThreshold to be a number between 0 and 1`)}get inputSize(){return this._inputSize}get scoreThreshold(){return this._scoreThreshold}};var io=class extends S{constructor(t){super("TinyYolov2");ao(t),this._config=t}get config(){return this._config}get withClassScores(){return this.config.withClassScores||this.config.classes.length>1}get boxEncodingSize(){return 5+(this.withClassScores?this.config.classes.length:0)}runTinyYolov2(t,e){let r=Ft(t,e.conv0);return r=N.maxPool(r,[2,2],[2,2],"same"),r=Ft(r,e.conv1),r=N.maxPool(r,[2,2],[2,2],"same"),r=Ft(r,e.conv2),r=N.maxPool(r,[2,2],[2,2],"same"),r=Ft(r,e.conv3),r=N.maxPool(r,[2,2],[2,2],"same"),r=Ft(r,e.conv4),r=N.maxPool(r,[2,2],[2,2],"same"),r=Ft(r,e.conv5),r=N.maxPool(r,[2,2],[1,1],"same"),r=Ft(r,e.conv6),r=Ft(r,e.conv7),Gt(r,e.conv8,"valid",!1)}runMobilenet(t,e){let r=this.config.isFirstLayerConv2d?be(Gt(t,e.conv0,"valid",!1)):Tt(t,e.conv0);return r=N.maxPool(r,[2,2],[2,2],"same"),r=Tt(r,e.conv1),r=N.maxPool(r,[2,2],[2,2],"same"),r=Tt(r,e.conv2),r=N.maxPool(r,[2,2],[2,2],"same"),r=Tt(r,e.conv3),r=N.maxPool(r,[2,2],[2,2],"same"),r=Tt(r,e.conv4),r=N.maxPool(r,[2,2],[2,2],"same"),r=Tt(r,e.conv5),r=N.maxPool(r,[2,2],[1,1],"same"),r=e.conv6?Tt(r,e.conv6):r,r=e.conv7?Tt(r,e.conv7):r,Gt(r,e.conv8,"valid",!1)}forwardInput(t,e){let{params:r}=this;if(!r)throw new Error("TinyYolov2 - load model before inference");return N.tidy(()=>{let n=N.cast(t.toBatchTensor(e,!1),"float32");return n=this.config.meanRgb?ot(n,this.config.meanRgb):n,n=n.div(N.scalar(256)),this.config.withSeparableConvs?this.runMobilenet(n,r):this.runTinyYolov2(n,r)})}async forward(t,e){return this.forwardInput(await E(t),e)}async detect(t,e={}){let{inputSize:r,scoreThreshold:n}=new lt(e),a=await E(t),s=await this.forwardInput(a,r),i=N.tidy(()=>N.unstack(s)[0].expandDims()),c={width:a.getInputWidth(0),height:a.getInputHeight(0)},m=await this.extractBoxes(i,a.getReshapedInputDimensions(0),n);s.dispose(),i.dispose();let p=m.map(h=>h.box),d=m.map(h=>h.score),u=m.map(h=>h.classScore),l=m.map(h=>this.config.classes[h.label]);return Sr(p.map(h=>h.rescale(r)),d,this.config.iouThreshold,!0).map(h=>new Dt(d[h],u[h],l[h],p[h],c))}getDefaultModelName(){return""}extractParamsFromWeightMap(t){return on(t,this.config)}extractParams(t){let e=this.config.filterSizes||io.DEFAULT_FILTER_SIZES,r=e?e.length:void 0;if(r!==7&&r!==8&&r!==9)throw new Error(`TinyYolov2 - expected 7 | 8 | 9 convolutional filters, but found ${r} filterSizes in config`);return rn(t,this.config,this.boxEncodingSize,e)}async extractBoxes(t,e,r){let{width:n,height:a}=e,s=Math.max(n,a),i=s/n,c=s/a,m=t.shape[1],p=this.config.anchors.length,[d,u,l]=N.tidy(()=>{let y=t.reshape([m,m,p,this.boxEncodingSize]),T=y.slice([0,0,0,0],[m,m,p,4]),F=y.slice([0,0,0,4],[m,m,p,1]),L=this.withClassScores?N.softmax(y.slice([0,0,0,5],[m,m,p,this.config.classes.length]),3):N.scalar(0);return[T,F,L]}),v=[],_=await u.array(),h=await d.array();for(let y=0;y<m;y++)for(let T=0;T<m;T++)for(let F=0;F<p;F++){let L=De(_[y][T][F][0]);if(!r||L>r){let G=(T+De(h[y][T][F][0]))/m*i,et=(y+De(h[y][T][F][1]))/m*c,it=Math.exp(h[y][T][F][2])*this.config.anchors[F].x/m*i,X=Math.exp(h[y][T][F][3])*this.config.anchors[F].y/m*c,Pt=G-it/2,_t=et-X/2,wt={row:y,col:T,anchor:F},{classScore:Qt,label:lo}=this.withClassScores?await this.extractPredictedClass(l,wt):{classScore:1,label:0};v.push({box:new ee(Pt,_t,Pt+it,_t+X),score:L,classScore:L*Qt,label:lo,...wt})}}return d.dispose(),u.dispose(),l.dispose(),v}async extractPredictedClass(t,e){let{row:r,col:n,anchor:a}=e,s=await t.array();return Array(this.config.classes.length).fill(0).map((i,c)=>s[r][n][a][c]).map((i,c)=>({classScore:i,label:c})).reduce((i,c)=>i.classScore>c.classScore?i:c)}},ge=io;ge.DEFAULT_FILTER_SIZES=[3,16,32,64,128,256,512,1024,1024];var ve=class extends ge{constructor(t=!0){let e={withSeparableConvs:t,iouThreshold:qo,classes:["face"],...t?{anchors:Ko,meanRgb:Qo}:{anchors:Zo,withClassScores:!0}};super(e)}get withSeparableConvs(){return this.config.withSeparableConvs}get anchors(){return this.config.anchors}async locateFaces(t,e){return(await this.detect(t,e)).map(n=>new M(n.score,n.relativeBox,{width:n.imageWidth,height:n.imageHeight}))}getDefaultModelName(){return this.withSeparableConvs?en:tn}extractParamsFromWeightMap(t){return super.extractParamsFromWeightMap(t)}};function ia(o,t=!0){let e=new ve(t);return e.extractWeights(o),e}var gr=class extends lt{constructor(){super(...arguments);this._name="TinyFaceDetectorOptions"}};var tt=class{async then(t){return t(await this.run())}async run(){throw new Error("ComposableTask - run is not implemented")}};var je=b(g());var co=b(g());async function Xt(o,t,e,r,n=({alignedRect:a})=>a){let a=o.map(c=>zt(c)?n(c):c.detection),s=r||(t instanceof co.Tensor?await se(t,a):await ae(t,a)),i=await e(s);return s.forEach(c=>c instanceof co.Tensor&&c.dispose()),i}async function ye(o,t,e,r,n){return Xt([o],t,async a=>e(a[0]),r,n)}var nn=.4,an=[new x(1.603231,2.094468),new x(6.041143,7.080126),new x(2.882459,3.518061),new x(4.266906,5.178857),new x(9.041765,10.66308)],sn=[117.001,114.697,97.404];var Fe=class extends ge{constructor(){let t={withSeparableConvs:!0,iouThreshold:nn,classes:["face"],anchors:an,meanRgb:sn,isFirstLayerConv2d:!0,filterSizes:[3,16,32,64,128,256,512]};super(t)}get anchors(){return this.config.anchors}async locateFaces(t,e){return(await this.detect(t,e)).map(n=>new M(n.score,n.relativeBox,{width:n.imageWidth,height:n.imageHeight}))}getDefaultModelName(){return"tiny_face_detector_model"}extractParamsFromWeightMap(t){return super.extractParamsFromWeightMap(t)}};var P={ssdMobilenetv1:new Ut,tinyFaceDetector:new Fe,tinyYolov2:new ve,faceLandmark68Net:new fe,faceLandmark68TinyNet:new dr,faceRecognitionNet:new xe,faceExpressionNet:new cr,ageGenderNet:new pr},cn=(o,t)=>P.ssdMobilenetv1.locateFaces(o,t),ca=(o,t)=>P.tinyFaceDetector.locateFaces(o,t),ma=(o,t)=>P.tinyYolov2.locateFaces(o,t),mn=o=>P.faceLandmark68Net.detectLandmarks(o),pa=o=>P.faceLandmark68TinyNet.detectLandmarks(o),da=o=>P.faceRecognitionNet.computeFaceDescriptor(o),ua=o=>P.faceExpressionNet.predictExpressions(o),la=o=>P.ageGenderNet.predictAgeAndGender(o),pn=o=>P.ssdMobilenetv1.load(o),fa=o=>P.tinyFaceDetector.load(o),ha=o=>P.tinyYolov2.load(o),xa=o=>P.faceLandmark68Net.load(o),ba=o=>P.faceLandmark68TinyNet.load(o),ga=o=>P.faceRecognitionNet.load(o),va=o=>P.faceExpressionNet.load(o),ya=o=>P.ageGenderNet.load(o),Fa=pn,Ta=cn,Pa=mn;var mo=class extends tt{constructor(t,e,r){super();this.parentTask=t;this.input=e;this.extractedFaces=r}},_e=class extends mo{async run(){let t=await this.parentTask,e=await Xt(t,this.input,async r=>Promise.all(r.map(n=>P.faceExpressionNet.predictExpressions(n))),this.extractedFaces);return t.map((r,n)=>mr(r,e[n]))}withAgeAndGender(){return new Te(this,this.input)}},we=class extends mo{async run(){let t=await this.parentTask;if(!t)return;let e=await ye(t,this.input,r=>P.faceExpressionNet.predictExpressions(r),this.extractedFaces);return mr(t,e)}withAgeAndGender(){return new Pe(this,this.input)}},Zt=class extends _e{withAgeAndGender(){return new Jt(this,this.input)}withFaceDescriptors(){return new At(this,this.input)}},Kt=class extends we{withAgeAndGender(){return new qt(this,this.input)}withFaceDescriptor(){return new Wt(this,this.input)}};var po=class extends tt{constructor(t,e,r){super();this.parentTask=t;this.input=e;this.extractedFaces=r}},Te=class extends po{async run(){let t=await this.parentTask,e=await Xt(t,this.input,async r=>Promise.all(r.map(n=>P.ageGenderNet.predictAgeAndGender(n))),this.extractedFaces);return t.map((r,n)=>{let{age:a,gender:s,genderProbability:i}=e[n];return hr(xr(r,s,i),a)})}withFaceExpressions(){return new _e(this,this.input)}},Pe=class extends po{async run(){let t=await this.parentTask;if(!t)return;let{age:e,gender:r,genderProbability:n}=await ye(t,this.input,a=>P.ageGenderNet.predictAgeAndGender(a),this.extractedFaces);return hr(xr(t,r,n),e)}withFaceExpressions(){return new we(this,this.input)}},Jt=class extends Te{withFaceExpressions(){return new Zt(this,this.input)}withFaceDescriptors(){return new At(this,this.input)}},qt=class extends Pe{withFaceExpressions(){return new Kt(this,this.input)}withFaceDescriptor(){return new Wt(this,this.input)}};var vr=class extends tt{constructor(t,e){super();this.parentTask=t;this.input=e}},At=class extends vr{async run(){let t=await this.parentTask;return(await Xt(t,this.input,r=>Promise.all(r.map(n=>P.faceRecognitionNet.computeFaceDescriptor(n))),null,r=>r.landmarks.align(null,{useDlibAlignment:!0}))).map((r,n)=>fr(t[n],r))}withFaceExpressions(){return new Zt(this,this.input)}withAgeAndGender(){return new Jt(this,this.input)}},Wt=class extends vr{async run(){let t=await this.parentTask;if(!t)return;let e=await ye(t,this.input,r=>P.faceRecognitionNet.computeFaceDescriptor(r),null,r=>r.landmarks.align(null,{useDlibAlignment:!0}));return fr(t,e)}withFaceExpressions(){return new Kt(this,this.input)}withAgeAndGender(){return new qt(this,this.input)}};var yr=class extends tt{constructor(t,e,r){super();this.parentTask=t;this.input=e;this.useTinyLandmarkNet=r}get landmarkNet(){return this.useTinyLandmarkNet?P.faceLandmark68TinyNet:P.faceLandmark68Net}},Fr=class extends yr{async run(){let t=await this.parentTask,e=t.map(a=>a.detection),r=this.input instanceof je.Tensor?await se(this.input,e):await ae(this.input,e),n=await Promise.all(r.map(a=>this.landmarkNet.detectLandmarks(a)));return r.forEach(a=>a instanceof je.Tensor&&a.dispose()),t.map((a,s)=>le(a,n[s]))}withFaceExpressions(){return new Zt(this,this.input)}withAgeAndGender(){return new Jt(this,this.input)}withFaceDescriptors(){return new At(this,this.input)}},Tr=class extends yr{async run(){let t=await this.parentTask;if(!t)return;let{detection:e}=t,r=this.input instanceof je.Tensor?await se(this.input,[e]):await ae(this.input,[e]),n=await this.landmarkNet.detectLandmarks(r[0]);return r.forEach(a=>a instanceof je.Tensor&&a.dispose()),le(t,n)}withFaceExpressions(){return new Kt(this,this.input)}withAgeAndGender(){return new qt(this,this.input)}withFaceDescriptor(){return new Wt(this,this.input)}};var Pr=class extends tt{constructor(t,e=new Z){super();this.input=t;this.options=e}},He=class extends Pr{async run(){let{input:t,options:e}=this,r=e instanceof gr?n=>P.tinyFaceDetector.locateFaces(n,e):e instanceof Z?n=>P.ssdMobilenetv1.locateFaces(n,e):e instanceof lt?n=>P.tinyYolov2.locateFaces(n,e):null;if(!r)throw new Error("detectFaces - expected options to be instance of TinyFaceDetectorOptions | SsdMobilenetv1Options | MtcnnOptions | TinyYolov2Options");return r(t)}runAndExtendWithFaceDetections(){return new Promise(async t=>{let e=await this.run();t(e.map(r=>$t({},r)))})}withFaceLandmarks(t=!1){return new Fr(this.runAndExtendWithFaceDetections(),this.input,t)}withFaceExpressions(){return new _e(this.runAndExtendWithFaceDetections(),this.input)}withAgeAndGender(){return new Te(this.runAndExtendWithFaceDetections(),this.input)}},_r=class extends Pr{async run(){let t=await new He(this.input,this.options),e=t[0];return t.forEach(r=>{r.score>e.score&&(e=r)}),e}runAndExtendWithFaceDetection(){return new Promise(async t=>{let e=await this.run();t(e?$t({},e):void 0)})}withFaceLandmarks(t=!1){return new Tr(this.runAndExtendWithFaceDetection(),this.input,t)}withFaceExpressions(){return new we(this.runAndExtendWithFaceDetection(),this.input)}withAgeAndGender(){return new Pe(this.runAndExtendWithFaceDetection(),this.input)}};function _a(o,t=new Z){return new _r(o,t)}function wr(o,t=new Z){return new He(o,t)}async function dn(o,t){return wr(o,new Z(t?{minConfidence:t}:{})).withFaceLandmarks().withFaceDescriptors()}async function wa(o,t={}){return wr(o,new lt(t)).withFaceLandmarks().withFaceDescriptors()}var Da=dn;function uo(o,t){if(o.length!==t.length)throw new Error("euclideanDistance: arr1.length !== arr2.length");let e=Array.from(o),r=Array.from(t);return Math.sqrt(e.map((n,a)=>n-r[a]).reduce((n,a)=>n+a**2,0))}var Dr=class{constructor(t,e=.6){this._distanceThreshold=e;let r=Array.isArray(t)?t:[t];if(!r.length)throw new Error("FaceRecognizer.constructor - expected atleast one input");let n=1,a=()=>`person ${n++}`;this._labeledDescriptors=r.map(s=>{if(s instanceof xt)return s;if(s instanceof Float32Array)return new xt(a(),[s]);if(s.descriptor&&s.descriptor instanceof Float32Array)return new xt(a(),[s.descriptor]);throw new Error("FaceRecognizer.constructor - expected inputs to be of type LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array | Array<LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array>")})}get labeledDescriptors(){return this._labeledDescriptors}get distanceThreshold(){return this._distanceThreshold}computeMeanDistance(t,e){return e.map(r=>uo(r,t)).reduce((r,n)=>r+n,0)/(e.length||1)}matchDescriptor(t){return this.labeledDescriptors.map(({descriptors:e,label:r})=>new Ee(r,this.computeMeanDistance(t,e))).reduce((e,r)=>e.distance<r.distance?e:r)}findBestMatch(t){let e=this.matchDescriptor(t);return e.distance<this.distanceThreshold?e:new Ee("unknown",e.distance)}toJSON(){return{distanceThreshold:this.distanceThreshold,labeledDescriptors:this.labeledDescriptors.map(t=>t.toJSON())}}static fromJSON(t){let e=t.labeledDescriptors.map(r=>xt.fromJSON(r));return new Dr(e,t.distanceThreshold)}};function Ea(o){let t=new Fe;return t.extractWeights(o),t}function un(o,t){let{width:e,height:r}=new A(t.width,t.height);if(e<=0||r<=0)throw new Error(`resizeResults - invalid dimensions: ${JSON.stringify({width:e,height:r})}`);if(Array.isArray(o))return o.map(n=>un(n,{width:e,height:r}));if(zt(o)){let n=o.detection.forSize(e,r),a=o.unshiftedLandmarks.forSize(n.box.width,n.box.height);return le($t(o,n),a)}return pt(o)?$t(o,o.detection.forSize(e,r)):o instanceof V||o instanceof M?o.forSize(e,r):o}var Ca=typeof process!="undefined",Na=typeof navigator!="undefined"&&typeof navigator.userAgent!="undefined",Ia={faceapi:Co,node:Ca,browser:Na};
+var ln = Object.create,
+  Ye = Object.defineProperty,
+  fn = Object.getPrototypeOf,
+  hn = Object.prototype.hasOwnProperty,
+  xn = Object.getOwnPropertyNames,
+  bn = Object.getOwnPropertyDescriptor
+var fo = o => Ye(o, '__esModule', {value: !0})
+var ho = (o, t) => () => (t || ((t = {exports: {}}), o(t.exports, t)), t.exports),
+  Ge = (o, t) => {
+    fo(o)
+    for (var e in t) Ye(o, e, {get: t[e], enumerable: !0})
+  },
+  gn = (o, t, e) => {
+    if ((fo(o), (t && typeof t == 'object') || typeof t == 'function'))
+      for (let r of xn(t))
+        !hn.call(o, r) &&
+          r !== 'default' &&
+          Ye(o, r, {get: () => t[r], enumerable: !(e = bn(t, r)) || e.enumerable})
+    return o
+  },
+  b = o =>
+    o && o.__esModule
+      ? o
+      : gn(Ye(o != null ? ln(fn(o)) : {}, 'default', {value: o, enumerable: !0}), o)
+var g = ho(xo => {
+  var vn = Object.create,
+    Er = Object.defineProperty,
+    yn = Object.getPrototypeOf,
+    Fn = Object.prototype.hasOwnProperty,
+    Tn = Object.getOwnPropertyNames,
+    Pn = Object.getOwnPropertyDescriptor,
+    _n = o => Er(o, '__esModule', {value: !0}),
+    bo = (o, t, e) => {
+      if ((_n(o), (t && typeof t == 'object') || typeof t == 'function'))
+        for (let r of Tn(t))
+          !Fn.call(o, r) &&
+            r !== 'default' &&
+            Er(o, r, {get: () => t[r], enumerable: !(e = Pn(t, r)) || e.enumerable})
+      return o
+    },
+    wn = o =>
+      o && o.__esModule
+        ? o
+        : bo(Er(o != null ? vn(yn(o)) : {}, 'default', {value: o, enumerable: !0}), o)
+  bo(xo, wn(require('@tensorflow/tfjs-node')))
+})
+var To = ho((Ln, Fo) => {
+  Ge(Ln, {isNodejs: () => kn})
+  function kn() {
+    return (
+      typeof global == 'object' &&
+      !0 &&
+      typeof Fo != 'undefined' &&
+      typeof process != 'undefined' &&
+      !!process.version
+    )
+  }
+})
+Ge(exports, {
+  AgeGenderNet: () => pr,
+  BoundingBox: () => ee,
+  Box: () => D,
+  ComposableTask: () => tt,
+  ComputeAllFaceDescriptorsTask: () => At,
+  ComputeFaceDescriptorsTaskBase: () => vr,
+  ComputeSingleFaceDescriptorTask: () => Wt,
+  DetectAllFaceLandmarksTask: () => Fr,
+  DetectAllFacesTask: () => He,
+  DetectFaceLandmarksTaskBase: () => yr,
+  DetectFacesTaskBase: () => Pr,
+  DetectSingleFaceLandmarksTask: () => Tr,
+  DetectSingleFaceTask: () => _r,
+  Dimensions: () => A,
+  FACE_EXPRESSION_LABELS: () => Jr,
+  FaceDetection: () => M,
+  FaceDetectionNet: () => Jo,
+  FaceExpressionNet: () => cr,
+  FaceExpressions: () => It,
+  FaceLandmark68Net: () => fe,
+  FaceLandmark68TinyNet: () => dr,
+  FaceLandmarkNet: () => Bo,
+  FaceLandmarks: () => V,
+  FaceLandmarks5: () => vo,
+  FaceLandmarks68: () => oe,
+  FaceMatch: () => Ee,
+  FaceMatcher: () => Dr,
+  FaceRecognitionNet: () => xe,
+  Gender: () => vt,
+  LabeledBox: () => Me,
+  LabeledFaceDescriptors: () => xt,
+  NetInput: () => bt,
+  NeuralNetwork: () => S,
+  ObjectDetection: () => Dt,
+  Point: () => x,
+  PredictedBox: () => yo,
+  Rect: () => re,
+  SsdMobilenetv1: () => Ut,
+  SsdMobilenetv1Options: () => Z,
+  TinyFaceDetector: () => Fe,
+  TinyFaceDetectorOptions: () => gr,
+  TinyYolov2: () => ve,
+  TinyYolov2Options: () => lt,
+  allFaces: () => Da,
+  allFacesSsdMobilenetv1: () => dn,
+  allFacesTinyYolov2: () => wa,
+  awaitMediaLoaded: () => Yr,
+  bufferToImage: () => Gr,
+  computeFaceDescriptor: () => da,
+  createCanvas: () => ne,
+  createCanvasFromMedia: () => Ie,
+  createFaceDetectionNet: () => na,
+  createFaceRecognitionNet: () => Un,
+  createSsdMobilenetv1: () => Xo,
+  createTinyFaceDetector: () => Ea,
+  createTinyYolov2: () => ia,
+  detectAllFaces: () => wr,
+  detectFaceLandmarks: () => mn,
+  detectFaceLandmarksTiny: () => pa,
+  detectLandmarks: () => Pa,
+  detectSingleFace: () => _a,
+  draw: () => Qr,
+  env: () => w,
+  euclideanDistance: () => uo,
+  extendWithAge: () => hr,
+  extendWithFaceDescriptor: () => fr,
+  extendWithFaceDetection: () => $t,
+  extendWithFaceExpressions: () => mr,
+  extendWithFaceLandmarks: () => le,
+  extendWithGender: () => xr,
+  extractFaceTensors: () => se,
+  extractFaces: () => ae,
+  fetchImage: () => Bn,
+  fetchJson: () => Ur,
+  fetchNetWeights: () => Rn,
+  fetchOrThrow: () => Yt,
+  getContext2dOrThrow: () => O,
+  getMediaDimensions: () => Ht,
+  imageTensorToCanvas: () => zr,
+  imageToSquare: () => Vr,
+  inverseSigmoid: () => Mn,
+  iou: () => Lr,
+  isMediaElement: () => qe,
+  isMediaLoaded: () => Ne,
+  isWithAge: () => Xn,
+  isWithFaceDetection: () => pt,
+  isWithFaceExpressions: () => qr,
+  isWithFaceLandmarks: () => zt,
+  isWithGender: () => Jn,
+  loadAgeGenderModel: () => ya,
+  loadFaceDetectionModel: () => Fa,
+  loadFaceExpressionModel: () => va,
+  loadFaceLandmarkModel: () => xa,
+  loadFaceLandmarkTinyModel: () => ba,
+  loadFaceRecognitionModel: () => ga,
+  loadSsdMobilenetv1Model: () => pn,
+  loadTinyFaceDetectorModel: () => fa,
+  loadTinyYolov2Model: () => ha,
+  loadWeightMap: () => Xr,
+  locateFaces: () => Ta,
+  matchDimensions: () => On,
+  minBbox: () => kr,
+  nets: () => P,
+  nonMaxSuppression: () => Sr,
+  normalize: () => ot,
+  padToSquare: () => Ar,
+  predictAgeAndGender: () => la,
+  recognizeFaceExpressions: () => ua,
+  resizeResults: () => un,
+  resolveInput: () => jt,
+  shuffleArray: () => En,
+  sigmoid: () => De,
+  ssdMobilenetv1: () => cn,
+  tf: () => Ma,
+  tinyFaceDetector: () => ca,
+  tinyYolov2: () => ma,
+  toNetInput: () => E,
+  utils: () => Mr,
+  validateConfig: () => ao,
+  version: () => Ia,
+})
+var Ma = b(g())
+var Qr = {}
+Ge(Qr, {
+  AnchorPosition: () => dt,
+  DrawBox: () => Xe,
+  DrawBoxOptions: () => Hr,
+  DrawFaceLandmarks: () => Kr,
+  DrawFaceLandmarksOptions: () => Zr,
+  DrawTextField: () => Mt,
+  DrawTextFieldOptions: () => Ce,
+  drawContour: () => ft,
+  drawDetections: () => Wn,
+  drawFaceExpressions: () => $n,
+  drawFaceLandmarks: () => jn,
+})
+function ft(o, t, e = !1) {
+  if (
+    (o.beginPath(),
+    t.slice(1).forEach(({x: r, y: n}, a) => {
+      let s = t[a]
+      o.moveTo(s.x, s.y), o.lineTo(r, n)
+    }),
+    e)
+  ) {
+    let r = t[t.length - 1],
+      n = t[0]
+    if (!r || !n) return
+    o.moveTo(r.x, r.y), o.lineTo(n.x, n.y)
+  }
+  o.stroke()
+}
+var Mr = {}
+Ge(Mr, {
+  computeReshapedDimensions: () => Ir,
+  getCenterPoint: () => Ot,
+  isDimensions: () => Ve,
+  isEven: () => ze,
+  isFloat: () => Nr,
+  isTensor: () => Bt,
+  isTensor1D: () => Dn,
+  isTensor2D: () => Cr,
+  isTensor3D: () => ht,
+  isTensor4D: () => z,
+  isValidNumber: () => rt,
+  isValidProbablitiy: () => te,
+  range: () => ct,
+  round: () => Rt,
+})
+var go = b(g())
+var A = class {
+  constructor(t, e) {
+    if (!rt(t) || !rt(e))
+      throw new Error(
+        `Dimensions.constructor - expected width and height to be valid numbers, instead have ${JSON.stringify(
+          {width: t, height: e},
+        )}`,
+      )
+    ;(this._width = t), (this._height = e)
+  }
+  get width() {
+    return this._width
+  }
+  get height() {
+    return this._height
+  }
+  reverse() {
+    return new A(1 / this.width, 1 / this.height)
+  }
+}
+function Bt(o, t) {
+  return o instanceof go.Tensor && o.shape.length === t
+}
+function Dn(o) {
+  return Bt(o, 1)
+}
+function Cr(o) {
+  return Bt(o, 2)
+}
+function ht(o) {
+  return Bt(o, 3)
+}
+function z(o) {
+  return Bt(o, 4)
+}
+function Nr(o) {
+  return o % 1 != 0
+}
+function ze(o) {
+  return o % 2 == 0
+}
+function Rt(o, t = 2) {
+  let e = 10 ** t
+  return Math.floor(o * e) / e
+}
+function Ve(o) {
+  return o && o.width && o.height
+}
+function Ir({width: o, height: t}, e) {
+  let r = e / Math.max(t, o)
+  return new A(Math.round(o * r), Math.round(t * r))
+}
+function Ot(o) {
+  return o.reduce((t, e) => t.add(e), new x(0, 0)).div(new x(o.length, o.length))
+}
+function ct(o, t, e) {
+  return Array(o)
+    .fill(0)
+    .map((r, n) => t + n * e)
+}
+function rt(o) {
+  return (!!o && o !== Infinity && o !== -Infinity && !Number.isNaN(o)) || o === 0
+}
+function te(o) {
+  return rt(o) && o >= 0 && o <= 1
+}
+var x = class {
+  constructor(t, e) {
+    ;(this._x = t), (this._y = e)
+  }
+  get x() {
+    return this._x
+  }
+  get y() {
+    return this._y
+  }
+  add(t) {
+    return new x(this.x + t.x, this.y + t.y)
+  }
+  sub(t) {
+    return new x(this.x - t.x, this.y - t.y)
+  }
+  mul(t) {
+    return new x(this.x * t.x, this.y * t.y)
+  }
+  div(t) {
+    return new x(this.x / t.x, this.y / t.y)
+  }
+  abs() {
+    return new x(Math.abs(this.x), Math.abs(this.y))
+  }
+  magnitude() {
+    return Math.sqrt(this.x ** 2 + this.y ** 2)
+  }
+  floor() {
+    return new x(Math.floor(this.x), Math.floor(this.y))
+  }
+}
+var D = class {
+  static isRect(t) {
+    return !!t && [t.x, t.y, t.width, t.height].every(rt)
+  }
+  static assertIsValidBox(t, e, r = !1) {
+    if (!D.isRect(t))
+      throw new Error(
+        `${e} - invalid box: ${JSON.stringify(
+          t,
+        )}, expected object with properties x, y, width, height`,
+      )
+    if (!r && (t.width < 0 || t.height < 0))
+      throw new Error(`${e} - width (${t.width}) and height (${t.height}) must be positive numbers`)
+  }
+  constructor(t, e = !0) {
+    let r = t || {},
+      n = [r.left, r.top, r.right, r.bottom].every(rt),
+      a = [r.x, r.y, r.width, r.height].every(rt)
+    if (!a && !n)
+      throw new Error(
+        `Box.constructor - expected box to be IBoundingBox | IRect, instead have ${JSON.stringify(
+          r,
+        )}`,
+      )
+    let [s, i, c, m] = a
+      ? [r.x, r.y, r.width, r.height]
+      : [r.left, r.top, r.right - r.left, r.bottom - r.top]
+    D.assertIsValidBox({x: s, y: i, width: c, height: m}, 'Box.constructor', e),
+      (this._x = s),
+      (this._y = i),
+      (this._width = c),
+      (this._height = m)
+  }
+  get x() {
+    return this._x
+  }
+  get y() {
+    return this._y
+  }
+  get width() {
+    return this._width
+  }
+  get height() {
+    return this._height
+  }
+  get left() {
+    return this.x
+  }
+  get top() {
+    return this.y
+  }
+  get right() {
+    return this.x + this.width
+  }
+  get bottom() {
+    return this.y + this.height
+  }
+  get area() {
+    return this.width * this.height
+  }
+  get topLeft() {
+    return new x(this.left, this.top)
+  }
+  get topRight() {
+    return new x(this.right, this.top)
+  }
+  get bottomLeft() {
+    return new x(this.left, this.bottom)
+  }
+  get bottomRight() {
+    return new x(this.right, this.bottom)
+  }
+  round() {
+    let [t, e, r, n] = [this.x, this.y, this.width, this.height].map(a => Math.round(a))
+    return new D({x: t, y: e, width: r, height: n})
+  }
+  floor() {
+    let [t, e, r, n] = [this.x, this.y, this.width, this.height].map(a => Math.floor(a))
+    return new D({x: t, y: e, width: r, height: n})
+  }
+  toSquare() {
+    let {x: t, y: e, width: r, height: n} = this,
+      a = Math.abs(r - n)
+    return (
+      r < n && ((t -= a / 2), (r += a)),
+      n < r && ((e -= a / 2), (n += a)),
+      new D({x: t, y: e, width: r, height: n})
+    )
+  }
+  rescale(t) {
+    let e = Ve(t) ? t.width : t,
+      r = Ve(t) ? t.height : t
+    return new D({x: this.x * e, y: this.y * r, width: this.width * e, height: this.height * r})
+  }
+  pad(t, e) {
+    let [r, n, a, s] = [this.x - t / 2, this.y - e / 2, this.width + t, this.height + e]
+    return new D({x: r, y: n, width: a, height: s})
+  }
+  clipAtImageBorders(t, e) {
+    let {x: r, y: n, right: a, bottom: s} = this,
+      i = Math.max(r, 0),
+      c = Math.max(n, 0),
+      m = a - i,
+      p = s - c,
+      d = Math.min(m, t - i),
+      u = Math.min(p, e - c)
+    return new D({x: i, y: c, width: d, height: u}).floor()
+  }
+  shift(t, e) {
+    let {width: r, height: n} = this,
+      a = this.x + t,
+      s = this.y + e
+    return new D({x: a, y: s, width: r, height: n})
+  }
+  padAtBorders(t, e) {
+    let r = this.width + 1,
+      n = this.height + 1,
+      a = 1,
+      s = 1,
+      i = r,
+      c = n,
+      m = this.left,
+      p = this.top,
+      d = this.right,
+      u = this.bottom
+    return (
+      d > e && ((i = -d + e + r), (d = e)),
+      u > t && ((c = -u + t + n), (u = t)),
+      m < 1 && ((c = 2 - m), (m = 1)),
+      p < 1 && ((c = 2 - p), (p = 1)),
+      {dy: s, edy: c, dx: a, edx: i, y: p, ey: u, x: m, ex: d, w: r, h: n}
+    )
+  }
+  calibrate(t) {
+    return new D({
+      left: this.left + t.left * this.width,
+      top: this.top + t.top * this.height,
+      right: this.right + t.right * this.width,
+      bottom: this.bottom + t.bottom * this.height,
+    })
+      .toSquare()
+      .round()
+  }
+}
+var ee = class extends D {
+  constructor(t, e, r, n, a = !1) {
+    super({left: t, top: e, right: r, bottom: n}, a)
+  }
+}
+var Dt = class {
+  constructor(t, e, r, n, a) {
+    ;(this._imageDims = new A(a.width, a.height)),
+      (this._score = t),
+      (this._classScore = e),
+      (this._className = r),
+      (this._box = new D(n).rescale(this._imageDims))
+  }
+  get score() {
+    return this._score
+  }
+  get classScore() {
+    return this._classScore
+  }
+  get className() {
+    return this._className
+  }
+  get box() {
+    return this._box
+  }
+  get imageDims() {
+    return this._imageDims
+  }
+  get imageWidth() {
+    return this.imageDims.width
+  }
+  get imageHeight() {
+    return this.imageDims.height
+  }
+  get relativeBox() {
+    return new D(this._box).rescale(this.imageDims.reverse())
+  }
+  forSize(t, e) {
+    return new Dt(this.score, this.classScore, this.className, this.relativeBox, {
+      width: t,
+      height: e,
+    })
+  }
+}
+var M = class extends Dt {
+  constructor(t, e, r) {
+    super(t, t, '', e, r)
+  }
+  forSize(t, e) {
+    let {score: r, relativeBox: n, imageDims: a} = super.forSize(t, e)
+    return new M(r, n, a)
+  }
+}
+function Lr(o, t, e = !0) {
+  let r = Math.max(0, Math.min(o.right, t.right) - Math.max(o.left, t.left)),
+    n = Math.max(0, Math.min(o.bottom, t.bottom) - Math.max(o.top, t.top)),
+    a = r * n
+  return e ? a / (o.area + t.area - a) : a / Math.min(o.area, t.area)
+}
+function kr(o) {
+  let t = o.map(i => i.x),
+    e = o.map(i => i.y),
+    r = t.reduce((i, c) => (c < i ? c : i), Infinity),
+    n = e.reduce((i, c) => (c < i ? c : i), Infinity),
+    a = t.reduce((i, c) => (i < c ? c : i), 0),
+    s = e.reduce((i, c) => (i < c ? c : i), 0)
+  return new ee(r, n, a, s)
+}
+function Sr(o, t, e, r = !0) {
+  let n = t
+      .map((s, i) => ({score: s, boxIndex: i}))
+      .sort((s, i) => s.score - i.score)
+      .map(s => s.boxIndex),
+    a = []
+  for (; n.length > 0; ) {
+    let s = n.pop()
+    a.push(s)
+    let i = n,
+      c = []
+    for (let m = 0; m < i.length; m++) {
+      let p = i[m],
+        d = o[s],
+        u = o[p]
+      c.push(Lr(d, u, r))
+    }
+    n = n.filter((m, p) => c[p] <= e)
+  }
+  return a
+}
+var mt = b(g())
+function ot(o, t) {
+  return mt.tidy(() => {
+    let [e, r, n] = t,
+      a = mt.fill([...o.shape.slice(0, 3), 1], e, 'float32'),
+      s = mt.fill([...o.shape.slice(0, 3), 1], r, 'float32'),
+      i = mt.fill([...o.shape.slice(0, 3), 1], n, 'float32'),
+      c = mt.concat([a, s, i], 3)
+    return mt.sub(o, c)
+  })
+}
+var Et = b(g())
+function Ar(o, t = !1) {
+  return Et.tidy(() => {
+    let [e, r] = o.shape.slice(1)
+    if (e === r) return o
+    let n = Math.abs(e - r),
+      a = Math.round(n * (t ? 0.5 : 1)),
+      s = e > r ? 2 : 1,
+      i = u => {
+        let l = o.shape.slice()
+        return (l[s] = u), Et.fill(l, 0, 'float32')
+      },
+      c = i(a),
+      m = n - c.shape[s],
+      d = [t && m ? i(m) : null, o, c].filter(u => !!u).map(u => Et.cast(u, 'float32'))
+    return Et.concat(d, s)
+  })
+}
+function En(o) {
+  let t = o.slice()
+  for (let e = t.length - 1; e > 0; e--) {
+    let r = Math.floor(Math.random() * (e + 1)),
+      n = t[e]
+    ;(t[e] = t[r]), (t[r] = n)
+  }
+  return t
+}
+function De(o) {
+  return 1 / (1 + Math.exp(-o))
+}
+function Mn(o) {
+  return Math.log(o / (1 - o))
+}
+var re = class extends D {
+  constructor(t, e, r, n, a = !1) {
+    super({x: t, y: e, width: r, height: n}, a)
+  }
+}
+var Cn = 0.5,
+  Nn = 0.43,
+  In = 0.45,
+  V = class {
+    constructor(t, e, r = new x(0, 0)) {
+      let {width: n, height: a} = e
+      ;(this._imgDims = new A(n, a)),
+        (this._shift = r),
+        (this._positions = t.map(s => s.mul(new x(n, a)).add(r)))
+    }
+    get shift() {
+      return new x(this._shift.x, this._shift.y)
+    }
+    get imageWidth() {
+      return this._imgDims.width
+    }
+    get imageHeight() {
+      return this._imgDims.height
+    }
+    get positions() {
+      return this._positions
+    }
+    get relativePositions() {
+      return this._positions.map(t =>
+        t.sub(this._shift).div(new x(this.imageWidth, this.imageHeight)),
+      )
+    }
+    forSize(t, e) {
+      return new this.constructor(this.relativePositions, {width: t, height: e})
+    }
+    shiftBy(t, e) {
+      return new this.constructor(this.relativePositions, this._imgDims, new x(t, e))
+    }
+    shiftByPoint(t) {
+      return this.shiftBy(t.x, t.y)
+    }
+    align(t, e = {}) {
+      if (t) {
+        let a = t instanceof M ? t.box.floor() : new D(t)
+        return this.shiftBy(a.x, a.y).align(null, e)
+      }
+      let {useDlibAlignment: r, minBoxPadding: n} = {useDlibAlignment: !1, minBoxPadding: 0.2, ...e}
+      return r ? this.alignDlib() : this.alignMinBbox(n)
+    }
+    alignDlib() {
+      let t = this.getRefPointsForAlignment(),
+        [e, r, n] = t,
+        a = d => n.sub(d).magnitude(),
+        s = (a(e) + a(r)) / 2,
+        i = Math.floor(s / In),
+        c = Ot(t),
+        m = Math.floor(Math.max(0, c.x - Cn * i)),
+        p = Math.floor(Math.max(0, c.y - Nn * i))
+      return new re(m, p, Math.min(i, this.imageWidth + m), Math.min(i, this.imageHeight + p))
+    }
+    alignMinBbox(t) {
+      let e = kr(this.positions)
+      return e.pad(e.width * t, e.height * t)
+    }
+    getRefPointsForAlignment() {
+      throw new Error('getRefPointsForAlignment not implemented by base class')
+    }
+  }
+var vo = class extends V {
+  getRefPointsForAlignment() {
+    let t = this.positions
+    return [t[0], t[1], Ot([t[3], t[4]])]
+  }
+}
+var oe = class extends V {
+  getJawOutline() {
+    return this.positions.slice(0, 17)
+  }
+  getLeftEyeBrow() {
+    return this.positions.slice(17, 22)
+  }
+  getRightEyeBrow() {
+    return this.positions.slice(22, 27)
+  }
+  getNose() {
+    return this.positions.slice(27, 36)
+  }
+  getLeftEye() {
+    return this.positions.slice(36, 42)
+  }
+  getRightEye() {
+    return this.positions.slice(42, 48)
+  }
+  getMouth() {
+    return this.positions.slice(48, 68)
+  }
+  getRefPointsForAlignment() {
+    return [this.getLeftEye(), this.getRightEye(), this.getMouth()].map(Ot)
+  }
+}
+var Ee = class {
+  constructor(t, e) {
+    ;(this._label = t), (this._distance = e)
+  }
+  get label() {
+    return this._label
+  }
+  get distance() {
+    return this._distance
+  }
+  toString(t = !0) {
+    return `${this.label}${t ? ` (${Rt(this.distance)})` : ''}`
+  }
+}
+var Me = class extends D {
+  static assertIsValidLabeledBox(t, e) {
+    if ((D.assertIsValidBox(t, e), !rt(t.label)))
+      throw new Error(`${e} - expected property label (${t.label}) to be a number`)
+  }
+  constructor(t, e) {
+    super(t)
+    this._label = e
+  }
+  get label() {
+    return this._label
+  }
+}
+var xt = class {
+  constructor(t, e) {
+    if (typeof t != 'string')
+      throw new Error('LabeledFaceDescriptors - constructor expected label to be a string')
+    if (!Array.isArray(e) || e.some(r => !(r instanceof Float32Array)))
+      throw new Error(
+        'LabeledFaceDescriptors - constructor expected descriptors to be an array of Float32Array',
+      )
+    ;(this._label = t), (this._descriptors = e)
+  }
+  get label() {
+    return this._label
+  }
+  get descriptors() {
+    return this._descriptors
+  }
+  toJSON() {
+    return {label: this.label, descriptors: this.descriptors.map(t => Array.from(t))}
+  }
+  static fromJSON(t) {
+    let e = t.descriptors.map(r => new Float32Array(r))
+    return new xt(t.label, e)
+  }
+}
+var yo = class extends Me {
+  static assertIsValidPredictedBox(t, e) {
+    if ((Me.assertIsValidLabeledBox(t, e), !te(t.score) || !te(t.classScore)))
+      throw new Error(
+        `${e} - expected properties score (${t.score}) and (${t.classScore}) to be a number between [0, 1]`,
+      )
+  }
+  constructor(t, e, r, n) {
+    super(t, e)
+    ;(this._score = r), (this._classScore = n)
+  }
+  get score() {
+    return this._score
+  }
+  get classScore() {
+    return this._classScore
+  }
+}
+function pt(o) {
+  return o.detection instanceof M
+}
+function $t(o, t) {
+  return {...o, ...{detection: t}}
+}
+function Wr() {
+  let o = window.fetch
+  if (!o) throw new Error('fetch - missing fetch implementation for browser environment')
+  let t = () => {
+    throw new Error('readFile - filesystem not available for browser environment')
+  }
+  return {
+    Canvas: HTMLCanvasElement,
+    CanvasRenderingContext2D,
+    Image: HTMLImageElement,
+    ImageData,
+    Video: HTMLVideoElement,
+    createCanvasElement: () => document.createElement('canvas'),
+    createImageElement: () => document.createElement('img'),
+    fetch: o,
+    readFile: t,
+  }
+}
+function Ue(o) {
+  let t = ''
+  if (!o)
+    try {
+      o = require('fs')
+    } catch (r) {
+      t = r.toString()
+    }
+  return {
+    readFile: o
+      ? r =>
+          new Promise((n, a) => {
+            o.readFile(r, (s, i) => (s ? a(s) : n(i)))
+          })
+      : () => {
+          throw new Error(`readFile - failed to require fs in nodejs environment with error: ${t}`)
+        },
+  }
+}
+function Br() {
+  let o = global.Canvas || global.HTMLCanvasElement,
+    t = global.Image || global.HTMLImageElement,
+    e = () => {
+      if (o) return new o()
+      throw new Error('createCanvasElement - missing Canvas implementation for nodejs environment')
+    },
+    r = () => {
+      if (t) return new t()
+      throw new Error('createImageElement - missing Image implementation for nodejs environment')
+    },
+    n = global.fetch,
+    a = Ue()
+  return {
+    Canvas: o || class {},
+    CanvasRenderingContext2D: global.CanvasRenderingContext2D || class {},
+    Image: t || class {},
+    ImageData: global.ImageData || class {},
+    Video: global.HTMLVideoElement || class {},
+    createCanvasElement: e,
+    createImageElement: r,
+    fetch: n,
+    ...a,
+  }
+}
+function Rr() {
+  return (
+    typeof window == 'object' &&
+    typeof document != 'undefined' &&
+    typeof HTMLImageElement != 'undefined' &&
+    typeof HTMLCanvasElement != 'undefined' &&
+    typeof HTMLVideoElement != 'undefined' &&
+    typeof ImageData != 'undefined' &&
+    typeof CanvasRenderingContext2D != 'undefined'
+  )
+}
+var Or = b(To()),
+  k
+function Sn() {
+  if (!k) throw new Error('getEnv - environment is not defined, check isNodejs() and isBrowser()')
+  return k
+}
+function $r(o) {
+  k = o
+}
+function jr() {
+  return Rr() ? $r(Wr()) : Or.isNodejs() ? $r(Br()) : null
+}
+function An(o) {
+  if ((k || jr(), !k))
+    throw new Error('monkeyPatch - environment is not defined, check isNodejs() and isBrowser()')
+  let {Canvas: t = k.Canvas, Image: e = k.Image} = o
+  ;(k.Canvas = t),
+    (k.Image = e),
+    (k.createCanvasElement = o.createCanvasElement || (() => new t())),
+    (k.createImageElement = o.createImageElement || (() => new e())),
+    (k.ImageData = o.ImageData || k.ImageData),
+    (k.Video = o.Video || k.Video),
+    (k.fetch = o.fetch || k.fetch),
+    (k.readFile = o.readFile || k.readFile)
+}
+var w = {
+  getEnv: Sn,
+  setEnv: $r,
+  initialize: jr,
+  createBrowserEnv: Wr,
+  createFileSystem: Ue,
+  createNodejsEnv: Br,
+  monkeyPatch: An,
+  isBrowser: Rr,
+  isNodejs: Or.isNodejs,
+}
+jr()
+function jt(o) {
+  return !w.isNodejs() && typeof o == 'string' ? document.getElementById(o) : o
+}
+function O(o) {
+  let {Canvas: t, CanvasRenderingContext2D: e} = w.getEnv()
+  if (o instanceof e) return o
+  let r = jt(o)
+  if (!(r instanceof t))
+    throw new Error('resolveContext2d - expected canvas to be of instance of Canvas')
+  let n = r.getContext('2d')
+  if (!n) throw new Error('resolveContext2d - canvas 2d context is null')
+  return n
+}
+var dt
+;(function(o) {
+  ;(o.TOP_LEFT = 'TOP_LEFT'),
+    (o.TOP_RIGHT = 'TOP_RIGHT'),
+    (o.BOTTOM_LEFT = 'BOTTOM_LEFT'),
+    (o.BOTTOM_RIGHT = 'BOTTOM_RIGHT')
+})(dt || (dt = {}))
+var Ce = class {
+    constructor(t = {}) {
+      let {
+        anchorPosition: e,
+        backgroundColor: r,
+        fontColor: n,
+        fontSize: a,
+        fontStyle: s,
+        padding: i,
+      } = t
+      ;(this.anchorPosition = e || dt.TOP_LEFT),
+        (this.backgroundColor = r || 'rgba(0, 0, 0, 0.5)'),
+        (this.fontColor = n || 'rgba(255, 255, 255, 1)'),
+        (this.fontSize = a || 14),
+        (this.fontStyle = s || 'Georgia'),
+        (this.padding = i || 4)
+    }
+  },
+  Mt = class {
+    constructor(t, e, r = {}) {
+      ;(this.text = typeof t == 'string' ? [t] : t instanceof Mt ? t.text : t),
+        (this.anchor = e),
+        (this.options = new Ce(r))
+    }
+    measureWidth(t) {
+      let {padding: e} = this.options
+      return this.text.map(r => t.measureText(r).width).reduce((r, n) => (r < n ? n : r), 0) + 2 * e
+    }
+    measureHeight() {
+      let {fontSize: t, padding: e} = this.options
+      return this.text.length * t + 2 * e
+    }
+    getUpperLeft(t, e) {
+      let {anchorPosition: r} = this.options,
+        n = r === dt.BOTTOM_RIGHT || r === dt.TOP_RIGHT,
+        a = r === dt.BOTTOM_LEFT || r === dt.BOTTOM_RIGHT,
+        s = this.measureWidth(t),
+        i = this.measureHeight(),
+        c = n ? this.anchor.x - s : this.anchor.x,
+        m = a ? this.anchor.y - i : this.anchor.y
+      if (e) {
+        let {width: p, height: d} = e,
+          u = Math.max(Math.min(c, p - s), 0),
+          l = Math.max(Math.min(m, d - i), 0)
+        return {x: u, y: l}
+      }
+      return {x: c, y: m}
+    }
+    draw(t) {
+      let e = jt(t),
+        r = O(e),
+        {backgroundColor: n, fontColor: a, fontSize: s, fontStyle: i, padding: c} = this.options
+      r.font = `${s}px ${i}`
+      let m = this.measureWidth(r),
+        p = this.measureHeight()
+      r.fillStyle = n
+      let d = this.getUpperLeft(r, e)
+      r.fillRect(d.x, d.y, m, p),
+        (r.fillStyle = a),
+        this.text.forEach((u, l) => {
+          let v = c + d.x,
+            _ = c + d.y + (l + 1) * s
+          r.fillText(u, v, _)
+        })
+    }
+  }
+var Hr = class {
+    constructor(t = {}) {
+      let {boxColor: e, lineWidth: r, label: n, drawLabelOptions: a} = t
+      ;(this.boxColor = e || 'rgba(0, 0, 255, 1)'), (this.lineWidth = r || 2), (this.label = n)
+      let s = {anchorPosition: dt.BOTTOM_LEFT, backgroundColor: this.boxColor}
+      this.drawLabelOptions = new Ce({...s, ...a})
+    }
+  },
+  Xe = class {
+    constructor(t, e = {}) {
+      ;(this.box = new D(t)), (this.options = new Hr(e))
+    }
+    draw(t) {
+      let e = O(t),
+        {boxColor: r, lineWidth: n} = this.options,
+        {x: a, y: s, width: i, height: c} = this.box
+      ;(e.strokeStyle = r), (e.lineWidth = n), e.strokeRect(a, s, i, c)
+      let {label: m} = this.options
+      m && new Mt([m], {x: a - n / 2, y: s}, this.options.drawLabelOptions).draw(t)
+    }
+  }
+function Wn(o, t) {
+  ;(Array.isArray(t) ? t : [t]).forEach(r => {
+    let n = r instanceof M ? r.score : pt(r) ? r.detection.score : void 0,
+      a = r instanceof M ? r.box : pt(r) ? r.detection.box : new D(r),
+      s = n ? `${Rt(n)}` : void 0
+    new Xe(a, {label: s}).draw(o)
+  })
+}
+var ue = b(g())
+function Ne(o) {
+  let {Image: t, Video: e} = w.getEnv()
+  return (o instanceof t && o.complete) || (o instanceof e && o.readyState >= 3)
+}
+function Yr(o) {
+  return new Promise((t, e) => {
+    if (o instanceof w.getEnv().Canvas || Ne(o)) return t(null)
+    function r(a) {
+      !a.currentTarget ||
+        (a.currentTarget.removeEventListener('load', n),
+        a.currentTarget.removeEventListener('error', r),
+        e(a))
+    }
+    function n(a) {
+      !a.currentTarget ||
+        (a.currentTarget.removeEventListener('load', n),
+        a.currentTarget.removeEventListener('error', r),
+        t(a))
+    }
+    o.addEventListener('load', n), o.addEventListener('error', r)
+  })
+}
+function Gr(o) {
+  return new Promise((t, e) => {
+    o instanceof Blob || e(new Error('bufferToImage - expected buf to be of type: Blob'))
+    let r = new FileReader()
+    ;(r.onload = () => {
+      typeof r.result != 'string' &&
+        e(new Error('bufferToImage - expected reader.result to be a string, in onload'))
+      let n = w.getEnv().createImageElement()
+      ;(n.onload = () => t(n)), (n.onerror = e), (n.src = r.result)
+    }),
+      (r.onerror = e),
+      r.readAsDataURL(o)
+  })
+}
+function Ht(o) {
+  let {Image: t, Video: e} = w.getEnv()
+  return o instanceof t
+    ? new A(o.naturalWidth, o.naturalHeight)
+    : o instanceof e
+    ? new A(o.videoWidth, o.videoHeight)
+    : new A(o.width, o.height)
+}
+function ne({width: o, height: t}) {
+  let {createCanvasElement: e} = w.getEnv(),
+    r = e()
+  return (r.width = o), (r.height = t), r
+}
+function Ie(o, t) {
+  let {ImageData: e} = w.getEnv()
+  if (!(o instanceof e) && !Ne(o))
+    throw new Error('createCanvasFromMedia - media has not finished loading yet')
+  let {width: r, height: n} = t || Ht(o),
+    a = ne({width: r, height: n})
+  return o instanceof e ? O(a).putImageData(o, 0, 0) : O(a).drawImage(o, 0, 0, r, n), a
+}
+var Je = b(g())
+async function zr(o, t) {
+  let e = t || w.getEnv().createCanvasElement(),
+    [r, n, a] = o.shape.slice(z(o) ? 1 : 0),
+    s = Je.tidy(() => o.as3D(r, n, a).toInt())
+  return await Je.browser.toPixels(s, e), s.dispose(), e
+}
+function qe(o) {
+  let {Image: t, Canvas: e, Video: r} = w.getEnv()
+  return o instanceof t || o instanceof e || o instanceof r
+}
+var J = b(g())
+function Vr(o, t, e = !1) {
+  let {Image: r, Canvas: n} = w.getEnv()
+  if (!(o instanceof r || o instanceof n))
+    throw new Error('imageToSquare - expected arg0 to be HTMLImageElement | HTMLCanvasElement')
+  let a = Ht(o),
+    s = t / Math.max(a.height, a.width),
+    i = s * a.width,
+    c = s * a.height,
+    m = ne({width: t, height: t}),
+    p = o instanceof n ? o : Ie(o),
+    d = Math.abs(i - c) / 2,
+    u = e && i < c ? d : 0,
+    l = e && c < i ? d : 0
+  return O(m).drawImage(p, u, l, i, c), m
+}
+var bt = class {
+  constructor(t, e = !1) {
+    this._imageTensors = []
+    this._canvases = []
+    this._treatAsBatchInput = !1
+    this._inputDimensions = []
+    if (!Array.isArray(t))
+      throw new Error(
+        `NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have ${t}`,
+      )
+    ;(this._treatAsBatchInput = e),
+      (this._batchSize = t.length),
+      t.forEach((r, n) => {
+        if (ht(r)) {
+          ;(this._imageTensors[n] = r), (this._inputDimensions[n] = r.shape)
+          return
+        }
+        if (z(r)) {
+          let s = r.shape[0]
+          if (s !== 1)
+            throw new Error(
+              `NetInput - tf.Tensor4D with batchSize ${s} passed, but not supported in input array`,
+            )
+          ;(this._imageTensors[n] = r), (this._inputDimensions[n] = r.shape.slice(1))
+          return
+        }
+        let a = r instanceof w.getEnv().Canvas ? r : Ie(r)
+        ;(this._canvases[n] = a), (this._inputDimensions[n] = [a.height, a.width, 3])
+      })
+  }
+  get imageTensors() {
+    return this._imageTensors
+  }
+  get canvases() {
+    return this._canvases
+  }
+  get isBatchInput() {
+    return this.batchSize > 1 || this._treatAsBatchInput
+  }
+  get batchSize() {
+    return this._batchSize
+  }
+  get inputDimensions() {
+    return this._inputDimensions
+  }
+  get inputSize() {
+    return this._inputSize
+  }
+  get reshapedInputDimensions() {
+    return ct(this.batchSize, 0, 1).map((t, e) => this.getReshapedInputDimensions(e))
+  }
+  getInput(t) {
+    return this.canvases[t] || this.imageTensors[t]
+  }
+  getInputDimensions(t) {
+    return this._inputDimensions[t]
+  }
+  getInputHeight(t) {
+    return this._inputDimensions[t][0]
+  }
+  getInputWidth(t) {
+    return this._inputDimensions[t][1]
+  }
+  getReshapedInputDimensions(t) {
+    if (typeof this.inputSize != 'number')
+      throw new Error(
+        'getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet',
+      )
+    let e = this.getInputWidth(t),
+      r = this.getInputHeight(t)
+    return Ir({width: e, height: r}, this.inputSize)
+  }
+  toBatchTensor(t, e = !0) {
+    return (
+      (this._inputSize = t),
+      J.tidy(() => {
+        let r = ct(this.batchSize, 0, 1).map(a => {
+          let s = this.getInput(a)
+          if (s instanceof J.Tensor) {
+            let i = z(s) ? s : s.expandDims()
+            return (
+              (i = Ar(i, e)),
+              (i.shape[1] !== t || i.shape[2] !== t) && (i = J.image.resizeBilinear(i, [t, t])),
+              i.as3D(t, t, 3)
+            )
+          }
+          if (s instanceof w.getEnv().Canvas) return J.browser.fromPixels(Vr(s, t, e))
+          throw new Error(
+            `toBatchTensor - at batchIdx ${a}, expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have ${s}`,
+          )
+        })
+        return J.stack(r.map(a => J.cast(a, 'float32'))).as4D(this.batchSize, t, t, 3)
+      })
+    )
+  }
+}
+async function E(o) {
+  if (o instanceof bt) return o
+  let t = Array.isArray(o) ? o : [o]
+  if (!t.length) throw new Error('toNetInput - empty array passed as input')
+  let e = n => (Array.isArray(o) ? ` at input index ${n}:` : ''),
+    r = t.map(jt)
+  return (
+    r.forEach((n, a) => {
+      if (!qe(n) && !ht(n) && !z(n))
+        throw typeof t[a] == 'string'
+          ? new Error(
+              `toNetInput -${e(
+                a,
+              )} string passed, but could not resolve HTMLElement for element id ${t[a]}`,
+            )
+          : new Error(
+              `toNetInput -${e(
+                a,
+              )} expected media to be of type HTMLImageElement | HTMLVideoElement | HTMLCanvasElement | tf.Tensor3D, or to be an element id`,
+            )
+      if (z(n)) {
+        let s = n.shape[0]
+        if (s !== 1)
+          throw new Error(
+            `toNetInput -${e(
+              a,
+            )} tf.Tensor4D with batchSize ${s} passed, but not supported in input array`,
+          )
+      }
+    }),
+    await Promise.all(r.map(n => qe(n) && Yr(n))),
+    new bt(r, Array.isArray(o))
+  )
+}
+async function ae(o, t) {
+  let {Canvas: e} = w.getEnv(),
+    r = o
+  if (!(o instanceof e)) {
+    let s = await E(o)
+    if (s.batchSize > 1) throw new Error('extractFaces - batchSize > 1 not supported')
+    let i = s.getInput(0)
+    r = i instanceof e ? i : await zr(i)
+  }
+  let n = O(r)
+  return t
+    .map(s => (s instanceof M ? s.forSize(r.width, r.height).box.floor() : s))
+    .map(s => s.clipAtImageBorders(r.width, r.height))
+    .map(({x: s, y: i, width: c, height: m}) => {
+      let p = ne({width: c, height: m})
+      return O(p).putImageData(n.getImageData(s, i, c, m), 0, 0), p
+    })
+}
+var Ze = b(g())
+async function se(o, t) {
+  if (!ht(o) && !z(o)) throw new Error('extractFaceTensors - expected image tensor to be 3D or 4D')
+  if (z(o) && o.shape[0] > 1) throw new Error('extractFaceTensors - batchSize > 1 not supported')
+  return Ze.tidy(() => {
+    let [e, r, n] = o.shape.slice(z(o) ? 1 : 0)
+    return t
+      .map(i => (i instanceof M ? i.forSize(r, e).box : i))
+      .map(i => i.clipAtImageBorders(r, e))
+      .map(({x: i, y: c, width: m, height: p}) => Ze.slice3d(o.as3D(e, r, n), [c, i, 0], [p, m, n]))
+  })
+}
+async function Yt(o, t) {
+  let {fetch: e} = w.getEnv(),
+    r = await e(o, t)
+  if (!(r.status < 400))
+    throw new Error(`failed to fetch: (${r.status}) ${r.statusText}, from url: ${r.url}`)
+  return r
+}
+async function Bn(o) {
+  let t = await Yt(o),
+    e = await t.blob()
+  if (!e.type.startsWith('image/'))
+    throw new Error(
+      `fetchImage - expected blob type to be of type image/*, instead have: ${e.type}, for url: ${t.url}`,
+    )
+  return Gr(e)
+}
+async function Ur(o) {
+  return (await Yt(o)).json()
+}
+async function Rn(o) {
+  return new Float32Array(await (await Yt(o)).arrayBuffer())
+}
+var Po = b(g())
+function Ke(o, t) {
+  let e = `${t}-weights_manifest.json`
+  if (!o) return {modelBaseUri: '', manifestUri: e}
+  if (o === '/') return {modelBaseUri: '/', manifestUri: `/${e}`}
+  let r = o.startsWith('http://') ? 'http://' : o.startsWith('https://') ? 'https://' : ''
+  o = o.replace(r, '')
+  let n = o.split('/').filter(i => i),
+    a = o.endsWith('.json') ? n[n.length - 1] : e,
+    s = r + (o.endsWith('.json') ? n.slice(0, n.length - 1) : n).join('/')
+  return (
+    (s = o.startsWith('/') ? `/${s}` : s),
+    {modelBaseUri: s, manifestUri: s === '/' ? `/${a}` : `${s}/${a}`}
+  )
+}
+async function Xr(o, t) {
+  let {manifestUri: e, modelBaseUri: r} = Ke(o, t),
+    n = await Ur(e)
+  return Po.io.loadWeights(n, r)
+}
+function On(o, t, e = !1) {
+  let {width: r, height: n} = e ? Ht(t) : t
+  return (o.width = r), (o.height = n), {width: r, height: n}
+}
+var Nt = b(g())
+var gt = b(g())
+var S = class {
+  constructor() {
+    this._params = void 0
+    this._paramMappings = []
+  }
+  get params() {
+    return this._params
+  }
+  get paramMappings() {
+    return this._paramMappings
+  }
+  get isLoaded() {
+    return !!this.params
+  }
+  getParamFromPath(t) {
+    let {obj: e, objProp: r} = this.traversePropertyPath(t)
+    return e[r]
+  }
+  reassignParamFromPath(t, e) {
+    let {obj: r, objProp: n} = this.traversePropertyPath(t)
+    r[n].dispose(), (r[n] = e)
+  }
+  getParamList() {
+    return this._paramMappings.map(({paramPath: t}) => ({
+      path: t,
+      tensor: this.getParamFromPath(t),
+    }))
+  }
+  getTrainableParams() {
+    return this.getParamList().filter(t => t.tensor instanceof gt.Variable)
+  }
+  getFrozenParams() {
+    return this.getParamList().filter(t => !(t.tensor instanceof gt.Variable))
+  }
+  variable() {
+    this.getFrozenParams().forEach(({path: t, tensor: e}) => {
+      this.reassignParamFromPath(t, e.variable())
+    })
+  }
+  freeze() {
+    this.getTrainableParams().forEach(({path: t, tensor: e}) => {
+      let r = gt.tensor(e.dataSync())
+      e.dispose(), this.reassignParamFromPath(t, r)
+    })
+  }
+  dispose(t = !0) {
+    this.getParamList().forEach(e => {
+      if (t && e.tensor.isDisposed)
+        throw new Error(`param tensor has already been disposed for path ${e.path}`)
+      e.tensor.dispose()
+    }),
+      (this._params = void 0)
+  }
+  serializeParams() {
+    return new Float32Array(
+      this.getParamList()
+        .map(({tensor: t}) => Array.from(t.dataSync()))
+        .reduce((t, e) => t.concat(e)),
+    )
+  }
+  async load(t) {
+    if (t instanceof Float32Array) {
+      this.extractWeights(t)
+      return
+    }
+    await this.loadFromUri(t)
+  }
+  async loadFromUri(t) {
+    if (t && typeof t != 'string') throw new Error(`${this._name}.loadFromUri - expected model uri`)
+    let e = await Xr(t, this.getDefaultModelName())
+    this.loadFromWeightMap(e)
+  }
+  async loadFromDisk(t) {
+    if (t && typeof t != 'string')
+      throw new Error(`${this._name}.loadFromDisk - expected model file path`)
+    let {readFile: e} = w.getEnv(),
+      {manifestUri: r, modelBaseUri: n} = Ke(t, this.getDefaultModelName()),
+      a = m => Promise.all(m.map(p => e(p).then(d => d.buffer))),
+      s = gt.io.weightsLoaderFactory(a),
+      i = JSON.parse((await e(r)).toString()),
+      c = await s(i, n)
+    this.loadFromWeightMap(c)
+  }
+  loadFromWeightMap(t) {
+    let {paramMappings: e, params: r} = this.extractParamsFromWeightMap(t)
+    ;(this._paramMappings = e), (this._params = r)
+  }
+  extractWeights(t) {
+    let {paramMappings: e, params: r} = this.extractParams(t)
+    ;(this._paramMappings = e), (this._params = r)
+  }
+  traversePropertyPath(t) {
+    if (!this.params) throw new Error('traversePropertyPath - model has no loaded params')
+    let e = t.split('/').reduce(
+        (a, s) => {
+          if (!a.nextObj.hasOwnProperty(s))
+            throw new Error(
+              `traversePropertyPath - object does not have property ${s}, for path ${t}`,
+            )
+          return {obj: a.nextObj, objProp: s, nextObj: a.nextObj[s]}
+        },
+        {nextObj: this.params},
+      ),
+      {obj: r, objProp: n} = e
+    if (!r || !n || !(r[n] instanceof gt.Tensor))
+      throw new Error(`traversePropertyPath - parameter is not a tensor, for path ${t}`)
+    return {obj: r, objProp: n}
+  }
+}
+var C = b(g())
+var ie = b(g())
+function $(o, t, e) {
+  return ie.tidy(() => {
+    let r = ie.separableConv2d(o, t.depthwise_filter, t.pointwise_filter, e, 'same')
+    return (r = ie.add(r, t.bias)), r
+  })
+}
+function Qe(o, t, e = !1) {
+  return C.tidy(() => {
+    let r = C.relu(
+        e
+          ? C.add(C.conv2d(o, t.conv0.filters, [2, 2], 'same'), t.conv0.bias)
+          : $(o, t.conv0, [2, 2]),
+      ),
+      n = $(r, t.conv1, [1, 1]),
+      a = C.relu(C.add(r, n)),
+      s = $(a, t.conv2, [1, 1])
+    return C.relu(C.add(r, C.add(n, s)))
+  })
+}
+function Le(o, t, e = !1, r = !0) {
+  return C.tidy(() => {
+    let n = C.relu(
+        e
+          ? C.add(C.conv2d(o, t.conv0.filters, r ? [2, 2] : [1, 1], 'same'), t.conv0.bias)
+          : $(o, t.conv0, r ? [2, 2] : [1, 1]),
+      ),
+      a = $(n, t.conv1, [1, 1]),
+      s = C.relu(C.add(n, a)),
+      i = $(s, t.conv2, [1, 1]),
+      c = C.relu(C.add(n, C.add(a, i))),
+      m = $(c, t.conv3, [1, 1])
+    return C.relu(C.add(n, C.add(a, C.add(i, m))))
+  })
+}
+var Ct = b(g())
+function Gt(o, t, e = 'same', r = !1) {
+  return Ct.tidy(() => {
+    let n = Ct.add(Ct.conv2d(o, t.filters, [1, 1], e), t.bias)
+    return r ? Ct.relu(n) : n
+  })
+}
+function W(o, t) {
+  Object.keys(o).forEach(e => {
+    t.some(r => r.originalPath === e) || o[e].dispose()
+  })
+}
+var tr = b(g())
+function ce(o, t) {
+  return (e, r, n, a) => {
+    let s = tr.tensor4d(o(e * r * n * n), [n, n, e, r]),
+      i = tr.tensor1d(o(r))
+    return t.push({paramPath: `${a}/filters`}, {paramPath: `${a}/bias`}), {filters: s, bias: i}
+  }
+}
+var er = b(g())
+function rr(o, t) {
+  return (e, r, n) => {
+    let a = er.tensor2d(o(e * r), [e, r]),
+      s = er.tensor1d(o(r))
+    return t.push({paramPath: `${n}/weights`}, {paramPath: `${n}/bias`}), {weights: a, bias: s}
+  }
+}
+var ke = b(g())
+var or = class {
+  constructor(t, e, r) {
+    this.depthwise_filter = t
+    this.pointwise_filter = e
+    this.bias = r
+  }
+}
+function me(o, t) {
+  return (e, r, n) => {
+    let a = ke.tensor4d(o(3 * 3 * e), [3, 3, e, 1]),
+      s = ke.tensor4d(o(e * r), [1, 1, e, r]),
+      i = ke.tensor1d(o(r))
+    return (
+      t.push(
+        {paramPath: `${n}/depthwise_filter`},
+        {paramPath: `${n}/pointwise_filter`},
+        {paramPath: `${n}/bias`},
+      ),
+      new or(a, s, i)
+    )
+  }
+}
+function pe(o) {
+  return t => {
+    let e = o(`${t}/depthwise_filter`, 4),
+      r = o(`${t}/pointwise_filter`, 4),
+      n = o(`${t}/bias`, 1)
+    return new or(e, r, n)
+  }
+}
+function j(o, t) {
+  return (e, r, n) => {
+    let a = o[e]
+    if (!Bt(a, r))
+      throw new Error(`expected weightMap[${e}] to be a Tensor${r}D, instead have ${a}`)
+    return t.push({originalPath: e, paramPath: n || e}), a
+  }
+}
+function B(o) {
+  let t = o
+  function e(n) {
+    let a = t.slice(0, n)
+    return (t = t.slice(n)), a
+  }
+  function r() {
+    return t
+  }
+  return {extractWeights: e, getRemainingWeights: r}
+}
+function nr(o, t) {
+  let e = ce(o, t),
+    r = me(o, t)
+  function n(s, i, c, m = !1) {
+    let p = m ? e(s, i, 3, `${c}/conv0`) : r(s, i, `${c}/conv0`),
+      d = r(i, i, `${c}/conv1`),
+      u = r(i, i, `${c}/conv2`)
+    return {conv0: p, conv1: d, conv2: u}
+  }
+  function a(s, i, c, m = !1) {
+    let {conv0: p, conv1: d, conv2: u} = n(s, i, c, m),
+      l = r(i, i, `${c}/conv3`)
+    return {conv0: p, conv1: d, conv2: u, conv3: l}
+  }
+  return {extractDenseBlock3Params: n, extractDenseBlock4Params: a}
+}
+function _o(o) {
+  let t = [],
+    {extractWeights: e, getRemainingWeights: r} = B(o),
+    {extractDenseBlock4Params: n} = nr(e, t),
+    a = n(3, 32, 'dense0', !0),
+    s = n(32, 64, 'dense1'),
+    i = n(64, 128, 'dense2'),
+    c = n(128, 256, 'dense3')
+  if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`)
+  return {paramMappings: t, params: {dense0: a, dense1: s, dense2: i, dense3: c}}
+}
+function ar(o) {
+  return t => {
+    let e = o(`${t}/filters`, 4),
+      r = o(`${t}/bias`, 1)
+    return {filters: e, bias: r}
+  }
+}
+function sr(o, t) {
+  let e = j(o, t),
+    r = ar(e),
+    n = pe(e)
+  function a(i, c = !1) {
+    let m = c ? r(`${i}/conv0`) : n(`${i}/conv0`),
+      p = n(`${i}/conv1`),
+      d = n(`${i}/conv2`)
+    return {conv0: m, conv1: p, conv2: d}
+  }
+  function s(i, c = !1) {
+    let m = c ? r(`${i}/conv0`) : n(`${i}/conv0`),
+      p = n(`${i}/conv1`),
+      d = n(`${i}/conv2`),
+      u = n(`${i}/conv3`)
+    return {conv0: m, conv1: p, conv2: d, conv3: u}
+  }
+  return {extractDenseBlock3Params: a, extractDenseBlock4Params: s}
+}
+function wo(o) {
+  let t = [],
+    {extractDenseBlock4Params: e} = sr(o, t),
+    r = {dense0: e('dense0', !0), dense1: e('dense1'), dense2: e('dense2'), dense3: e('dense3')}
+  return W(o, t), {params: r, paramMappings: t}
+}
+var Se = class extends S {
+  constructor() {
+    super('FaceFeatureExtractor')
+  }
+  forwardInput(t) {
+    let {params: e} = this
+    if (!e) throw new Error('FaceFeatureExtractor - load model before inference')
+    return Nt.tidy(() => {
+      let r = Nt.cast(t.toBatchTensor(112, !0), 'float32'),
+        a = ot(r, [122.782, 117.001, 104.298]).div(Nt.scalar(255)),
+        s = Le(a, e.dense0, !0)
+      return (
+        (s = Le(s, e.dense1)),
+        (s = Le(s, e.dense2)),
+        (s = Le(s, e.dense3)),
+        (s = Nt.avgPool(s, [7, 7], [2, 2], 'valid')),
+        s
+      )
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  getDefaultModelName() {
+    return 'face_feature_extractor_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return wo(t)
+  }
+  extractParams(t) {
+    return _o(t)
+  }
+}
+var Mo = b(g())
+var de = b(g())
+function Ae(o, t) {
+  return de.tidy(() => de.add(de.matMul(o, t.weights), t.bias))
+}
+function Do(o, t, e) {
+  let r = [],
+    {extractWeights: n, getRemainingWeights: a} = B(o),
+    i = rr(n, r)(t, e, 'fc')
+  if (a().length !== 0) throw new Error(`weights remaing after extract: ${a().length}`)
+  return {paramMappings: r, params: {fc: i}}
+}
+function Eo(o) {
+  let t = [],
+    e = j(o, t)
+  function r(a) {
+    let s = e(`${a}/weights`, 2),
+      i = e(`${a}/bias`, 1)
+    return {weights: s, bias: i}
+  }
+  let n = {fc: r('fc')}
+  return W(o, t), {params: n, paramMappings: t}
+}
+function ir(o) {
+  let t = {},
+    e = {}
+  return (
+    Object.keys(o).forEach(r => {
+      let n = r.startsWith('fc') ? e : t
+      n[r] = o[r]
+    }),
+    {featureExtractorMap: t, classifierMap: e}
+  )
+}
+var We = class extends S {
+  constructor(t, e) {
+    super(t)
+    this._faceFeatureExtractor = e
+  }
+  get faceFeatureExtractor() {
+    return this._faceFeatureExtractor
+  }
+  runNet(t) {
+    let {params: e} = this
+    if (!e) throw new Error(`${this._name} - load model before inference`)
+    return Mo.tidy(() => {
+      let r = t instanceof bt ? this.faceFeatureExtractor.forwardInput(t) : t
+      return Ae(r.as2D(r.shape[0], -1), e.fc)
+    })
+  }
+  dispose(t = !0) {
+    this.faceFeatureExtractor.dispose(t), super.dispose(t)
+  }
+  loadClassifierParams(t) {
+    let {params: e, paramMappings: r} = this.extractClassifierParams(t)
+    ;(this._params = e), (this._paramMappings = r)
+  }
+  extractClassifierParams(t) {
+    return Do(t, this.getClassifierChannelsIn(), this.getClassifierChannelsOut())
+  }
+  extractParamsFromWeightMap(t) {
+    let {featureExtractorMap: e, classifierMap: r} = ir(t)
+    return this.faceFeatureExtractor.loadFromWeightMap(e), Eo(r)
+  }
+  extractParams(t) {
+    let e = this.getClassifierChannelsIn(),
+      r = this.getClassifierChannelsOut(),
+      n = r * e + r,
+      a = t.slice(0, t.length - n),
+      s = t.slice(t.length - n)
+    return this.faceFeatureExtractor.extractWeights(a), this.extractClassifierParams(s)
+  }
+}
+var Jr = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised'],
+  It = class {
+    constructor(t) {
+      if (t.length !== 7)
+        throw new Error(
+          `FaceExpressions.constructor - expected probabilities.length to be 7, have: ${t.length}`,
+        )
+      Jr.forEach((e, r) => {
+        this[e] = t[r]
+      })
+    }
+    asSortedArray() {
+      return Jr.map(t => ({expression: t, probability: this[t]})).sort(
+        (t, e) => e.probability - t.probability,
+      )
+    }
+  }
+var cr = class extends We {
+  constructor(t = new Se()) {
+    super('FaceExpressionNet', t)
+  }
+  forwardInput(t) {
+    return ue.tidy(() => ue.softmax(this.runNet(t)))
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  async predictExpressions(t) {
+    let e = await E(t),
+      r = await this.forwardInput(e),
+      n = await Promise.all(
+        ue.unstack(r).map(async s => {
+          let i = await s.data()
+          return s.dispose(), i
+        }),
+      )
+    r.dispose()
+    let a = n.map(s => new It(s))
+    return e.isBatchInput ? a : a[0]
+  }
+  getDefaultModelName() {
+    return 'face_expression_model'
+  }
+  getClassifierChannelsIn() {
+    return 256
+  }
+  getClassifierChannelsOut() {
+    return 7
+  }
+}
+function qr(o) {
+  return o.expressions instanceof It
+}
+function mr(o, t) {
+  return {...o, ...{expressions: t}}
+}
+function $n(o, t, e = 0.1, r) {
+  ;(Array.isArray(t) ? t : [t]).forEach(a => {
+    let s = a instanceof It ? a : qr(a) ? a.expressions : void 0
+    if (!s)
+      throw new Error(
+        'drawFaceExpressions - expected faceExpressions to be FaceExpressions | WithFaceExpressions<{}> or array thereof',
+      )
+    let c = s.asSortedArray().filter(d => d.probability > e),
+      m = pt(a) ? a.detection.box.bottomLeft : r || new x(0, 0)
+    new Mt(
+      c.map(d => `${d.expression} (${Rt(d.probability)})`),
+      m,
+    ).draw(o)
+  })
+}
+function zt(o) {
+  return (
+    pt(o) &&
+    o.landmarks instanceof V &&
+    o.unshiftedLandmarks instanceof V &&
+    o.alignedRect instanceof M
+  )
+}
+function le(o, t) {
+  let {box: e} = o.detection,
+    r = t.shiftBy(e.x, e.y),
+    n = r.align(),
+    {imageDims: a} = o.detection,
+    s = new M(o.detection.score, n.rescale(a.reverse()), a)
+  return {...o, ...{landmarks: r, unshiftedLandmarks: t, alignedRect: s}}
+}
+var Zr = class {
+    constructor(t = {}) {
+      let {
+        drawLines: e = !0,
+        drawPoints: r = !0,
+        lineWidth: n,
+        lineColor: a,
+        pointSize: s,
+        pointColor: i,
+      } = t
+      ;(this.drawLines = e),
+        (this.drawPoints = r),
+        (this.lineWidth = n || 1),
+        (this.pointSize = s || 2),
+        (this.lineColor = a || 'rgba(0, 255, 255, 1)'),
+        (this.pointColor = i || 'rgba(255, 0, 255, 1)')
+    }
+  },
+  Kr = class {
+    constructor(t, e = {}) {
+      ;(this.faceLandmarks = t), (this.options = new Zr(e))
+    }
+    draw(t) {
+      let e = O(t),
+        {
+          drawLines: r,
+          drawPoints: n,
+          lineWidth: a,
+          lineColor: s,
+          pointSize: i,
+          pointColor: c,
+        } = this.options
+      if (
+        (r &&
+          this.faceLandmarks instanceof oe &&
+          ((e.strokeStyle = s),
+          (e.lineWidth = a),
+          ft(e, this.faceLandmarks.getJawOutline()),
+          ft(e, this.faceLandmarks.getLeftEyeBrow()),
+          ft(e, this.faceLandmarks.getRightEyeBrow()),
+          ft(e, this.faceLandmarks.getNose()),
+          ft(e, this.faceLandmarks.getLeftEye(), !0),
+          ft(e, this.faceLandmarks.getRightEye(), !0),
+          ft(e, this.faceLandmarks.getMouth(), !0)),
+        n)
+      ) {
+        ;(e.strokeStyle = c), (e.fillStyle = c)
+        let m = p => {
+          e.beginPath(), e.arc(p.x, p.y, i, 0, 2 * Math.PI), e.fill()
+        }
+        this.faceLandmarks.positions.forEach(m)
+      }
+    }
+  }
+function jn(o, t) {
+  ;(Array.isArray(t) ? t : [t]).forEach(r => {
+    let n = r instanceof V ? r : zt(r) ? r.landmarks : void 0
+    if (!n)
+      throw new Error(
+        'drawFaceLandmarks - expected faceExpressions to be FaceLandmarks | WithFaceLandmarks<WithFaceDetection<{}>> or array thereof',
+      )
+    new Kr(n).draw(o)
+  })
+}
+var Co = '0.11.4'
+var ut = b(g())
+var I = b(g())
+function Hn(o, t) {
+  let e = ce(o, t),
+    r = me(o, t)
+  function n(s, i, c) {
+    let m = r(s, i, `${c}/separable_conv0`),
+      p = r(i, i, `${c}/separable_conv1`),
+      d = e(s, i, 1, `${c}/expansion_conv`)
+    return {separable_conv0: m, separable_conv1: p, expansion_conv: d}
+  }
+  function a(s, i) {
+    let c = r(s, s, `${i}/separable_conv0`),
+      m = r(s, s, `${i}/separable_conv1`),
+      p = r(s, s, `${i}/separable_conv2`)
+    return {separable_conv0: c, separable_conv1: m, separable_conv2: p}
+  }
+  return {
+    extractConvParams: e,
+    extractSeparableConvParams: r,
+    extractReductionBlockParams: n,
+    extractMainBlockParams: a,
+  }
+}
+function No(o, t) {
+  let e = [],
+    {extractWeights: r, getRemainingWeights: n} = B(o),
+    {
+      extractConvParams: a,
+      extractSeparableConvParams: s,
+      extractReductionBlockParams: i,
+      extractMainBlockParams: c,
+    } = Hn(r, e),
+    m = a(3, 32, 3, 'entry_flow/conv_in'),
+    p = i(32, 64, 'entry_flow/reduction_block_0'),
+    d = i(64, 128, 'entry_flow/reduction_block_1'),
+    u = {conv_in: m, reduction_block_0: p, reduction_block_1: d},
+    l = {}
+  ct(t, 0, 1).forEach(y => {
+    l[`main_block_${y}`] = c(128, `middle_flow/main_block_${y}`)
+  })
+  let v = i(128, 256, 'exit_flow/reduction_block'),
+    _ = s(256, 512, 'exit_flow/separable_conv'),
+    h = {reduction_block: v, separable_conv: _}
+  if (n().length !== 0) throw new Error(`weights remaing after extract: ${n().length}`)
+  return {paramMappings: e, params: {entry_flow: u, middle_flow: l, exit_flow: h}}
+}
+function Yn(o, t) {
+  let e = j(o, t),
+    r = ar(e),
+    n = pe(e)
+  function a(i) {
+    let c = n(`${i}/separable_conv0`),
+      m = n(`${i}/separable_conv1`),
+      p = r(`${i}/expansion_conv`)
+    return {separable_conv0: c, separable_conv1: m, expansion_conv: p}
+  }
+  function s(i) {
+    let c = n(`${i}/separable_conv0`),
+      m = n(`${i}/separable_conv1`),
+      p = n(`${i}/separable_conv2`)
+    return {separable_conv0: c, separable_conv1: m, separable_conv2: p}
+  }
+  return {
+    extractConvParams: r,
+    extractSeparableConvParams: n,
+    extractReductionBlockParams: a,
+    extractMainBlockParams: s,
+  }
+}
+function Io(o, t) {
+  let e = [],
+    {
+      extractConvParams: r,
+      extractSeparableConvParams: n,
+      extractReductionBlockParams: a,
+      extractMainBlockParams: s,
+    } = Yn(o, e),
+    i = r('entry_flow/conv_in'),
+    c = a('entry_flow/reduction_block_0'),
+    m = a('entry_flow/reduction_block_1'),
+    p = {conv_in: i, reduction_block_0: c, reduction_block_1: m},
+    d = {}
+  ct(t, 0, 1).forEach(_ => {
+    d[`main_block_${_}`] = s(`middle_flow/main_block_${_}`)
+  })
+  let u = a('exit_flow/reduction_block'),
+    l = n('exit_flow/separable_conv'),
+    v = {reduction_block: u, separable_conv: l}
+  return W(o, e), {params: {entry_flow: p, middle_flow: d, exit_flow: v}, paramMappings: e}
+}
+function Lo(o, t, e) {
+  return I.add(I.conv2d(o, t.filters, e, 'same'), t.bias)
+}
+function to(o, t, e = !0) {
+  let r = e ? I.relu(o) : o
+  return (
+    (r = $(r, t.separable_conv0, [1, 1])),
+    (r = $(I.relu(r), t.separable_conv1, [1, 1])),
+    (r = I.maxPool(r, [3, 3], [2, 2], 'same')),
+    (r = I.add(r, Lo(o, t.expansion_conv, [2, 2]))),
+    r
+  )
+}
+function Gn(o, t) {
+  let e = $(I.relu(o), t.separable_conv0, [1, 1])
+  return (
+    (e = $(I.relu(e), t.separable_conv1, [1, 1])),
+    (e = $(I.relu(e), t.separable_conv2, [1, 1])),
+    (e = I.add(e, o)),
+    e
+  )
+}
+var eo = class extends S {
+  constructor(t) {
+    super('TinyXception')
+    this._numMainBlocks = t
+  }
+  forwardInput(t) {
+    let {params: e} = this
+    if (!e) throw new Error('TinyXception - load model before inference')
+    return I.tidy(() => {
+      let r = I.cast(t.toBatchTensor(112, !0), 'float32'),
+        a = ot(r, [122.782, 117.001, 104.298]).div(I.scalar(256)),
+        s = I.relu(Lo(a, e.entry_flow.conv_in, [2, 2]))
+      return (
+        (s = to(s, e.entry_flow.reduction_block_0, !1)),
+        (s = to(s, e.entry_flow.reduction_block_1)),
+        ct(this._numMainBlocks, 0, 1).forEach(i => {
+          s = Gn(s, e.middle_flow[`main_block_${i}`])
+        }),
+        (s = to(s, e.exit_flow.reduction_block)),
+        (s = I.relu($(s, e.exit_flow.separable_conv, [1, 1]))),
+        s
+      )
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  getDefaultModelName() {
+    return 'tiny_xception_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return Io(t, this._numMainBlocks)
+  }
+  extractParams(t) {
+    return No(t, this._numMainBlocks)
+  }
+}
+function ko(o) {
+  let t = [],
+    {extractWeights: e, getRemainingWeights: r} = B(o),
+    n = rr(e, t),
+    a = n(512, 1, 'fc/age'),
+    s = n(512, 2, 'fc/gender')
+  if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`)
+  return {paramMappings: t, params: {fc: {age: a, gender: s}}}
+}
+function So(o) {
+  let t = [],
+    e = j(o, t)
+  function r(a) {
+    let s = e(`${a}/weights`, 2),
+      i = e(`${a}/bias`, 1)
+    return {weights: s, bias: i}
+  }
+  let n = {fc: {age: r('fc/age'), gender: r('fc/gender')}}
+  return W(o, t), {params: n, paramMappings: t}
+}
+var vt
+;(function(o) {
+  ;(o.FEMALE = 'female'), (o.MALE = 'male')
+})(vt || (vt = {}))
+var pr = class extends S {
+  constructor(t = new eo(2)) {
+    super('AgeGenderNet')
+    this._faceFeatureExtractor = t
+  }
+  get faceFeatureExtractor() {
+    return this._faceFeatureExtractor
+  }
+  runNet(t) {
+    let {params: e} = this
+    if (!e) throw new Error(`${this._name} - load model before inference`)
+    return ut.tidy(() => {
+      let r = t instanceof bt ? this.faceFeatureExtractor.forwardInput(t) : t,
+        n = ut.avgPool(r, [7, 7], [2, 2], 'valid').as2D(r.shape[0], -1),
+        a = Ae(n, e.fc.age).as1D(),
+        s = Ae(n, e.fc.gender)
+      return {age: a, gender: s}
+    })
+  }
+  forwardInput(t) {
+    return ut.tidy(() => {
+      let {age: e, gender: r} = this.runNet(t)
+      return {age: e, gender: ut.softmax(r)}
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  async predictAgeAndGender(t) {
+    let e = await E(t),
+      r = await this.forwardInput(e),
+      n = ut.unstack(r.age),
+      a = ut.unstack(r.gender),
+      s = n.map((c, m) => ({ageTensor: c, genderTensor: a[m]})),
+      i = await Promise.all(
+        s.map(async ({ageTensor: c, genderTensor: m}) => {
+          let p = (await c.data())[0],
+            d = (await m.data())[0],
+            u = d > 0.5,
+            l = u ? vt.MALE : vt.FEMALE,
+            v = u ? d : 1 - d
+          return c.dispose(), m.dispose(), {age: p, gender: l, genderProbability: v}
+        }),
+      )
+    return r.age.dispose(), r.gender.dispose(), e.isBatchInput ? i : i[0]
+  }
+  getDefaultModelName() {
+    return 'age_gender_model'
+  }
+  dispose(t = !0) {
+    this.faceFeatureExtractor.dispose(t), super.dispose(t)
+  }
+  loadClassifierParams(t) {
+    let {params: e, paramMappings: r} = this.extractClassifierParams(t)
+    ;(this._params = e), (this._paramMappings = r)
+  }
+  extractClassifierParams(t) {
+    return ko(t)
+  }
+  extractParamsFromWeightMap(t) {
+    let {featureExtractorMap: e, classifierMap: r} = ir(t)
+    return this.faceFeatureExtractor.loadFromWeightMap(e), So(r)
+  }
+  extractParams(t) {
+    let e = 512 * 1 + 1 + (512 * 2 + 2),
+      r = t.slice(0, t.length - e),
+      n = t.slice(t.length - e)
+    return this.faceFeatureExtractor.extractWeights(r), this.extractClassifierParams(n)
+  }
+}
+var H = b(g())
+var Be = class extends We {
+  postProcess(t, e, r) {
+    let n = r.map(({width: s, height: i}) => {
+        let c = e / Math.max(i, s)
+        return {width: s * c, height: i * c}
+      }),
+      a = n.length
+    return H.tidy(() => {
+      let s = (d, u) =>
+          H.stack([H.fill([68], d, 'float32'), H.fill([68], u, 'float32')], 1)
+            .as2D(1, 136)
+            .as1D(),
+        i = (d, u) => {
+          let {width: l, height: v} = n[d]
+          return u(l, v) ? Math.abs(l - v) / 2 : 0
+        },
+        c = d => i(d, (u, l) => u < l),
+        m = d => i(d, (u, l) => l < u)
+      return t
+        .mul(H.fill([a, 136], e, 'float32'))
+        .sub(H.stack(Array.from(Array(a), (d, u) => s(c(u), m(u)))))
+        .div(H.stack(Array.from(Array(a), (d, u) => s(n[u].width, n[u].height))))
+    })
+  }
+  forwardInput(t) {
+    return H.tidy(() => {
+      let e = this.runNet(t)
+      return this.postProcess(
+        e,
+        t.inputSize,
+        t.inputDimensions.map(([r, n]) => ({height: r, width: n})),
+      )
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  async detectLandmarks(t) {
+    let e = await E(t),
+      r = H.tidy(() => H.unstack(this.forwardInput(e))),
+      n = await Promise.all(
+        r.map(async (a, s) => {
+          let i = Array.from(await a.data()),
+            c = i.filter((p, d) => ze(d)),
+            m = i.filter((p, d) => !ze(d))
+          return new oe(
+            Array(68)
+              .fill(0)
+              .map((p, d) => new x(c[d], m[d])),
+            {height: e.getInputHeight(s), width: e.getInputWidth(s)},
+          )
+        }),
+      )
+    return r.forEach(a => a.dispose()), e.isBatchInput ? n : n[0]
+  }
+  getClassifierChannelsOut() {
+    return 136
+  }
+}
+var fe = class extends Be {
+  constructor(t = new Se()) {
+    super('FaceLandmark68Net', t)
+  }
+  getDefaultModelName() {
+    return 'face_landmark_68_model'
+  }
+  getClassifierChannelsIn() {
+    return 256
+  }
+}
+var Lt = b(g())
+function Ao(o) {
+  let t = [],
+    {extractDenseBlock3Params: e} = sr(o, t),
+    r = {dense0: e('dense0', !0), dense1: e('dense1'), dense2: e('dense2')}
+  return W(o, t), {params: r, paramMappings: t}
+}
+function Wo(o) {
+  let t = [],
+    {extractWeights: e, getRemainingWeights: r} = B(o),
+    {extractDenseBlock3Params: n} = nr(e, t),
+    a = n(3, 32, 'dense0', !0),
+    s = n(32, 64, 'dense1'),
+    i = n(64, 128, 'dense2')
+  if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`)
+  return {paramMappings: t, params: {dense0: a, dense1: s, dense2: i}}
+}
+var ro = class extends S {
+  constructor() {
+    super('TinyFaceFeatureExtractor')
+  }
+  forwardInput(t) {
+    let {params: e} = this
+    if (!e) throw new Error('TinyFaceFeatureExtractor - load model before inference')
+    return Lt.tidy(() => {
+      let r = Lt.cast(t.toBatchTensor(112, !0), 'float32'),
+        a = ot(r, [122.782, 117.001, 104.298]).div(Lt.scalar(255)),
+        s = Qe(a, e.dense0, !0)
+      return (
+        (s = Qe(s, e.dense1)),
+        (s = Qe(s, e.dense2)),
+        (s = Lt.avgPool(s, [14, 14], [2, 2], 'valid')),
+        s
+      )
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  getDefaultModelName() {
+    return 'face_feature_extractor_tiny_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return Ao(t)
+  }
+  extractParams(t) {
+    return Wo(t)
+  }
+}
+var dr = class extends Be {
+  constructor(t = new ro()) {
+    super('FaceLandmark68TinyNet', t)
+  }
+  getDefaultModelName() {
+    return 'face_landmark_68_tiny_model'
+  }
+  getClassifierChannelsIn() {
+    return 128
+  }
+}
+var Bo = class extends fe {}
+var U = b(g())
+var he = b(g())
+var ur = b(g())
+function Ro(o, t) {
+  return ur.add(ur.mul(o, t.weights), t.biases)
+}
+function oo(o, t, e, r, n = 'same') {
+  let {filters: a, bias: s} = t.conv,
+    i = he.conv2d(o, a, e, n)
+  return (i = he.add(i, s)), (i = Ro(i, t.scale)), r ? he.relu(i) : i
+}
+function Oo(o, t) {
+  return oo(o, t, [1, 1], !0)
+}
+function no(o, t) {
+  return oo(o, t, [1, 1], !1)
+}
+function lr(o, t) {
+  return oo(o, t, [2, 2], !0, 'valid')
+}
+var Y = b(g())
+function zn(o, t) {
+  function e(i, c, m) {
+    let p = o(i),
+      d = p.length / (c * m * m)
+    if (Nr(d))
+      throw new Error(
+        `depth has to be an integer: ${d}, weights.length: ${p.length}, numFilters: ${c}, filterSize: ${m}`,
+      )
+    return Y.tidy(() => Y.transpose(Y.tensor4d(p, [c, d, m, m]), [2, 3, 1, 0]))
+  }
+  function r(i, c, m, p) {
+    let d = e(i, c, m),
+      u = Y.tensor1d(o(c))
+    return t.push({paramPath: `${p}/filters`}, {paramPath: `${p}/bias`}), {filters: d, bias: u}
+  }
+  function n(i, c) {
+    let m = Y.tensor1d(o(i)),
+      p = Y.tensor1d(o(i))
+    return t.push({paramPath: `${c}/weights`}, {paramPath: `${c}/biases`}), {weights: m, biases: p}
+  }
+  function a(i, c, m, p) {
+    let d = r(i, c, m, `${p}/conv`),
+      u = n(c, `${p}/scale`)
+    return {conv: d, scale: u}
+  }
+  function s(i, c, m, p, d = !1) {
+    let u = a((d ? 0.5 : 1) * i, c, m, `${p}/conv1`),
+      l = a(i, c, m, `${p}/conv2`)
+    return {conv1: u, conv2: l}
+  }
+  return {extractConvLayerParams: a, extractResidualLayerParams: s}
+}
+function $o(o) {
+  let {extractWeights: t, getRemainingWeights: e} = B(o),
+    r = [],
+    {extractConvLayerParams: n, extractResidualLayerParams: a} = zn(t, r),
+    s = n(4704, 32, 7, 'conv32_down'),
+    i = a(9216, 32, 3, 'conv32_1'),
+    c = a(9216, 32, 3, 'conv32_2'),
+    m = a(9216, 32, 3, 'conv32_3'),
+    p = a(36864, 64, 3, 'conv64_down', !0),
+    d = a(36864, 64, 3, 'conv64_1'),
+    u = a(36864, 64, 3, 'conv64_2'),
+    l = a(36864, 64, 3, 'conv64_3'),
+    v = a(147456, 128, 3, 'conv128_down', !0),
+    _ = a(147456, 128, 3, 'conv128_1'),
+    h = a(147456, 128, 3, 'conv128_2'),
+    y = a(589824, 256, 3, 'conv256_down', !0),
+    T = a(589824, 256, 3, 'conv256_1'),
+    F = a(589824, 256, 3, 'conv256_2'),
+    L = a(589824, 256, 3, 'conv256_down_out'),
+    G = Y.tidy(() => Y.transpose(Y.tensor2d(t(256 * 128), [128, 256]), [1, 0]))
+  if ((r.push({paramPath: 'fc'}), e().length !== 0))
+    throw new Error(`weights remaing after extract: ${e().length}`)
+  return {
+    params: {
+      conv32_down: s,
+      conv32_1: i,
+      conv32_2: c,
+      conv32_3: m,
+      conv64_down: p,
+      conv64_1: d,
+      conv64_2: u,
+      conv64_3: l,
+      conv128_down: v,
+      conv128_1: _,
+      conv128_2: h,
+      conv256_down: y,
+      conv256_1: T,
+      conv256_2: F,
+      conv256_down_out: L,
+      fc: G,
+    },
+    paramMappings: r,
+  }
+}
+function Vn(o, t) {
+  let e = j(o, t)
+  function r(s) {
+    let i = e(`${s}/scale/weights`, 1),
+      c = e(`${s}/scale/biases`, 1)
+    return {weights: i, biases: c}
+  }
+  function n(s) {
+    let i = e(`${s}/conv/filters`, 4),
+      c = e(`${s}/conv/bias`, 1),
+      m = r(s)
+    return {conv: {filters: i, bias: c}, scale: m}
+  }
+  function a(s) {
+    return {conv1: n(`${s}/conv1`), conv2: n(`${s}/conv2`)}
+  }
+  return {extractConvLayerParams: n, extractResidualLayerParams: a}
+}
+function jo(o) {
+  let t = [],
+    {extractConvLayerParams: e, extractResidualLayerParams: r} = Vn(o, t),
+    n = e('conv32_down'),
+    a = r('conv32_1'),
+    s = r('conv32_2'),
+    i = r('conv32_3'),
+    c = r('conv64_down'),
+    m = r('conv64_1'),
+    p = r('conv64_2'),
+    d = r('conv64_3'),
+    u = r('conv128_down'),
+    l = r('conv128_1'),
+    v = r('conv128_2'),
+    _ = r('conv256_down'),
+    h = r('conv256_1'),
+    y = r('conv256_2'),
+    T = r('conv256_down_out'),
+    {fc: F} = o
+  if ((t.push({originalPath: 'fc', paramPath: 'fc'}), !Cr(F)))
+    throw new Error(`expected weightMap[fc] to be a Tensor2D, instead have ${F}`)
+  let L = {
+    conv32_down: n,
+    conv32_1: a,
+    conv32_2: s,
+    conv32_3: i,
+    conv64_down: c,
+    conv64_1: m,
+    conv64_2: p,
+    conv64_3: d,
+    conv128_down: u,
+    conv128_1: l,
+    conv128_2: v,
+    conv256_down: _,
+    conv256_1: h,
+    conv256_2: y,
+    conv256_down_out: T,
+    fc: F,
+  }
+  return W(o, t), {params: L, paramMappings: t}
+}
+var R = b(g())
+function nt(o, t) {
+  let e = Oo(o, t.conv1)
+  return (e = no(e, t.conv2)), (e = R.add(e, o)), (e = R.relu(e)), e
+}
+function Re(o, t) {
+  let e = lr(o, t.conv1)
+  e = no(e, t.conv2)
+  let r = R.avgPool(o, 2, 2, 'valid'),
+    n = R.zeros(r.shape),
+    a = r.shape[3] !== e.shape[3]
+  if (r.shape[1] !== e.shape[1] || r.shape[2] !== e.shape[2]) {
+    let i = [...e.shape]
+    i[1] = 1
+    let c = R.zeros(i)
+    e = R.concat([e, c], 1)
+    let m = [...e.shape]
+    m[2] = 1
+    let p = R.zeros(m)
+    e = R.concat([e, p], 2)
+  }
+  return (r = a ? R.concat([r, n], 3) : r), (e = R.add(r, e)), (e = R.relu(e)), e
+}
+var xe = class extends S {
+  constructor() {
+    super('FaceRecognitionNet')
+  }
+  forwardInput(t) {
+    let {params: e} = this
+    if (!e) throw new Error('FaceRecognitionNet - load model before inference')
+    return U.tidy(() => {
+      let r = U.cast(t.toBatchTensor(150, !0), 'float32'),
+        a = ot(r, [122.782, 117.001, 104.298]).div(U.scalar(256)),
+        s = lr(a, e.conv32_down)
+      ;(s = U.maxPool(s, 3, 2, 'valid')),
+        (s = nt(s, e.conv32_1)),
+        (s = nt(s, e.conv32_2)),
+        (s = nt(s, e.conv32_3)),
+        (s = Re(s, e.conv64_down)),
+        (s = nt(s, e.conv64_1)),
+        (s = nt(s, e.conv64_2)),
+        (s = nt(s, e.conv64_3)),
+        (s = Re(s, e.conv128_down)),
+        (s = nt(s, e.conv128_1)),
+        (s = nt(s, e.conv128_2)),
+        (s = Re(s, e.conv256_down)),
+        (s = nt(s, e.conv256_1)),
+        (s = nt(s, e.conv256_2)),
+        (s = Re(s, e.conv256_down_out))
+      let i = s.mean([1, 2])
+      return U.matMul(i, e.fc)
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  async computeFaceDescriptor(t) {
+    let e = await E(t),
+      r = U.tidy(() => U.unstack(this.forwardInput(e))),
+      n = await Promise.all(r.map(a => a.data()))
+    return r.forEach(a => a.dispose()), e.isBatchInput ? n : n[0]
+  }
+  getDefaultModelName() {
+    return 'face_recognition_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return jo(t)
+  }
+  extractParams(t) {
+    return $o(t)
+  }
+}
+function Un(o) {
+  let t = new xe()
+  return t.extractWeights(o), t
+}
+function fr(o, t) {
+  return {...o, ...{descriptor: t}}
+}
+function Xn(o) {
+  return typeof o.age == 'number'
+}
+function hr(o, t) {
+  return {...o, ...{age: t}}
+}
+function Jn(o) {
+  return (o.gender === vt.MALE || o.gender === vt.FEMALE) && te(o.genderProbability)
+}
+function xr(o, t, e) {
+  return {...o, ...{gender: t, genderProbability: e}}
+}
+var st = b(g())
+var at = b(g())
+function qn(o, t) {
+  function e(c, m) {
+    let p = at.tensor4d(o(3 * 3 * c), [3, 3, c, 1]),
+      d = at.tensor1d(o(c)),
+      u = at.tensor1d(o(c)),
+      l = at.tensor1d(o(c)),
+      v = at.tensor1d(o(c))
+    return (
+      t.push(
+        {paramPath: `${m}/filters`},
+        {paramPath: `${m}/batch_norm_scale`},
+        {paramPath: `${m}/batch_norm_offset`},
+        {paramPath: `${m}/batch_norm_mean`},
+        {paramPath: `${m}/batch_norm_variance`},
+      ),
+      {
+        filters: p,
+        batch_norm_scale: d,
+        batch_norm_offset: u,
+        batch_norm_mean: l,
+        batch_norm_variance: v,
+      }
+    )
+  }
+  function r(c, m, p, d, u) {
+    let l = at.tensor4d(o(c * m * p * p), [p, p, c, m]),
+      v = at.tensor1d(o(m))
+    return (
+      t.push({paramPath: `${d}/filters`}, {paramPath: `${d}/${u ? 'batch_norm_offset' : 'bias'}`}),
+      {filters: l, bias: v}
+    )
+  }
+  function n(c, m, p, d) {
+    let {filters: u, bias: l} = r(c, m, p, d, !0)
+    return {filters: u, batch_norm_offset: l}
+  }
+  function a(c, m, p) {
+    let d = e(c, `${p}/depthwise_conv`),
+      u = n(c, m, 1, `${p}/pointwise_conv`)
+    return {depthwise_conv: d, pointwise_conv: u}
+  }
+  function s() {
+    let c = n(3, 32, 3, 'mobilenetv1/conv_0'),
+      m = a(32, 64, 'mobilenetv1/conv_1'),
+      p = a(64, 128, 'mobilenetv1/conv_2'),
+      d = a(128, 128, 'mobilenetv1/conv_3'),
+      u = a(128, 256, 'mobilenetv1/conv_4'),
+      l = a(256, 256, 'mobilenetv1/conv_5'),
+      v = a(256, 512, 'mobilenetv1/conv_6'),
+      _ = a(512, 512, 'mobilenetv1/conv_7'),
+      h = a(512, 512, 'mobilenetv1/conv_8'),
+      y = a(512, 512, 'mobilenetv1/conv_9'),
+      T = a(512, 512, 'mobilenetv1/conv_10'),
+      F = a(512, 512, 'mobilenetv1/conv_11'),
+      L = a(512, 1024, 'mobilenetv1/conv_12'),
+      G = a(1024, 1024, 'mobilenetv1/conv_13')
+    return {
+      conv_0: c,
+      conv_1: m,
+      conv_2: p,
+      conv_3: d,
+      conv_4: u,
+      conv_5: l,
+      conv_6: v,
+      conv_7: _,
+      conv_8: h,
+      conv_9: y,
+      conv_10: T,
+      conv_11: F,
+      conv_12: L,
+      conv_13: G,
+    }
+  }
+  function i() {
+    let c = n(1024, 256, 1, 'prediction_layer/conv_0'),
+      m = n(256, 512, 3, 'prediction_layer/conv_1'),
+      p = n(512, 128, 1, 'prediction_layer/conv_2'),
+      d = n(128, 256, 3, 'prediction_layer/conv_3'),
+      u = n(256, 128, 1, 'prediction_layer/conv_4'),
+      l = n(128, 256, 3, 'prediction_layer/conv_5'),
+      v = n(256, 64, 1, 'prediction_layer/conv_6'),
+      _ = n(64, 128, 3, 'prediction_layer/conv_7'),
+      h = r(512, 12, 1, 'prediction_layer/box_predictor_0/box_encoding_predictor'),
+      y = r(512, 9, 1, 'prediction_layer/box_predictor_0/class_predictor'),
+      T = r(1024, 24, 1, 'prediction_layer/box_predictor_1/box_encoding_predictor'),
+      F = r(1024, 18, 1, 'prediction_layer/box_predictor_1/class_predictor'),
+      L = r(512, 24, 1, 'prediction_layer/box_predictor_2/box_encoding_predictor'),
+      G = r(512, 18, 1, 'prediction_layer/box_predictor_2/class_predictor'),
+      et = r(256, 24, 1, 'prediction_layer/box_predictor_3/box_encoding_predictor'),
+      it = r(256, 18, 1, 'prediction_layer/box_predictor_3/class_predictor'),
+      X = r(256, 24, 1, 'prediction_layer/box_predictor_4/box_encoding_predictor'),
+      Pt = r(256, 18, 1, 'prediction_layer/box_predictor_4/class_predictor'),
+      _t = r(128, 24, 1, 'prediction_layer/box_predictor_5/box_encoding_predictor'),
+      wt = r(128, 18, 1, 'prediction_layer/box_predictor_5/class_predictor')
+    return {
+      conv_0: c,
+      conv_1: m,
+      conv_2: p,
+      conv_3: d,
+      conv_4: u,
+      conv_5: l,
+      conv_6: v,
+      conv_7: _,
+      box_predictor_0: {box_encoding_predictor: h, class_predictor: y},
+      box_predictor_1: {box_encoding_predictor: T, class_predictor: F},
+      box_predictor_2: {box_encoding_predictor: L, class_predictor: G},
+      box_predictor_3: {box_encoding_predictor: et, class_predictor: it},
+      box_predictor_4: {box_encoding_predictor: X, class_predictor: Pt},
+      box_predictor_5: {box_encoding_predictor: _t, class_predictor: wt},
+    }
+  }
+  return {extractMobilenetV1Params: s, extractPredictionLayerParams: i}
+}
+function Ho(o) {
+  let t = [],
+    {extractWeights: e, getRemainingWeights: r} = B(o),
+    {extractMobilenetV1Params: n, extractPredictionLayerParams: a} = qn(e, t),
+    s = n(),
+    i = a(),
+    m = {extra_dim: at.tensor3d(e(5118 * 4), [1, 5118, 4])}
+  if ((t.push({paramPath: 'output_layer/extra_dim'}), r().length !== 0))
+    throw new Error(`weights remaing after extract: ${r().length}`)
+  return {params: {mobilenetv1: s, prediction_layer: i, output_layer: m}, paramMappings: t}
+}
+function Zn(o, t) {
+  let e = j(o, t)
+  function r(m, p, d) {
+    let u = e(`${m}/Conv2d_${p}_pointwise/weights`, 4, `${d}/filters`),
+      l = e(`${m}/Conv2d_${p}_pointwise/convolution_bn_offset`, 1, `${d}/batch_norm_offset`)
+    return {filters: u, batch_norm_offset: l}
+  }
+  function n(m) {
+    let p = `mobilenetv1/conv_${m}`,
+      d = `MobilenetV1/Conv2d_${m}_depthwise`,
+      u = `${p}/depthwise_conv`,
+      l = `${p}/pointwise_conv`,
+      v = e(`${d}/depthwise_weights`, 4, `${u}/filters`),
+      _ = e(`${d}/BatchNorm/gamma`, 1, `${u}/batch_norm_scale`),
+      h = e(`${d}/BatchNorm/beta`, 1, `${u}/batch_norm_offset`),
+      y = e(`${d}/BatchNorm/moving_mean`, 1, `${u}/batch_norm_mean`),
+      T = e(`${d}/BatchNorm/moving_variance`, 1, `${u}/batch_norm_variance`)
+    return {
+      depthwise_conv: {
+        filters: v,
+        batch_norm_scale: _,
+        batch_norm_offset: h,
+        batch_norm_mean: y,
+        batch_norm_variance: T,
+      },
+      pointwise_conv: r('MobilenetV1', m, l),
+    }
+  }
+  function a() {
+    return {
+      conv_0: r('MobilenetV1', 0, 'mobilenetv1/conv_0'),
+      conv_1: n(1),
+      conv_2: n(2),
+      conv_3: n(3),
+      conv_4: n(4),
+      conv_5: n(5),
+      conv_6: n(6),
+      conv_7: n(7),
+      conv_8: n(8),
+      conv_9: n(9),
+      conv_10: n(10),
+      conv_11: n(11),
+      conv_12: n(12),
+      conv_13: n(13),
+    }
+  }
+  function s(m, p) {
+    let d = e(`${m}/weights`, 4, `${p}/filters`),
+      u = e(`${m}/biases`, 1, `${p}/bias`)
+    return {filters: d, bias: u}
+  }
+  function i(m) {
+    let p = s(
+        `Prediction/BoxPredictor_${m}/BoxEncodingPredictor`,
+        `prediction_layer/box_predictor_${m}/box_encoding_predictor`,
+      ),
+      d = s(
+        `Prediction/BoxPredictor_${m}/ClassPredictor`,
+        `prediction_layer/box_predictor_${m}/class_predictor`,
+      )
+    return {box_encoding_predictor: p, class_predictor: d}
+  }
+  function c() {
+    return {
+      conv_0: r('Prediction', 0, 'prediction_layer/conv_0'),
+      conv_1: r('Prediction', 1, 'prediction_layer/conv_1'),
+      conv_2: r('Prediction', 2, 'prediction_layer/conv_2'),
+      conv_3: r('Prediction', 3, 'prediction_layer/conv_3'),
+      conv_4: r('Prediction', 4, 'prediction_layer/conv_4'),
+      conv_5: r('Prediction', 5, 'prediction_layer/conv_5'),
+      conv_6: r('Prediction', 6, 'prediction_layer/conv_6'),
+      conv_7: r('Prediction', 7, 'prediction_layer/conv_7'),
+      box_predictor_0: i(0),
+      box_predictor_1: i(1),
+      box_predictor_2: i(2),
+      box_predictor_3: i(3),
+      box_predictor_4: i(4),
+      box_predictor_5: i(5),
+    }
+  }
+  return {extractMobilenetV1Params: a, extractPredictionLayerParams: c}
+}
+function Yo(o) {
+  let t = [],
+    {extractMobilenetV1Params: e, extractPredictionLayerParams: r} = Zn(o, t),
+    n = o['Output/extra_dim']
+  if ((t.push({originalPath: 'Output/extra_dim', paramPath: 'output_layer/extra_dim'}), !ht(n)))
+    throw new Error(`expected weightMap['Output/extra_dim'] to be a Tensor3D, instead have ${n}`)
+  let a = {mobilenetv1: e(), prediction_layer: r(), output_layer: {extra_dim: n}}
+  return W(o, t), {params: a, paramMappings: t}
+}
+var yt = b(g())
+var kt = b(g())
+function q(o, t, e) {
+  return kt.tidy(() => {
+    let r = kt.conv2d(o, t.filters, e, 'same')
+    return (r = kt.add(r, t.batch_norm_offset)), kt.clipByValue(r, 0, 6)
+  })
+}
+var Kn = 0.0010000000474974513
+function Qn(o, t, e) {
+  return yt.tidy(() => {
+    let r = yt.depthwiseConv2d(o, t.filters, e, 'same')
+    return (
+      (r = yt.batchNorm(
+        r,
+        t.batch_norm_mean,
+        t.batch_norm_variance,
+        t.batch_norm_offset,
+        t.batch_norm_scale,
+        Kn,
+      )),
+      yt.clipByValue(r, 0, 6)
+    )
+  })
+}
+function ta(o) {
+  return [2, 4, 6, 12].some(t => t === o) ? [2, 2] : [1, 1]
+}
+function Go(o, t) {
+  return yt.tidy(() => {
+    let e,
+      r = q(o, t.conv_0, [2, 2])
+    if (
+      ([
+        t.conv_1,
+        t.conv_2,
+        t.conv_3,
+        t.conv_4,
+        t.conv_5,
+        t.conv_6,
+        t.conv_7,
+        t.conv_8,
+        t.conv_9,
+        t.conv_10,
+        t.conv_11,
+        t.conv_12,
+        t.conv_13,
+      ].forEach((a, s) => {
+        let i = s + 1,
+          c = ta(i)
+        ;(r = Qn(r, a.depthwise_conv, c)), (r = q(r, a.pointwise_conv, [1, 1])), i === 11 && (e = r)
+      }),
+      e === null)
+    )
+      throw new Error('mobileNetV1 - output of conv layer 11 is null')
+    return {out: r, conv11: e}
+  })
+}
+function ea(o, t, e) {
+  let r = o.arraySync(),
+    n = Math.min(r[t][0], r[t][2]),
+    a = Math.min(r[t][1], r[t][3]),
+    s = Math.max(r[t][0], r[t][2]),
+    i = Math.max(r[t][1], r[t][3]),
+    c = Math.min(r[e][0], r[e][2]),
+    m = Math.min(r[e][1], r[e][3]),
+    p = Math.max(r[e][0], r[e][2]),
+    d = Math.max(r[e][1], r[e][3]),
+    u = (s - n) * (i - a),
+    l = (p - c) * (d - m)
+  if (u <= 0 || l <= 0) return 0
+  let v = Math.max(n, c),
+    _ = Math.max(a, m),
+    h = Math.min(s, p),
+    y = Math.min(i, d),
+    T = Math.max(h - v, 0) * Math.max(y - _, 0)
+  return T / (u + l - T)
+}
+function zo(o, t, e, r, n) {
+  let a = o.shape[0],
+    s = Math.min(e, a),
+    i = t
+      .map((p, d) => ({score: p, boxIndex: d}))
+      .filter(p => p.score > n)
+      .sort((p, d) => d.score - p.score),
+    c = p => (p <= r ? 1 : 0),
+    m = []
+  return (
+    i.forEach(p => {
+      if (m.length >= s) return
+      let d = p.score
+      for (let u = m.length - 1; u >= 0; --u) {
+        let l = ea(o, p.boxIndex, m[u])
+        if (l !== 0 && ((p.score *= c(l)), p.score <= n)) break
+      }
+      d === p.score && m.push(p.boxIndex)
+    }),
+    m
+  )
+}
+var f = b(g())
+function ra(o) {
+  let t = f.unstack(f.transpose(o, [1, 0])),
+    e = [f.sub(t[2], t[0]), f.sub(t[3], t[1])],
+    r = [f.add(t[0], f.div(e[0], f.scalar(2))), f.add(t[1], f.div(e[1], f.scalar(2)))]
+  return {sizes: e, centers: r}
+}
+function oa(o, t) {
+  let {sizes: e, centers: r} = ra(o),
+    n = f.unstack(f.transpose(t, [1, 0])),
+    a = f.div(f.mul(f.exp(f.div(n[2], f.scalar(5))), e[0]), f.scalar(2)),
+    s = f.add(f.mul(f.div(n[0], f.scalar(10)), e[0]), r[0]),
+    i = f.div(f.mul(f.exp(f.div(n[3], f.scalar(5))), e[1]), f.scalar(2)),
+    c = f.add(f.mul(f.div(n[1], f.scalar(10)), e[1]), r[1])
+  return f.transpose(f.stack([f.sub(s, a), f.sub(c, i), f.add(s, a), f.add(c, i)]), [1, 0])
+}
+function Vo(o, t, e) {
+  return f.tidy(() => {
+    let r = o.shape[0],
+      n = oa(f.reshape(f.tile(e.extra_dim, [r, 1, 1]), [-1, 4]), f.reshape(o, [-1, 4]))
+    n = f.reshape(n, [r, n.shape[0] / r, 4])
+    let a = f.sigmoid(f.slice(t, [0, 0, 1], [-1, -1, -1])),
+      s = f.slice(a, [0, 0, 0], [-1, -1, 1])
+    s = f.reshape(s, [r, s.shape[1]])
+    let i = f.unstack(n),
+      c = f.unstack(s)
+    return {boxes: i, scores: c}
+  })
+}
+var $e = b(g())
+var Oe = b(g())
+function Vt(o, t) {
+  return Oe.tidy(() => {
+    let e = o.shape[0],
+      r = Oe.reshape(Gt(o, t.box_encoding_predictor), [e, -1, 1, 4]),
+      n = Oe.reshape(Gt(o, t.class_predictor), [e, -1, 3])
+    return {boxPredictionEncoding: r, classPrediction: n}
+  })
+}
+function Uo(o, t, e) {
+  return $e.tidy(() => {
+    let r = q(o, e.conv_0, [1, 1]),
+      n = q(r, e.conv_1, [2, 2]),
+      a = q(n, e.conv_2, [1, 1]),
+      s = q(a, e.conv_3, [2, 2]),
+      i = q(s, e.conv_4, [1, 1]),
+      c = q(i, e.conv_5, [2, 2]),
+      m = q(c, e.conv_6, [1, 1]),
+      p = q(m, e.conv_7, [2, 2]),
+      d = Vt(t, e.box_predictor_0),
+      u = Vt(o, e.box_predictor_1),
+      l = Vt(n, e.box_predictor_2),
+      v = Vt(s, e.box_predictor_3),
+      _ = Vt(c, e.box_predictor_4),
+      h = Vt(p, e.box_predictor_5),
+      y = $e.concat(
+        [
+          d.boxPredictionEncoding,
+          u.boxPredictionEncoding,
+          l.boxPredictionEncoding,
+          v.boxPredictionEncoding,
+          _.boxPredictionEncoding,
+          h.boxPredictionEncoding,
+        ],
+        1,
+      ),
+      T = $e.concat(
+        [
+          d.classPrediction,
+          u.classPrediction,
+          l.classPrediction,
+          v.classPrediction,
+          _.classPrediction,
+          h.classPrediction,
+        ],
+        1,
+      )
+    return {boxPredictions: y, classPredictions: T}
+  })
+}
+var Z = class {
+  constructor({minConfidence: t, maxResults: e} = {}) {
+    this._name = 'SsdMobilenetv1Options'
+    if (
+      ((this._minConfidence = t || 0.5),
+      (this._maxResults = e || 100),
+      typeof this._minConfidence != 'number' ||
+        this._minConfidence <= 0 ||
+        this._minConfidence >= 1)
+    )
+      throw new Error(`${this._name} - expected minConfidence to be a number between 0 and 1`)
+    if (typeof this._maxResults != 'number')
+      throw new Error(`${this._name} - expected maxResults to be a number`)
+  }
+  get minConfidence() {
+    return this._minConfidence
+  }
+  get maxResults() {
+    return this._maxResults
+  }
+}
+var Ut = class extends S {
+  constructor() {
+    super('SsdMobilenetv1')
+  }
+  forwardInput(t) {
+    let {params: e} = this
+    if (!e) throw new Error('SsdMobilenetv1 - load model before inference')
+    return st.tidy(() => {
+      let r = st.cast(t.toBatchTensor(512, !1), 'float32'),
+        n = st.sub(st.mul(r, st.scalar(0.007843137718737125)), st.scalar(1)),
+        a = Go(n, e.mobilenetv1),
+        {boxPredictions: s, classPredictions: i} = Uo(a.out, a.conv11, e.prediction_layer)
+      return Vo(s, i, e.output_layer)
+    })
+  }
+  async forward(t) {
+    return this.forwardInput(await E(t))
+  }
+  async locateFaces(t, e = {}) {
+    let {maxResults: r, minConfidence: n} = new Z(e),
+      a = await E(t),
+      {boxes: s, scores: i} = this.forwardInput(a),
+      c = s[0],
+      m = i[0]
+    for (let F = 1; F < s.length; F++) s[F].dispose(), i[F].dispose()
+    let p = Array.from(await m.data()),
+      u = zo(c, p, r, 0.5, n),
+      l = a.getReshapedInputDimensions(0),
+      v = a.inputSize,
+      _ = v / l.width,
+      h = v / l.height,
+      y = c.arraySync(),
+      T = u.map(F => {
+        let [L, G] = [Math.max(0, y[F][0]), Math.min(1, y[F][2])].map(X => X * h),
+          [et, it] = [Math.max(0, y[F][1]), Math.min(1, y[F][3])].map(X => X * _)
+        return new M(p[F], new re(et, L, it - et, G - L), {
+          height: a.getInputHeight(0),
+          width: a.getInputWidth(0),
+        })
+      })
+    return c.dispose(), m.dispose(), T
+  }
+  getDefaultModelName() {
+    return 'ssd_mobilenetv1_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return Yo(t)
+  }
+  extractParams(t) {
+    return Ho(t)
+  }
+}
+function Xo(o) {
+  let t = new Ut()
+  return t.extractWeights(o), t
+}
+function na(o) {
+  return Xo(o)
+}
+var Jo = class extends Ut {}
+var qo = 0.4,
+  Zo = [
+    new x(0.738768, 0.874946),
+    new x(2.42204, 2.65704),
+    new x(4.30971, 7.04493),
+    new x(10.246, 4.59428),
+    new x(12.6868, 11.8741),
+  ],
+  Ko = [
+    new x(1.603231, 2.094468),
+    new x(6.041143, 7.080126),
+    new x(2.882459, 3.518061),
+    new x(4.266906, 5.178857),
+    new x(9.041765, 10.66308),
+  ],
+  Qo = [117.001, 114.697, 97.404],
+  tn = 'tiny_yolov2_model',
+  en = 'tiny_yolov2_separable_conv_model'
+var N = b(g())
+var br = o => typeof o == 'number'
+function ao(o) {
+  if (!o) throw new Error(`invalid config: ${o}`)
+  if (typeof o.withSeparableConvs != 'boolean')
+    throw new Error(`config.withSeparableConvs has to be a boolean, have: ${o.withSeparableConvs}`)
+  if (!br(o.iouThreshold) || o.iouThreshold < 0 || o.iouThreshold > 1)
+    throw new Error(
+      `config.iouThreshold has to be a number between [0, 1], have: ${o.iouThreshold}`,
+    )
+  if (!Array.isArray(o.classes) || !o.classes.length || !o.classes.every(t => typeof t == 'string'))
+    throw new Error(
+      `config.classes has to be an array class names: string[], have: ${JSON.stringify(o.classes)}`,
+    )
+  if (
+    !Array.isArray(o.anchors) ||
+    !o.anchors.length ||
+    !o.anchors.map(t => t || {}).every(t => br(t.x) && br(t.y))
+  )
+    throw new Error(
+      `config.anchors has to be an array of { x: number, y: number }, have: ${JSON.stringify(
+        o.anchors,
+      )}`,
+    )
+  if (o.meanRgb && (!Array.isArray(o.meanRgb) || o.meanRgb.length !== 3 || !o.meanRgb.every(br)))
+    throw new Error(
+      `config.meanRgb has to be an array of shape [number, number, number], have: ${JSON.stringify(
+        o.meanRgb,
+      )}`,
+    )
+}
+var Q = b(g())
+var K = b(g())
+function be(o) {
+  return K.tidy(() => {
+    let t = K.mul(o, K.scalar(0.10000000149011612))
+    return K.add(K.relu(K.sub(o, t)), t)
+  })
+}
+function Ft(o, t) {
+  return Q.tidy(() => {
+    let e = Q.pad(o, [
+      [0, 0],
+      [1, 1],
+      [1, 1],
+      [0, 0],
+    ])
+    return (
+      (e = Q.conv2d(e, t.conv.filters, [1, 1], 'valid')),
+      (e = Q.sub(e, t.bn.sub)),
+      (e = Q.mul(e, t.bn.truediv)),
+      (e = Q.add(e, t.conv.bias)),
+      be(e)
+    )
+  })
+}
+var St = b(g())
+function Tt(o, t) {
+  return St.tidy(() => {
+    let e = St.pad(o, [
+      [0, 0],
+      [1, 1],
+      [1, 1],
+      [0, 0],
+    ])
+    return (
+      (e = St.separableConv2d(e, t.depthwise_filter, t.pointwise_filter, [1, 1], 'valid')),
+      (e = St.add(e, t.bias)),
+      be(e)
+    )
+  })
+}
+var so = b(g())
+function aa(o, t) {
+  let e = ce(o, t)
+  function r(s, i) {
+    let c = so.tensor1d(o(s)),
+      m = so.tensor1d(o(s))
+    return t.push({paramPath: `${i}/sub`}, {paramPath: `${i}/truediv`}), {sub: c, truediv: m}
+  }
+  function n(s, i, c) {
+    let m = e(s, i, 3, `${c}/conv`),
+      p = r(i, `${c}/bn`)
+    return {conv: m, bn: p}
+  }
+  let a = me(o, t)
+  return {extractConvParams: e, extractConvWithBatchNormParams: n, extractSeparableConvParams: a}
+}
+function rn(o, t, e, r) {
+  let {extractWeights: n, getRemainingWeights: a} = B(o),
+    s = [],
+    {extractConvParams: i, extractConvWithBatchNormParams: c, extractSeparableConvParams: m} = aa(
+      n,
+      s,
+    ),
+    p
+  if (t.withSeparableConvs) {
+    let [d, u, l, v, _, h, y, T, F] = r,
+      L = t.isFirstLayerConv2d ? i(d, u, 3, 'conv0') : m(d, u, 'conv0'),
+      G = m(u, l, 'conv1'),
+      et = m(l, v, 'conv2'),
+      it = m(v, _, 'conv3'),
+      X = m(_, h, 'conv4'),
+      Pt = m(h, y, 'conv5'),
+      _t = T ? m(y, T, 'conv6') : void 0,
+      wt = F ? m(T, F, 'conv7') : void 0,
+      Qt = i(F || T || y, 5 * e, 1, 'conv8')
+    p = {
+      conv0: L,
+      conv1: G,
+      conv2: et,
+      conv3: it,
+      conv4: X,
+      conv5: Pt,
+      conv6: _t,
+      conv7: wt,
+      conv8: Qt,
+    }
+  } else {
+    let [d, u, l, v, _, h, y, T, F] = r,
+      L = c(d, u, 'conv0'),
+      G = c(u, l, 'conv1'),
+      et = c(l, v, 'conv2'),
+      it = c(v, _, 'conv3'),
+      X = c(_, h, 'conv4'),
+      Pt = c(h, y, 'conv5'),
+      _t = c(y, T, 'conv6'),
+      wt = c(T, F, 'conv7'),
+      Qt = i(F, 5 * e, 1, 'conv8')
+    p = {
+      conv0: L,
+      conv1: G,
+      conv2: et,
+      conv3: it,
+      conv4: X,
+      conv5: Pt,
+      conv6: _t,
+      conv7: wt,
+      conv8: Qt,
+    }
+  }
+  if (a().length !== 0) throw new Error(`weights remaing after extract: ${a().length}`)
+  return {params: p, paramMappings: s}
+}
+function sa(o, t) {
+  let e = j(o, t)
+  function r(i) {
+    let c = e(`${i}/sub`, 1),
+      m = e(`${i}/truediv`, 1)
+    return {sub: c, truediv: m}
+  }
+  function n(i) {
+    let c = e(`${i}/filters`, 4),
+      m = e(`${i}/bias`, 1)
+    return {filters: c, bias: m}
+  }
+  function a(i) {
+    let c = n(`${i}/conv`),
+      m = r(`${i}/bn`)
+    return {conv: c, bn: m}
+  }
+  let s = pe(e)
+  return {extractConvParams: n, extractConvWithBatchNormParams: a, extractSeparableConvParams: s}
+}
+function on(o, t) {
+  let e = [],
+    {extractConvParams: r, extractConvWithBatchNormParams: n, extractSeparableConvParams: a} = sa(
+      o,
+      e,
+    ),
+    s
+  if (t.withSeparableConvs) {
+    let i = (t.filterSizes && t.filterSizes.length) || 9
+    s = {
+      conv0: t.isFirstLayerConv2d ? r('conv0') : a('conv0'),
+      conv1: a('conv1'),
+      conv2: a('conv2'),
+      conv3: a('conv3'),
+      conv4: a('conv4'),
+      conv5: a('conv5'),
+      conv6: i > 7 ? a('conv6') : void 0,
+      conv7: i > 8 ? a('conv7') : void 0,
+      conv8: r('conv8'),
+    }
+  } else
+    s = {
+      conv0: n('conv0'),
+      conv1: n('conv1'),
+      conv2: n('conv2'),
+      conv3: n('conv3'),
+      conv4: n('conv4'),
+      conv5: n('conv5'),
+      conv6: n('conv6'),
+      conv7: n('conv7'),
+      conv8: r('conv8'),
+    }
+  return W(o, e), {params: s, paramMappings: e}
+}
+var lt = class {
+  constructor({inputSize: t, scoreThreshold: e} = {}) {
+    this._name = 'TinyYolov2Options'
+    if (
+      ((this._inputSize = t || 416),
+      (this._scoreThreshold = e || 0.5),
+      typeof this._inputSize != 'number' || this._inputSize % 32 != 0)
+    )
+      throw new Error(`${this._name} - expected inputSize to be a number divisible by 32`)
+    if (
+      typeof this._scoreThreshold != 'number' ||
+      this._scoreThreshold <= 0 ||
+      this._scoreThreshold >= 1
+    )
+      throw new Error(`${this._name} - expected scoreThreshold to be a number between 0 and 1`)
+  }
+  get inputSize() {
+    return this._inputSize
+  }
+  get scoreThreshold() {
+    return this._scoreThreshold
+  }
+}
+var io = class extends S {
+    constructor(t) {
+      super('TinyYolov2')
+      ao(t), (this._config = t)
+    }
+    get config() {
+      return this._config
+    }
+    get withClassScores() {
+      return this.config.withClassScores || this.config.classes.length > 1
+    }
+    get boxEncodingSize() {
+      return 5 + (this.withClassScores ? this.config.classes.length : 0)
+    }
+    runTinyYolov2(t, e) {
+      let r = Ft(t, e.conv0)
+      return (
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Ft(r, e.conv1)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Ft(r, e.conv2)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Ft(r, e.conv3)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Ft(r, e.conv4)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Ft(r, e.conv5)),
+        (r = N.maxPool(r, [2, 2], [1, 1], 'same')),
+        (r = Ft(r, e.conv6)),
+        (r = Ft(r, e.conv7)),
+        Gt(r, e.conv8, 'valid', !1)
+      )
+    }
+    runMobilenet(t, e) {
+      let r = this.config.isFirstLayerConv2d ? be(Gt(t, e.conv0, 'valid', !1)) : Tt(t, e.conv0)
+      return (
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Tt(r, e.conv1)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Tt(r, e.conv2)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Tt(r, e.conv3)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Tt(r, e.conv4)),
+        (r = N.maxPool(r, [2, 2], [2, 2], 'same')),
+        (r = Tt(r, e.conv5)),
+        (r = N.maxPool(r, [2, 2], [1, 1], 'same')),
+        (r = e.conv6 ? Tt(r, e.conv6) : r),
+        (r = e.conv7 ? Tt(r, e.conv7) : r),
+        Gt(r, e.conv8, 'valid', !1)
+      )
+    }
+    forwardInput(t, e) {
+      let {params: r} = this
+      if (!r) throw new Error('TinyYolov2 - load model before inference')
+      return N.tidy(() => {
+        let n = N.cast(t.toBatchTensor(e, !1), 'float32')
+        return (
+          (n = this.config.meanRgb ? ot(n, this.config.meanRgb) : n),
+          (n = n.div(N.scalar(256))),
+          this.config.withSeparableConvs ? this.runMobilenet(n, r) : this.runTinyYolov2(n, r)
+        )
+      })
+    }
+    async forward(t, e) {
+      return this.forwardInput(await E(t), e)
+    }
+    async detect(t, e = {}) {
+      let {inputSize: r, scoreThreshold: n} = new lt(e),
+        a = await E(t),
+        s = await this.forwardInput(a, r),
+        i = N.tidy(() => N.unstack(s)[0].expandDims()),
+        c = {width: a.getInputWidth(0), height: a.getInputHeight(0)},
+        m = await this.extractBoxes(i, a.getReshapedInputDimensions(0), n)
+      s.dispose(), i.dispose()
+      let p = m.map(h => h.box),
+        d = m.map(h => h.score),
+        u = m.map(h => h.classScore),
+        l = m.map(h => this.config.classes[h.label])
+      return Sr(
+        p.map(h => h.rescale(r)),
+        d,
+        this.config.iouThreshold,
+        !0,
+      ).map(h => new Dt(d[h], u[h], l[h], p[h], c))
+    }
+    getDefaultModelName() {
+      return ''
+    }
+    extractParamsFromWeightMap(t) {
+      return on(t, this.config)
+    }
+    extractParams(t) {
+      let e = this.config.filterSizes || io.DEFAULT_FILTER_SIZES,
+        r = e ? e.length : void 0
+      if (r !== 7 && r !== 8 && r !== 9)
+        throw new Error(
+          `TinyYolov2 - expected 7 | 8 | 9 convolutional filters, but found ${r} filterSizes in config`,
+        )
+      return rn(t, this.config, this.boxEncodingSize, e)
+    }
+    async extractBoxes(t, e, r) {
+      let {width: n, height: a} = e,
+        s = Math.max(n, a),
+        i = s / n,
+        c = s / a,
+        m = t.shape[1],
+        p = this.config.anchors.length,
+        [d, u, l] = N.tidy(() => {
+          let y = t.reshape([m, m, p, this.boxEncodingSize]),
+            T = y.slice([0, 0, 0, 0], [m, m, p, 4]),
+            F = y.slice([0, 0, 0, 4], [m, m, p, 1]),
+            L = this.withClassScores
+              ? N.softmax(y.slice([0, 0, 0, 5], [m, m, p, this.config.classes.length]), 3)
+              : N.scalar(0)
+          return [T, F, L]
+        }),
+        v = [],
+        _ = await u.array(),
+        h = await d.array()
+      for (let y = 0; y < m; y++)
+        for (let T = 0; T < m; T++)
+          for (let F = 0; F < p; F++) {
+            let L = De(_[y][T][F][0])
+            if (!r || L > r) {
+              let G = ((T + De(h[y][T][F][0])) / m) * i,
+                et = ((y + De(h[y][T][F][1])) / m) * c,
+                it = ((Math.exp(h[y][T][F][2]) * this.config.anchors[F].x) / m) * i,
+                X = ((Math.exp(h[y][T][F][3]) * this.config.anchors[F].y) / m) * c,
+                Pt = G - it / 2,
+                _t = et - X / 2,
+                wt = {row: y, col: T, anchor: F},
+                {classScore: Qt, label: lo} = this.withClassScores
+                  ? await this.extractPredictedClass(l, wt)
+                  : {classScore: 1, label: 0}
+              v.push({
+                box: new ee(Pt, _t, Pt + it, _t + X),
+                score: L,
+                classScore: L * Qt,
+                label: lo,
+                ...wt,
+              })
+            }
+          }
+      return d.dispose(), u.dispose(), l.dispose(), v
+    }
+    async extractPredictedClass(t, e) {
+      let {row: r, col: n, anchor: a} = e,
+        s = await t.array()
+      return Array(this.config.classes.length)
+        .fill(0)
+        .map((i, c) => s[r][n][a][c])
+        .map((i, c) => ({classScore: i, label: c}))
+        .reduce((i, c) => (i.classScore > c.classScore ? i : c))
+    }
+  },
+  ge = io
+ge.DEFAULT_FILTER_SIZES = [3, 16, 32, 64, 128, 256, 512, 1024, 1024]
+var ve = class extends ge {
+  constructor(t = !0) {
+    let e = {
+      withSeparableConvs: t,
+      iouThreshold: qo,
+      classes: ['face'],
+      ...(t ? {anchors: Ko, meanRgb: Qo} : {anchors: Zo, withClassScores: !0}),
+    }
+    super(e)
+  }
+  get withSeparableConvs() {
+    return this.config.withSeparableConvs
+  }
+  get anchors() {
+    return this.config.anchors
+  }
+  async locateFaces(t, e) {
+    return (await this.detect(t, e)).map(
+      n => new M(n.score, n.relativeBox, {width: n.imageWidth, height: n.imageHeight}),
+    )
+  }
+  getDefaultModelName() {
+    return this.withSeparableConvs ? en : tn
+  }
+  extractParamsFromWeightMap(t) {
+    return super.extractParamsFromWeightMap(t)
+  }
+}
+function ia(o, t = !0) {
+  let e = new ve(t)
+  return e.extractWeights(o), e
+}
+var gr = class extends lt {
+  constructor() {
+    super(...arguments)
+    this._name = 'TinyFaceDetectorOptions'
+  }
+}
+var tt = class {
+  async then(t) {
+    return t(await this.run())
+  }
+  async run() {
+    throw new Error('ComposableTask - run is not implemented')
+  }
+}
+var je = b(g())
+var co = b(g())
+async function Xt(o, t, e, r, n = ({alignedRect: a}) => a) {
+  let a = o.map(c => (zt(c) ? n(c) : c.detection)),
+    s = r || (t instanceof co.Tensor ? await se(t, a) : await ae(t, a)),
+    i = await e(s)
+  return s.forEach(c => c instanceof co.Tensor && c.dispose()), i
+}
+async function ye(o, t, e, r, n) {
+  return Xt([o], t, async a => e(a[0]), r, n)
+}
+var nn = 0.4,
+  an = [
+    new x(1.603231, 2.094468),
+    new x(6.041143, 7.080126),
+    new x(2.882459, 3.518061),
+    new x(4.266906, 5.178857),
+    new x(9.041765, 10.66308),
+  ],
+  sn = [117.001, 114.697, 97.404]
+var Fe = class extends ge {
+  constructor() {
+    let t = {
+      withSeparableConvs: !0,
+      iouThreshold: nn,
+      classes: ['face'],
+      anchors: an,
+      meanRgb: sn,
+      isFirstLayerConv2d: !0,
+      filterSizes: [3, 16, 32, 64, 128, 256, 512],
+    }
+    super(t)
+  }
+  get anchors() {
+    return this.config.anchors
+  }
+  async locateFaces(t, e) {
+    return (await this.detect(t, e)).map(
+      n => new M(n.score, n.relativeBox, {width: n.imageWidth, height: n.imageHeight}),
+    )
+  }
+  getDefaultModelName() {
+    return 'tiny_face_detector_model'
+  }
+  extractParamsFromWeightMap(t) {
+    return super.extractParamsFromWeightMap(t)
+  }
+}
+var P = {
+    ssdMobilenetv1: new Ut(),
+    tinyFaceDetector: new Fe(),
+    tinyYolov2: new ve(),
+    faceLandmark68Net: new fe(),
+    faceLandmark68TinyNet: new dr(),
+    faceRecognitionNet: new xe(),
+    faceExpressionNet: new cr(),
+    ageGenderNet: new pr(),
+  },
+  cn = (o, t) => P.ssdMobilenetv1.locateFaces(o, t),
+  ca = (o, t) => P.tinyFaceDetector.locateFaces(o, t),
+  ma = (o, t) => P.tinyYolov2.locateFaces(o, t),
+  mn = o => P.faceLandmark68Net.detectLandmarks(o),
+  pa = o => P.faceLandmark68TinyNet.detectLandmarks(o),
+  da = o => P.faceRecognitionNet.computeFaceDescriptor(o),
+  ua = o => P.faceExpressionNet.predictExpressions(o),
+  la = o => P.ageGenderNet.predictAgeAndGender(o),
+  pn = o => P.ssdMobilenetv1.load(o),
+  fa = o => P.tinyFaceDetector.load(o),
+  ha = o => P.tinyYolov2.load(o),
+  xa = o => P.faceLandmark68Net.load(o),
+  ba = o => P.faceLandmark68TinyNet.load(o),
+  ga = o => P.faceRecognitionNet.load(o),
+  va = o => P.faceExpressionNet.load(o),
+  ya = o => P.ageGenderNet.load(o),
+  Fa = pn,
+  Ta = cn,
+  Pa = mn
+var mo = class extends tt {
+    constructor(t, e, r) {
+      super()
+      this.parentTask = t
+      this.input = e
+      this.extractedFaces = r
+    }
+  },
+  _e = class extends mo {
+    async run() {
+      let t = await this.parentTask,
+        e = await Xt(
+          t,
+          this.input,
+          async r => Promise.all(r.map(n => P.faceExpressionNet.predictExpressions(n))),
+          this.extractedFaces,
+        )
+      return t.map((r, n) => mr(r, e[n]))
+    }
+    withAgeAndGender() {
+      return new Te(this, this.input)
+    }
+  },
+  we = class extends mo {
+    async run() {
+      let t = await this.parentTask
+      if (!t) return
+      let e = await ye(
+        t,
+        this.input,
+        r => P.faceExpressionNet.predictExpressions(r),
+        this.extractedFaces,
+      )
+      return mr(t, e)
+    }
+    withAgeAndGender() {
+      return new Pe(this, this.input)
+    }
+  },
+  Zt = class extends _e {
+    withAgeAndGender() {
+      return new Jt(this, this.input)
+    }
+    withFaceDescriptors() {
+      return new At(this, this.input)
+    }
+  },
+  Kt = class extends we {
+    withAgeAndGender() {
+      return new qt(this, this.input)
+    }
+    withFaceDescriptor() {
+      return new Wt(this, this.input)
+    }
+  }
+var po = class extends tt {
+    constructor(t, e, r) {
+      super()
+      this.parentTask = t
+      this.input = e
+      this.extractedFaces = r
+    }
+  },
+  Te = class extends po {
+    async run() {
+      let t = await this.parentTask,
+        e = await Xt(
+          t,
+          this.input,
+          async r => Promise.all(r.map(n => P.ageGenderNet.predictAgeAndGender(n))),
+          this.extractedFaces,
+        )
+      return t.map((r, n) => {
+        let {age: a, gender: s, genderProbability: i} = e[n]
+        return hr(xr(r, s, i), a)
+      })
+    }
+    withFaceExpressions() {
+      return new _e(this, this.input)
+    }
+  },
+  Pe = class extends po {
+    async run() {
+      let t = await this.parentTask
+      if (!t) return
+      let {age: e, gender: r, genderProbability: n} = await ye(
+        t,
+        this.input,
+        a => P.ageGenderNet.predictAgeAndGender(a),
+        this.extractedFaces,
+      )
+      return hr(xr(t, r, n), e)
+    }
+    withFaceExpressions() {
+      return new we(this, this.input)
+    }
+  },
+  Jt = class extends Te {
+    withFaceExpressions() {
+      return new Zt(this, this.input)
+    }
+    withFaceDescriptors() {
+      return new At(this, this.input)
+    }
+  },
+  qt = class extends Pe {
+    withFaceExpressions() {
+      return new Kt(this, this.input)
+    }
+    withFaceDescriptor() {
+      return new Wt(this, this.input)
+    }
+  }
+var vr = class extends tt {
+    constructor(t, e) {
+      super()
+      this.parentTask = t
+      this.input = e
+    }
+  },
+  At = class extends vr {
+    async run() {
+      let t = await this.parentTask
+      return (
+        await Xt(
+          t,
+          this.input,
+          r =>
+            Promise.all(
+              r.map(n => {
+                if (n.shape[0] < 15) return new Float32Array(128)
+                return P.faceRecognitionNet.computeFaceDescriptor(n)
+              }),
+            ),
+          null,
+          r => r.landmarks.align(null, {useDlibAlignment: !0}),
+        )
+      ).map((r, n) => fr(t[n], r))
+    }
+    withFaceExpressions() {
+      return new Zt(this, this.input)
+    }
+    withAgeAndGender() {
+      return new Jt(this, this.input)
+    }
+  },
+  Wt = class extends vr {
+    async run() {
+      let t = await this.parentTask
+      if (!t) return
+      let e = await ye(
+        t,
+        this.input,
+        r => P.faceRecognitionNet.computeFaceDescriptor(r),
+        null,
+        r => r.landmarks.align(null, {useDlibAlignment: !0}),
+      )
+      return fr(t, e)
+    }
+    withFaceExpressions() {
+      return new Kt(this, this.input)
+    }
+    withAgeAndGender() {
+      return new qt(this, this.input)
+    }
+  }
+var yr = class extends tt {
+    constructor(t, e, r) {
+      super()
+      this.parentTask = t
+      this.input = e
+      this.useTinyLandmarkNet = r
+    }
+    get landmarkNet() {
+      return this.useTinyLandmarkNet ? P.faceLandmark68TinyNet : P.faceLandmark68Net
+    }
+  },
+  Fr = class extends yr {
+    async run() {
+      let t = await this.parentTask,
+        e = t.map(a => a.detection),
+        r = this.input instanceof je.Tensor ? await se(this.input, e) : await ae(this.input, e),
+        n = await Promise.all(r.map(a => this.landmarkNet.detectLandmarks(a)))
+      return r.forEach(a => a instanceof je.Tensor && a.dispose()), t.map((a, s) => le(a, n[s]))
+    }
+    withFaceExpressions() {
+      return new Zt(this, this.input)
+    }
+    withAgeAndGender() {
+      return new Jt(this, this.input)
+    }
+    withFaceDescriptors() {
+      return new At(this, this.input)
+    }
+  },
+  Tr = class extends yr {
+    async run() {
+      let t = await this.parentTask
+      if (!t) return
+      let {detection: e} = t,
+        r = this.input instanceof je.Tensor ? await se(this.input, [e]) : await ae(this.input, [e]),
+        n = await this.landmarkNet.detectLandmarks(r[0])
+      return r.forEach(a => a instanceof je.Tensor && a.dispose()), le(t, n)
+    }
+    withFaceExpressions() {
+      return new Kt(this, this.input)
+    }
+    withAgeAndGender() {
+      return new qt(this, this.input)
+    }
+    withFaceDescriptor() {
+      return new Wt(this, this.input)
+    }
+  }
+var Pr = class extends tt {
+    constructor(t, e = new Z()) {
+      super()
+      this.input = t
+      this.options = e
+    }
+  },
+  He = class extends Pr {
+    async run() {
+      let {input: t, options: e} = this,
+        r =
+          e instanceof gr
+            ? n => P.tinyFaceDetector.locateFaces(n, e)
+            : e instanceof Z
+            ? n => P.ssdMobilenetv1.locateFaces(n, e)
+            : e instanceof lt
+            ? n => P.tinyYolov2.locateFaces(n, e)
+            : null
+      if (!r)
+        throw new Error(
+          'detectFaces - expected options to be instance of TinyFaceDetectorOptions | SsdMobilenetv1Options | MtcnnOptions | TinyYolov2Options',
+        )
+      return r(t)
+    }
+    runAndExtendWithFaceDetections() {
+      return new Promise(async t => {
+        let e = await this.run()
+        t(e.map(r => $t({}, r)))
+      })
+    }
+    withFaceLandmarks(t = !1) {
+      return new Fr(this.runAndExtendWithFaceDetections(), this.input, t)
+    }
+    withFaceExpressions() {
+      return new _e(this.runAndExtendWithFaceDetections(), this.input)
+    }
+    withAgeAndGender() {
+      return new Te(this.runAndExtendWithFaceDetections(), this.input)
+    }
+  },
+  _r = class extends Pr {
+    async run() {
+      let t = await new He(this.input, this.options),
+        e = t[0]
+      return (
+        t.forEach(r => {
+          r.score > e.score && (e = r)
+        }),
+        e
+      )
+    }
+    runAndExtendWithFaceDetection() {
+      return new Promise(async t => {
+        let e = await this.run()
+        t(e ? $t({}, e) : void 0)
+      })
+    }
+    withFaceLandmarks(t = !1) {
+      return new Tr(this.runAndExtendWithFaceDetection(), this.input, t)
+    }
+    withFaceExpressions() {
+      return new we(this.runAndExtendWithFaceDetection(), this.input)
+    }
+    withAgeAndGender() {
+      return new Pe(this.runAndExtendWithFaceDetection(), this.input)
+    }
+  }
+function _a(o, t = new Z()) {
+  return new _r(o, t)
+}
+function wr(o, t = new Z()) {
+  return new He(o, t)
+}
+async function dn(o, t) {
+  return wr(o, new Z(t ? {minConfidence: t} : {}))
+    .withFaceLandmarks()
+    .withFaceDescriptors()
+}
+async function wa(o, t = {}) {
+  return wr(o, new lt(t))
+    .withFaceLandmarks()
+    .withFaceDescriptors()
+}
+var Da = dn
+function uo(o, t) {
+  if (o.length !== t.length) throw new Error('euclideanDistance: arr1.length !== arr2.length')
+  let e = Array.from(o),
+    r = Array.from(t)
+  return Math.sqrt(e.map((n, a) => n - r[a]).reduce((n, a) => n + a ** 2, 0))
+}
+var Dr = class {
+  constructor(t, e = 0.6) {
+    this._distanceThreshold = e
+    let r = Array.isArray(t) ? t : [t]
+    if (!r.length) throw new Error('FaceRecognizer.constructor - expected atleast one input')
+    let n = 1,
+      a = () => `person ${n++}`
+    this._labeledDescriptors = r.map(s => {
+      if (s instanceof xt) return s
+      if (s instanceof Float32Array) return new xt(a(), [s])
+      if (s.descriptor && s.descriptor instanceof Float32Array) return new xt(a(), [s.descriptor])
+      throw new Error(
+        'FaceRecognizer.constructor - expected inputs to be of type LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array | Array<LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array>',
+      )
+    })
+  }
+  get labeledDescriptors() {
+    return this._labeledDescriptors
+  }
+  get distanceThreshold() {
+    return this._distanceThreshold
+  }
+  computeMeanDistance(t, e) {
+    return e.map(r => uo(r, t)).reduce((r, n) => r + n, 0) / (e.length || 1)
+  }
+  matchDescriptor(t) {
+    return this.labeledDescriptors
+      .map(({descriptors: e, label: r}) => new Ee(r, this.computeMeanDistance(t, e)))
+      .reduce((e, r) => (e.distance < r.distance ? e : r))
+  }
+  findBestMatch(t) {
+    let e = this.matchDescriptor(t)
+    return e.distance < this.distanceThreshold ? e : new Ee('unknown', e.distance)
+  }
+  toJSON() {
+    return {
+      distanceThreshold: this.distanceThreshold,
+      labeledDescriptors: this.labeledDescriptors.map(t => t.toJSON()),
+    }
+  }
+  static fromJSON(t) {
+    let e = t.labeledDescriptors.map(r => xt.fromJSON(r))
+    return new Dr(e, t.distanceThreshold)
+  }
+}
+function Ea(o) {
+  let t = new Fe()
+  return t.extractWeights(o), t
+}
+function un(o, t) {
+  let {width: e, height: r} = new A(t.width, t.height)
+  if (e <= 0 || r <= 0)
+    throw new Error(`resizeResults - invalid dimensions: ${JSON.stringify({width: e, height: r})}`)
+  if (Array.isArray(o)) return o.map(n => un(n, {width: e, height: r}))
+  if (zt(o)) {
+    let n = o.detection.forSize(e, r),
+      a = o.unshiftedLandmarks.forSize(n.box.width, n.box.height)
+    return le($t(o, n), a)
+  }
+  return pt(o)
+    ? $t(o, o.detection.forSize(e, r))
+    : o instanceof V || o instanceof M
+    ? o.forSize(e, r)
+    : o
+}
+var Ca = typeof process != 'undefined',
+  Na = typeof navigator != 'undefined' && typeof navigator.userAgent != 'undefined',
+  Ia = {faceapi: Co, node: Ca, browser: Na}
 //# sourceMappingURL=face-api.node.js.map
